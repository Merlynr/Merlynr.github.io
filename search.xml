<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2022/05/15/attachments/1626158803254.table/"/>
      <url>/2022/05/15/attachments/1626158803254.table/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>2022-5-10 Day_Two</title>
      <link href="/2022/05/10/2022-5-10%20Day_Two/"/>
      <url>/2022/05/10/2022-5-10%20Day_Two/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO-List"><a href="#TODO-List" class="headerlink" title="TODO List"></a>TODO List</h1><ul><li><input disabled="" type="checkbox"> 9:30~10:00 今日学习学习            <strong><font color="#D2691E">查看调试参数，构思探索方式</font></strong></li><li><input disabled="" type="checkbox"> 10:00~10:20 上午学习总结</li><li><input disabled="" type="checkbox"> 10:20~10:50 breaking news【一三五】</li><li><input disabled="" type="checkbox"> 10:20~10:50 coding【二四六】</li><li><input disabled="" type="checkbox"> 10:50~11:20 coding【一三五】</li><li><input disabled="" type="checkbox"> 10:50~11:20 刘畅【二四六】</li></ul><hr><ul><li><input disabled="" type="checkbox"> 14:00~15:00 今日学习安排            <strong><font color="#ff7500">JavaScript阅读30%</font></strong></li><li><input disabled="" type="checkbox"> 15:00~16:00 今日学习安排            <strong><font color="#01274F">JavaScript10%</font></strong></li><li><input disabled="" type="checkbox"> 16:00~16:40 今日学习安排            <strong><font color="#2e4e7e">HTML30%</font></strong></li><li><input disabled="" type="checkbox"> 16:40~17:10 下午学习总结</li></ul><hr><ul><li><input disabled="" type="checkbox"> 18:30~19:30 无字幕版美剧</li><li><input disabled="" type="checkbox"> 19:00~21:30 晚上学习安排            <strong><font color="#8B008B">小论文</font></strong></li><li><input disabled="" type="checkbox"> 21:30~22:10 晚上学习安排            <strong><font color="#7FFF00">小论文</font></strong></li><li><input disabled="" type="checkbox"> 22:10~22:30 晚上学习总结</li></ul><h1 id="DONE"><a href="#DONE" class="headerlink" title="DONE"></a>DONE</h1><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul><li>对超参数进行了修改，学习别人的方式重新对奖罚值进行了设置</li></ul><h4 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h4><h2 id="★★★★C0：准确、清晰地描述全新的一天，第一个行动目的。"><a href="#★★★★C0：准确、清晰地描述全新的一天，第一个行动目的。" class="headerlink" title="★★★★C0：准确、清晰地描述全新的一天，第一个行动目的。    "></a>★★★★C0：准确、清晰地描述全新的一天，第一个行动目的。    </h2><p>行动目的：查看调试参数，构思探索方式<br>开始时间：2022/5/10 9:37:29<br>任务耗时：0时,26分<br>★★★★C1：在整体任务进程中，事情已经完成到什么程度？<br>                 <font color="#9932CC">修改了奖罚值，已经重新修改lr</font></p><p>★★★★C2：任务执行中间存在行动偏差，或被迫中断吗？下一步如何纠正？<br>                 <font color="#9932CC">无，时间短</font></p><p>★★★★C3：恭喜你，再一次强化了自己的执行力。再接再厉，下一步继续做什么？让时间看得见，记录你的生命历程。<br>                 <font color="#9932CC">修改参数，写小论文，做英语练习</font><br>任务评价：2022/5/10 10:02:05■■■■■■■■■■99</p>]]></content>
      
      
      <categories>
          
          <category> daily </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022-5-9 Day-One</title>
      <link href="/2022/05/09/2022-5-9%20Day-One/"/>
      <url>/2022/05/09/2022-5-9%20Day-One/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO-List"><a href="#TODO-List" class="headerlink" title="TODO List"></a>TODO List</h1><ul><li><input checked="" disabled="" type="checkbox"> 16:00~16:40 今日学习安排            <strong><font color="#2e4e7e">算法复习</font></strong></li><li><input checked="" disabled="" type="checkbox"> 16:40~17:10 下午学习总结</li></ul><hr><ul><li><input checked="" disabled="" type="checkbox"> 18:30~20:00 无字幕版美剧</li><li><input checked="" disabled="" type="checkbox"> 20:00~21:30 晚上学习安排            <strong><font color="#8B008B">前端基础</font></strong></li><li><input disabled="" type="checkbox"> 21:30~22:10 晚上学习安排            <strong><font color="#7FFF00">小论文的书写</font></strong></li><li><input disabled="" type="checkbox"> 22:10~22:30 晚上学习总结</li></ul><h1 id="DONE"><a href="#DONE" class="headerlink" title="DONE"></a>DONE</h1><h2 id="算法基础涉及"><a href="#算法基础涉及" class="headerlink" title="算法基础涉及"></a>算法基础涉及</h2><ol><li>前端的Hooks</li><li><a href="https://hyp.is/_V-ciM9vEeya5He_JLc9HQ/zhuanlan.zhihu.com/p/330300133">对头堵塞</a>   </li><li><a href="https://hyp.is/S35o_M93EeyS9vtQSSIAJQ/zhuanlan.zhihu.com/p/107947462">DSL</a> </li></ol><h1 id="JavaScript高级程序设计（4）"><a href="#JavaScript高级程序设计（4）" class="headerlink" title="JavaScript高级程序设计（4）"></a>JavaScript高级程序设计（4）</h1><ol><li>主要时间用于收集材料了，所以看的不多，只看了js的由三部分组成。</li></ol>]]></content>
      
      
      <categories>
          
          <category> daily </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>liumeixian</title>
      <link href="/2021/12/07/liumeixian/"/>
      <url>/2021/12/07/liumeixian/</url>
      
        <content type="html"><![CDATA[<h1 id="任务一-刘美贤账号等信息"><a href="#任务一-刘美贤账号等信息" class="headerlink" title="任务一 刘美贤账号等信息"></a>任务一 刘美贤账号等信息</h1><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1638877621135.png" alt="刘美贤"></p><p>刘美贤 Facebook <a href="https://www.facebook.com/Alysa-Liu-608813242911744/">https://www.facebook.com/Alysa-Liu-608813242911744/</a><br>            Ins <a href="https://www.instagram.com/explore/tags/alysaliu/">https://www.instagram.com/explore/tags/alysaliu/</a><br>            Tumbler <a href="https://www.tumblr.com/tagged/alysa%20liu">https://www.tumblr.com/tagged/alysa%20liu</a></p><p>近况：搬到科罗拉多斯普林斯与Christy Krall、Drew Meekins 和Viktor Pfeifer一起训练</p><h1 id="任务二-刘美贤言论"><a href="#任务二-刘美贤言论" class="headerlink" title="任务二 刘美贤言论"></a>任务二 刘美贤言论</h1><ol><li>facebook只有比赛信息</li><li>ins只有比赛信息</li><li>tumbler 只有比赛信息</li></ol><p><strong>与她相关论坛</strong><br><a href="https://kantie.org/topics/huaren/2384809">https://kantie.org/topics/huaren/2384809</a><br><a href="https://www.westca.com/pda/forums/op=view_topic/t=939274/page=1/lang=schinese.html#0">https://www.westca.com/pda/forums/op=view_topic/t=939274/page=1/lang=schinese.html#0</a></p><h1 id="任务三四-刘俊国信息"><a href="#任务三四-刘俊国信息" class="headerlink" title="任务三四 刘俊国信息"></a>任务三四 刘俊国信息</h1><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1638885259077.png" alt="刘俊国"></p><p>刘俊国 Facebook <a href="https://www.facebook.com/arthur.liu.16503">https://www.facebook.com/arthur.liu.16503</a><br>            twitter @arthurist<br><strong>其中twitter个人简介种包含<font color="#FF00FF">国民党</font>旗帜和同性恋的彩虹旗</strong><br>联系电话：(510) 986-1198<br>详细地址：324 10th St., #223, Oakland, CA 94607<br><strong>二个办公室</strong><br>在屋仑市地址：1904 Franklin St.,Suite #203, Oakland, CA 94612，<br>电话：510-986-1198，<br>传真：510-986-0889，<br>在圣荷西市：79 Devine Street, Suite #201, San Jose, CA 95110，<br>电邮：<a href="mailto:&#x41;&#x72;&#x74;&#x68;&#x75;&#x72;&#108;&#105;&#x75;&#x75;&#x73;&#x61;&#x40;&#x79;&#x61;&#104;&#111;&#x6f;&#x2e;&#x63;&#x6f;&#x6d;">&#x41;&#x72;&#x74;&#x68;&#x75;&#x72;&#108;&#105;&#x75;&#x75;&#x73;&#x61;&#x40;&#x79;&#x61;&#104;&#111;&#x6f;&#x2e;&#x63;&#x6f;&#x6d;</a>。<br><strong>与他相关论坛</strong><br><a href="https://kantie.org/topics/huaren/2384809">https://kantie.org/topics/huaren/2384809</a><br><a href="https://news.boxun.com/news/gb/china/2003/06/200306021238.shtml">https://news.boxun.com/news/gb/china/2003/06/200306021238.shtml</a><br><strong>他朋友中的反华势力</strong></p><ol><li>赵昕 <a href="https://www.facebook.com/profile.php?id=100013087354687">https://www.facebook.com/profile.php?id=100013087354687</a>    【他没有近期对此评论】</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1639037947027.png" alt="赵昕"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1639037976243.png" alt="个人信息"></p><ol start="2"><li>Amy Niu <a href="https://www.facebook.com/amy.niu.714">https://www.facebook.com/amy.niu.714</a>    【他没有近期对此评论】</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1639038026849.png" alt="Amy Niu"></p><ol start="3"><li>Xiang Wei Guo    <a href="https://www.facebook.com/xiangwei.guo.7">https://www.facebook.com/xiangwei.guo.7</a>    【他没有近期对此评论】</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1639038064283.png" alt="Xiang Wei Guo"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1639038100364.png" alt="个人信息"></p><ol start="4"><li>云 郑 <a href="https://www.facebook.com/profile.php?id=100013097400724">https://www.facebook.com/profile.php?id=100013097400724</a> 【他没有近期对此评论】</li><li>Steven Gu  <a href="https://www.facebook.com/steven.gu.587">https://www.facebook.com/steven.gu.587</a>   【他没有近期对此评论】</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1639039094402.png" alt="Steven Gu"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202112/1639039121085.png" alt="个人信息"></p><h1 id="任务五"><a href="#任务五" class="headerlink" title="任务五"></a>任务五</h1><ol><li>2021.11.22 <a href="https://twitter.com/graykimbrough/status/1462792458841079808?s=19">对于一个州的改革用“小香港”进行评论</a></li><li>2021.11.12 <a href="https://twitter.com/KyungLahCNN/status/1458869423348109312?s=19">对于美国的亚洲商品供应链进行点评</a></li><li>2019.1.27 <a href="https://twitter.com/wurenhua/status/1089381185120157701?s=19">他的朋友给他发送关于女儿夺冠的祝贺，其中谈及到了关于中国的政治问题</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> people </category>
          
      </categories>
      
      
        <tags>
            
            <tag> security </tag>
            
            <tag> people </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-11-30【周总结】</title>
      <link href="/2021/11/30/2021-11-30%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/11/30/2021-11-30%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li><input checked="" disabled="" type="checkbox"> 完成开题整体结构</li><li><input checked="" disabled="" type="checkbox"> 修改开题依据和研究内容</li><li><input checked="" disabled="" type="checkbox"> 调研增强学习的探索方式，并选取适合开题的方式</li><li><input checked="" disabled="" type="checkbox"> 完善开题中关于页面元素映射的相关思路</li></ul><h1 id="DONE"><a href="#DONE" class="headerlink" title="DONE"></a>DONE</h1><ol><li>根据上次开题反馈以及后期选取的研究点，重新构建了新的研究方向和开题内容，主要研究的是业务流程智能化，即对于流程策略的优化</li><li>经过上次演讲和老师辅导，反思自己在研究背景，研究意义以及趋势的书写错误进行改正。这块应该是正对业务流程发展进行描写，而不是描写后面对于模型的改进。</li><li>调研了目前主要的几种探索方式，包括了持续的随机的探索方式以及其改进，和通过监控环境的方式来进行探索。最后结合业务流程自动化的场景可能随时变化，同时页面元素复杂，通过监督的方式进行探索花费的资源比较大，所以选择了持续的一种探索方式，通过加入动作噪声来进行探索。</li><li>对于页面元素映射的算法进行了研究，结合页面元素本身定位复杂，同时不同页面的元素结构不同，这就导致一些对于数据结构要求固定的算发无法被应用到。我们直接采用顺序的元素捕获方式，将其有序映射到固定表单。</li></ol>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-11-21【周总结】</title>
      <link href="/2021/11/21/2021-11-21%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/11/21/2021-11-21%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li><input checked="" disabled="" type="checkbox"> 构建开题中的部分研究点</li><li><input checked="" disabled="" type="checkbox"> 阅读和理解强化学习与深度学习相结合的模型DPG和DDPG</li><li><input checked="" disabled="" type="checkbox"> 重新梳理开题的研究背景和内容等</li></ul><h1 id="DONE"><a href="#DONE" class="headerlink" title="DONE"></a>DONE</h1><p>1、重新修改开题题目，将业务流程自动化最优制定策略提取出来作为专门的研究点展开研究，研究过程中，发现深度学习模型仅仅是可以学习到已有的、被大部分沿用的流程策略，只能帮助员工进行流程制作，而无法对已有的流程进行优化，所以进行了进一步研究，发现策略优化是强化学习的一个重要研究点。所以加深了对于强化学习的研究，在研究过程中发现，简单的强化学习无法对于样本利用率低，同时针对业务流程这样的生产环境发现，强化学习模型无法存储这么多&lt;状态-动作&gt;,所以又引入深度学习，主要是RNN模型来存储离散的序列，这样就可以有效提升业务流程过程中的优化。其中还有很多需要克服的问题，后期会一一提出，并寻找解决方法。<br>2、第二部分是对于两个主流的深度增强学习模型进行学习。进行比较学习了两个模型的优缺和演变过程。<br>3、这一部分是听取老师的建议后进行了重新修改开题的结构，上次演讲过后进行反思，认为自己的整体结构确实比较散乱，既没有以流程自动化为中心进行研究，也没有将深度学习与强化学习的结合融汇到一块，所以其它同学没有听懂我要做什么，所有又进一步进行了修改整体脉络。</p>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-11-16【周总结】</title>
      <link href="/2021/11/16/2021-11-16%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/11/16/2021-11-16%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li><input checked="" disabled="" type="checkbox"> 强化学习</li><li><input checked="" disabled="" type="checkbox"> 深度学习在深度强化学习的作用</li><li><input disabled="" type="checkbox"> 开题准备</li></ul><h1 id="DONE"><a href="#DONE" class="headerlink" title="DONE"></a>DONE</h1><ol><li>学习了强化学习中关于离策略近似方法、资格迹和策略梯度方法。同时阅读了《自适应序列生成的建筑能耗预测》</li><li>学习了DQN，DP以及DDPG模型</li><li>主要针对构建策略函数、价值函数的构建进行了深入研究，同时由于主要考虑了**==强化学习在Web场景中进行广义探索探索方式 #F44336==** ，同时在Web场景中状态的数量也很多，提出使用==高维数 #F44336==据来记录代理机器人状态，通过映射函数记录状态与动作的映射关系。</li></ol>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-11-8【mission】</title>
      <link href="/2021/11/08/2021-11-8%E3%80%90mission%E3%80%91/"/>
      <url>/2021/11/08/2021-11-8%E3%80%90mission%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ol><li>20.50-11.20 <a href="https://rl.qiwihui.com/zh_CN/latest/partII/chapter9/on-policy_prediction_with_approximation.html">在策略预测近似方法</a></li><li>在策略控制近似方法</li><li>离策略近似方法</li><li>资格迹</li><li>策略梯度的方法</li><li>周报</li></ol><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p> 如果强化学习系统要适用于人工智能或大型工程应用，则必须能够进行 泛化。 为了实现这一点，可以简单地通过将每个更新视为训练样例，使用用于 监督学习函数近似 的任何广泛的现有方法。</p><p>也许最合适的监督学习方法是使用 参数化函数近似 的方法，其中策略由权向量 w 参数化。 虽然权重向量有很多分量，但状态空间仍然大得多，我们必须找到一个近似的解决方案。 我们将 均方值误差 VE¯¯¯¯¯¯¯¯(w) 定义为 在策略分布 μ 下 权重向量 w 的值 vπw(s) 中的误差的度量。 VE¯¯¯¯¯¯¯¯ 为我们提供了一种明确的方法，可以在在<a href="https://rl.qiwihui.com/zh_CN/latest/partII/chapter9/on-policy_prediction_with_approximation.html#id16">策略案例</a>中对不同的价值函数近似进行排序。<br>为了找到一个好的权重向量，最流行的方法是 随机梯度下降 （SGD）的变化。 在本章中，我们重点关注具有 固定策略 的 在策略 案例，也称为策略评估或预测； 这种情况下的自然学习算法是 n步半梯度TD，其包括梯度蒙特卡罗和半梯度TD(0)算法 作为 n=∞ 和 n=1 的特殊情况。半梯度TD方法不是真正的梯度方法。 在这种自举方法（包括DP）中，权重向量出现在更新目标中，但在计算梯度时不考虑这一点──因此它们是 半 梯度方法。 因此，他们不能依赖于经典的SGD结果。</p><p>然而，在 线性 函数近似的特殊情况下，半梯度方法可以获得良好的结果， 其中价值估计是特征的总和乘以相应的权重。线性情况在理论上是最容易理解的，并且在提供适当特征时在实践中工作良好。 选择特征是将先前领域知识添加到强化学习系统的最重要方法之一。 它们可以被选择为多项式，但是这种情况在通常在强化学习中考虑的在线学习设置中很难感化。 更好的是根据傅立叶基选择特征，或者根据稀疏重叠感受域的某种形式的粗编码。 铺片编码是粗编码的一种形式，其特别具有计算效率和灵活性。 径向基函数对于一维或二维任务非常有用，其中平滑变化的响应很重要。 LSTD是数据最有效的线性TD预测方法，但<font color="#8A2BE2">需要与权重数的平方成比例的计算</font>，而所有其他方法在权重数量上<font color="#A52A2A">具有线性复杂性</font>。 非线性方法包括通过反向传播训练的人工神经网络和SGD的变化；这些方法近年来以 深度强化学习 的名义变得非常流行。</p><p>对于所有 n，线性半梯度n步TD保证在标准条件下 收敛到最佳误差范围内的 VE¯¯¯¯¯¯¯¯ （通过蒙特卡罗方法渐近实现）。 对于更高的n，这个界限总是更紧，并且对于 n→∞ 来说接近零。 然而，在实践中，非常高的n导致学习非常缓慢，并且一定程度的自举（n&lt;∞）通常是可取的， 正如我们在第7章中的表格n步法和和第5章中表格TD和蒙特卡罗方法的比较中所看到的那样。</p><p><a href="https://www.sohu.com/a/136502405_114877">采样</a> </p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20211113/1636808280633.png" alt="最后用伪代码进行阐述"></p><p>需要修改的是动作策略</p>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-11-8【周总结】</title>
      <link href="/2021/11/08/2021-11-8%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/11/08/2021-11-8%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li><input disabled="" type="checkbox"> 答辩总结</li><li><input disabled="" type="checkbox"> 本周学习—强化学习</li></ul><h1 id="DONE"><a href="#DONE" class="headerlink" title="DONE"></a>DONE</h1><ol><li>答辩问题与总结</li></ol><ul><li>数据集哪来的</li><li>和老师们理解的智能化不一样，他们理解的是在创建过程中提示最佳策略</li><li>机器人范围不够详细，物流机器人这些都有可能</li><li>如何有效蒙特拉洛算法咋没写上</li><li>题目需要修改</li></ul><p>针对老师所提及的关键问题首先是针对算法层面的讲解确实不够详细，这方面确实也没有准备充分，由于开题准备确实比较粗浅，而且在工程应用方面的设计占比比较多，时间占用也比较大，所以忽视了在算法研究上的投入。同时与其它学硕进行比较都是针对某一点，然后进行算法上的刨析，进行研究，在这发面确实存在不足。其次针对另一个老师提出的覆盖面较大，应该抓住某一点进行研究，开题涉及面过大反而大致研究内容比较杂，同时研究方案存在比较空洞的问题，在开题前就担心自己所涉及到的更多的是应用层面，从而缺少对于深度学习深入讨论，虽然后期补了一个神经网路结构和强化学习算法，但是相较与其它学硕依旧显得很研究很单薄，不具有说服力。所以后期会针对某一方面进行深入研究。</p><ol start="2"><li>本周学习任务主要是完成强化学习的理论学习，包括主要的n步引导方法、表格方法规划和学习、在策略预测近似方法、在策略控制近似方法等。基本的强度学习方法无论是在策略强化学习还是离策略强化学习在时间序列的问题上都存在只能非平稳的学习到目标值的问题，所以目前的方法是策略由权重向量参数化，设置VE（均方值误差）作为度量，然后通过一些梯度下降方法来寻找最好的权重向量。另一个是目前还存在疑虑的就是对于长序列的记录效果差，这一块还没看完，所以还在看。</li></ol>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-11-01【周总结】</title>
      <link href="/2021/11/01/2021-11-01%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/11/01/2021-11-01%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<p>目标<br>1.流程构建辅助决策<br>2.页面元素获取<br>3.运行过程中的自动修正和反馈</p><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>[1]周能. 复杂场景下基于深度增强学习的移动机器人控制方法研究[D].北京邮电大学,2019.<br><a href="https://segmentfault.com/a/1190000014128757">强化学习</a><br><a href="https://blog.csdn.net/weixin_41521681/article/details/108016951">强化学习算法分类</a><br>[1]凌兴宏,李杰,朱斐,刘全,伏玉琛.基于双重注意力机制的异步优势行动者评论家算法[J].计算机学报,2020,43(01):93-106.</p><h2 id="策略模块"><a href="#策略模块" class="headerlink" title="策略模块"></a>策略模块</h2><ol><li>无算法</li><li>组成：影响因子【暂定名称】，决策池、根据因子和决策池重新构建权重最大的可能【简单算法】</li><li>是否考虑不同错误对应不同修改方案</li><li>影响因子不仅是根据页面元素的可能性设置，同时需要考虑动作</li><li>错误的基本原因“自适应”，“版本更替”</li><li>增强模型，决策函数，评估函数，奖励函数和外界反馈</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021102/1633159142456.png" alt="DQN"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021102/1633159979319.png" alt="训练框架"></p><h3 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h3><ol><li>预测模块基于lstm进行微调</li><li>改进增强学习模型actor-critic，加入影响因子，提高决策效果</li><li>为了控制<h2 id="引用-1"><a href="#引用-1" class="headerlink" title="引用"></a>引用</h2>智能自动化技术在汽车安全辅助驾驶系统中的应用 </li></ol><h1 id="二辩准备"><a href="#二辩准备" class="headerlink" title="二辩准备"></a>二辩准备</h1><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul><li><input disabled="" type="checkbox"> <ol><li>ppt新增页面—上次答辩记录和修改</li></ol></li><li><input disabled="" type="checkbox"> <ol start="2"><li>将DOM元素获取放到最后一个研究方案</li></ol></li><li><input disabled="" type="checkbox"> <ol start="3"><li>重新写研究目标，研究内容，研究方案，算法是主要</li></ol></li></ul><h2 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h2><ol><li>情节性的任务需要重新额外的<a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter3/finite_markov_decision_process.html#id2">符号</a></li><li>算法函数<a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter3/finite_markov_decision_process.html#id13">分析</a></li><li>多个动作集合成一个，减少不必要的搜索</li><li>一个栗子 示例3.19：回收机器人的贝尔曼最优方程 使用（<a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter3/finite_markov_decision_process.html#id13">3.19</a>）这个解决方案依赖于至少三个假设，在实践中很少是这样的： （1）我们准确地知道环境的动态；（2）我们有足够的计算资源来完成解决方案的计算；（3）马尔可夫性。 </li><li> <a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter4/dynamic_programming.html#id7">使价值函数的策略贪婪通常会使更改的策略的价值函数不正确，使价值函数与策略一致通常会导致该策略不再贪婪。</a>  策略评估 指的是（通常）迭代计算一个给定策略的价值函数。策略提升 指的是给定一个策略的价值函数计算一个提升的策略。</li><li>  就像在动态规划（DP）的那章所做的，首先我们考虑预测的问题 （计算一个确定的随机策略 π 的价值 vπ 和 qπ ）， 然后是策略提升，以及最后，控制的问题和解决它的广义策略迭代方法。 从动态规划（DP）中得到的这些想法都被推广到蒙特卡洛方法中，不过在这种情况下（指蒙特卡洛），我们只有样本经验。</li><li>  行为策略&amp;目标策略的制定</li><li>  rollout策略生成模拟轨迹</li><li>  MCTS决策时规划取得的巨大成功深刻影响了人工智能，许多研究人员正在研究用于游戏和单一个体应用程序的<a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter8/planning_and_learning_with_tabular_methods.html#id12">基本程序的修改和扩展</a>。</li><li>  <a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter8/planning_and_learning_with_tabular_methods.html#id14">总结</a></li><li>  <a href="https://rl.qiwihui.com/zh_CN/latest/partII/index.html#id1">泛化</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2021/10/02/attachments/1625557760628.table/"/>
      <url>/2021/10/02/attachments/1625557760628.table/</url>
      
        <content type="html"><![CDATA[<table class='table table-celled table-component' border='1' style='border-collapse: collapse; width: 100%;' id='tinymcetable' > <tbody><tr><td>&nbsp;</td><td style="background-color: #d9caca;">&nbsp;晴</td><td style="background-color: #d9caca;">&nbsp;阴</td></tr><tr><td style="background-color: #d1c9c9;">&nbsp;晴</td><td>&nbsp;0.9</td><td>0.1&nbsp;</td></tr><tr><td style="background-color: #e3dcdc;">&nbsp;阴</td><td>&nbsp;0.5</td><td>0.5&nbsp;</td></tr></tbody> </table>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>开题准备</title>
      <link href="/2021/09/30/%E5%BC%80%E9%A2%98%E5%87%86%E5%A4%87/"/>
      <url>/2021/09/30/%E5%BC%80%E9%A2%98%E5%87%86%E5%A4%87/</url>
      
        <content type="html"><![CDATA[<p>目标<br>1.流程构建辅助决策<br>2.页面元素获取<br>3.运行过程中的自动修正和反馈</p><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>[1]周能. 复杂场景下基于深度增强学习的移动机器人控制方法研究[D].北京邮电大学,2019.<br><a href="https://segmentfault.com/a/1190000014128757">强化学习</a><br><a href="https://blog.csdn.net/weixin_41521681/article/details/108016951">强化学习算法分类</a><br>[1]凌兴宏,李杰,朱斐,刘全,伏玉琛.基于双重注意力机制的异步优势行动者评论家算法[J].计算机学报,2020,43(01):93-106.</p><h2 id="策略模块"><a href="#策略模块" class="headerlink" title="策略模块"></a>策略模块</h2><ol><li>无算法</li><li>组成：影响因子【暂定名称】，决策池、根据因子和决策池重新构建权重最大的可能【简单算法】</li><li>是否考虑不同错误对应不同修改方案</li><li>影响因子不仅是根据页面元素的可能性设置，同时需要考虑动作</li><li>错误的基本原因“自适应”，“版本更替”</li><li>增强模型，决策函数，评估函数，奖励函数和外界反馈</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021102/1633159142456.png" alt="DQN"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021102/1633159979319.png" alt="训练框架"></p><h3 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h3><ol><li>预测模块基于lstm进行微调</li><li>改进增强学习模型actor-critic，加入影响因子，提高决策效果</li><li>为了控制<h2 id="引用-1"><a href="#引用-1" class="headerlink" title="引用"></a>引用</h2>智能自动化技术在汽车安全辅助驾驶系统中的应用 </li></ol><h1 id="二辩准备"><a href="#二辩准备" class="headerlink" title="二辩准备"></a>二辩准备</h1><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul><li><input disabled="" type="checkbox"> <ol><li>ppt新增页面—上次答辩记录和修改</li></ol></li><li><input disabled="" type="checkbox"> <ol start="2"><li>将DOM元素获取放到最后一个研究方案</li></ol></li><li><input disabled="" type="checkbox"> <ol start="3"><li>重新写研究目标，研究内容，研究方案，算法是主要</li></ol></li></ul><h2 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h2><ol><li>情节性的任务需要重新额外的<a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter3/finite_markov_decision_process.html#id2">符号</a></li><li>函数<a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter3/finite_markov_decision_process.html#id13">分析</a></li><li>多个动作集合成一个，减少不必要的搜索</li><li>一个栗子 示例3.19：回收机器人的贝尔曼最优方程 使用（<a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter3/finite_markov_decision_process.html#id13">3.19</a>）这个解决方案依赖于至少三个假设，在实践中很少是这样的： （1）我们准确地知道环境的动态；（2）我们有足够的计算资源来完成解决方案的计算；（3）马尔可夫性。 </li><li> <a href="https://rl.qiwihui.com/zh_CN/latest/partI/chapter4/dynamic_programming.html#id7">使价值函数的策略贪婪通常会使更改的策略的价值函数不正确，使价值函数与策略一致通常会导致该策略不再贪婪。</a>  策略评估 指的是（通常）迭代计算一个给定策略的价值函数。策略提升 指的是给定一个策略的价值函数计算一个提升的策略。</li><li>  就像在动态规划（DP）的那章所做的，首先我们考虑预测的问题 （计算一个确定的随机策略 π 的价值 vπ 和 qπ ）， 然后是策略提升，以及最后，控制的问题和解决它的广义策略迭代方法。 从动态规划（DP）中得到的这些想法都被推广到蒙特卡洛方法中，不过在这种情况下（指蒙特卡洛），我们只有样本经验。</li><li>  行为策略&amp;目标策略的制定</li></ol>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
            <tag> daily/weekly </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-9-06【周总结】</title>
      <link href="/2021/09/06/2021-9-06%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/09/06/2021-9-06%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ol><li><input checked="" disabled="" type="checkbox"> tensorflow2.0</li><li><input checked="" disabled="" type="checkbox"> 看LSTM源码，了解其对于数据的处理方式</li><li><input checked="" disabled="" type="checkbox"> 继续看源码</li></ol><ul><li><input checked="" disabled="" type="checkbox"> <ol start="7"><li>几篇论文创意点总结</li></ol></li><li><input disabled="" type="checkbox"> <ol start="10"><li>几篇论文创意点总结</li></ol></li><li><input checked="" disabled="" type="checkbox"> <ol start="11"><li>小论文摘要</li></ol></li><li><input checked="" disabled="" type="checkbox"> <ol start="7"><li>几篇论文创意点总结<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1></li></ol></li></ul><ul><li>学的是tensorflow中自动求导机制的函数GradientTape()，其中包函了一阶求导和二阶求导。</li><li>对于一个Tensor和Variable类型，如果你的网络结构使用的是Dense Layers构建的，里面的变量w, b类型就是Variable类型的变量， <font color="#0000FF">也就是不需要watch</font>；如果我们构建的x是一个constant也就是一个Tenosr类型的话，为了更好的跟踪梯度的相关信息，这里需要把它加进tape.watch里面去，这个例子就是。</li><li><font color="#228B22">tf.GradientTape里面默认只会跟踪tf.Variable()类型</font>。如果类型不是这个的话。这里为tf.tensor,tf.Variable是tf.tensor的一种特殊类型。因此简单的包装一下，在tensor类型外面包一个Variable类型。</li></ul><p> “Classifying process instances using recurrent neural networks,”–Springer, 2018, pp. 313–324.</p><ul><li>paper中作者的创意是首次使用LSTM和GRU流程进行分类并进行对比，GRU效果较好。【涉及到超长序列可能有用。作者思想是<font color="#A52A2A">将长序列中不频繁及数量少的序列视为一项活动</font>，可以进一步提高吞吐量时间且不会显著影响分类精度】</li></ul><p>“Learning Effective Neural Nets for Outcome Prediction from Partially Labelled Log Data”–2019 IEEE</p><ul><li><p>paper中作者的创新点是基于默认模型进行无监督学习，主要思路是通过微调来提高预测精准度。比较的是训练数据集大小与预测准确度之间的比例，<font color="#7FFF00">没有可以借鉴的</font>。</p><h1 id="TODO-1"><a href="#TODO-1" class="headerlink" title="TODO"></a>TODO</h1><p>构思开题，与自己研究方向出入较大。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EVERYDAY---2021</title>
      <link href="/2021/08/30/EVERYDAY---2021/"/>
      <url>/2021/08/30/EVERYDAY---2021/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO-List"><a href="#TODO-List" class="headerlink" title="TODO List"></a>TODO List</h1><ul><li><input disabled="" type="checkbox"> 9:00~10:00 今日学习学习            <strong><font color="#D2691E">todo-1</font></strong></li><li><input disabled="" type="checkbox"> 10:00~10:20 上午学习总结</li><li><input disabled="" type="checkbox"> 10:20~10:50 breaking news【一三五】</li><li><input disabled="" type="checkbox"> 10:20~10:50 coding【二四六】</li><li><input disabled="" type="checkbox"> 10:50~11:20 coding【一三五】</li><li><input disabled="" type="checkbox"> 10:50~11:20 刘畅【二四六】</li></ul><hr><ul><li><input disabled="" type="checkbox"> 14:00~15:00 今日学习安排            <strong><font color="#ff7500">todo-2</font></strong></li><li><input disabled="" type="checkbox"> 15:00~16:00 今日学习安排            <strong><font color="#01274F">todo-3</font></strong></li><li><input disabled="" type="checkbox"> 16:00~16:40 今日学习安排            <strong><font color="#2e4e7e">todo-4</font></strong></li><li><input disabled="" type="checkbox"> 16:40~17:10 下午学习总结</li></ul><hr><ul><li><input disabled="" type="checkbox"> 18:30~20:00 无字幕版美剧</li><li><input disabled="" type="checkbox"> 20:00~21:30 晚上学习安排            <strong><font color="#8B008B">todo-5</font></strong></li><li><input disabled="" type="checkbox"> 21:30~22:10 晚上学习安排            <strong><font color="#7FFF00">todo-6</font></strong></li><li><input disabled="" type="checkbox"> 22:10~22:30 晚上学习总结</li></ul><p>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 </p>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-8-24【周总结】</title>
      <link href="/2021/08/24/2021-8-24%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/08/24/2021-8-24%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li><input checked="" disabled="" type="checkbox"> 学习吴恩达–机器学习视频</li><li><input checked="" disabled="" type="checkbox"> 搭建本地实验环境</li><li><input checked="" disabled="" type="checkbox"> 查看数据集，查看基本预处理方法</li><li><input disabled="" type="checkbox"> 小论文框架构建</li></ul><h1 id="Done"><a href="#Done" class="headerlink" title="Done"></a>Done</h1><ol><li>前段时间只是看完前半部分中吴老师讲的机器学习中基础算法理论，看完这些的时候基本上论文中涉及到机器学习专业词汇都能理解，就算有些涉及到了模型也可以通过查询很快就能理解。上周做实验的时候经常做不下去，就索性把吴老师后半部分的课程看完了，大概有40节，主要包函的是常见的模型，支持向量机，核函数，以及k-means，还有一部分是对于数据的预处理的方法。【看这个视频的原因一个是需要入门，另一个主要原因是当时听彭老师实验室一个研一学生的分享，他做了一次基本实验的演示分享，觉得很不错，对于模型的理解更加透彻，最后才听到他和彭老师对话说的，就是跟着视频学习，所以觉得自己也应该学一遍】</li><li>主要是为了学习tensorflow，本地搭建了python3.6+tensorflow1.5.0和python3.7+tensorflow2.1.1两个版本，由于tensorflow2是去年年初更新的，而且两个版本差异比较大，所以都进行了对于其CPU版本进行简单的尝试</li><li>适用Prom工具进行了简单流程挖掘，基本的流程可以挖掘出来了，下一步是对数据进行预处理，这一块估计有很大工作量</li><li>小论文框架已经开始构思了，现在在整理之前看到的paper，近两年文章发的比较少哇，所以看的论文一般都是2019年以前的。</li></ol><p><strong><font color="#1E90FF">目前的论文思维导图：</font></strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021825/1629874905860.png" alt="Introduce的材料"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021825/1629874977085.png" alt="部分数据集及预处理"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021825/1629875159925.png" alt="预处理"></p><p><font color="#5F9EA0">近几年都是前缀填充和连续编码为主，目前我只看到18年有一篇用到N-gram，还是适用自动编码器的文中用到了，其它LSTM这种热门框架都没用到，这个后续中我也会把序列编码的方法换成连续编码。</font></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021825/1629875199842.png" alt="后续待完善"></p><p>这几年都没看到有与语义结合的，就LSTM，GRU这种RNN网络结构，<font color="#CC391D">个人感觉</font>上下文关系在其中的体现不是很大，因为本身业务流程直接关系没有那么复杂，words bag也没有自然语言中实体处理中的那么大，下周抽空看一篇，记得之前看到过一篇。</p><h1 id="下周安排"><a href="#下周安排" class="headerlink" title="下周安排"></a>下周安排</h1><ul><li><input disabled="" type="checkbox"> 看一遍吴老师对于深度学习的讲解</li><li><input disabled="" type="checkbox"> “TAP: A Transformer based Activity Prediction Exploiting Temporal Relations in Collaborative Tasks” 2021 IEEE</li><li><input disabled="" type="checkbox"> 书写小论文的introduce</li><li><input disabled="" type="checkbox"> 继续学习tensorflow的使用</li></ul>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实验安排</title>
      <link href="/2021/08/20/%E5%AE%9E%E9%AA%8C%E5%AE%89%E6%8E%92/"/>
      <url>/2021/08/20/%E5%AE%9E%E9%AA%8C%E5%AE%89%E6%8E%92/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gitee.com/merlynr/img-store/raw/master/2021820/1629431056745.png" alt="实验安排"></p>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
            <tag> daily/weekly </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-8-15【周总结】</title>
      <link href="/2021/08/15/2021-8-17%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/08/15/2021-8-17%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="本周安排"><a href="#本周安排" class="headerlink" title="本周安排"></a>本周安排</h1><ul><li><input checked="" disabled="" type="checkbox"> 思考小论文的可研究点</li><li><input disabled="" type="checkbox"> 构建论文结构~</li><li><input disabled="" type="checkbox"> 查找相关算法</li><li><input checked="" disabled="" type="checkbox"> 搭建实验室论坛</li></ul><h1 id="完成情况"><a href="#完成情况" class="headerlink" title="完成情况"></a>完成情况</h1><h2 id="研究点"><a href="#研究点" class="headerlink" title="研究点"></a>研究点</h2><ol><li><p>在不损失正常长度流程的预测精度下，提高长度较长的预测精度</p><ul><li>方法一：该想法建立的基础是在RNN神经网络上，由于对于长序列的处理效率低，所以当时想的可以通过预处理，<strong>通过聚类或者其它方式划分长序列相似片段，再进行局部匹配</strong></li><li>方法二：同样基于RNN，预处理，为长度设置不同给的阈值，然后分别进行预测，但是这样会导致长度长的数据集效率低下，依旧是根本性。</li></ul></li><li><p>加入时间戳或者其它属性来提高预测精度</p><ul><li>主要正对的是attention，本身attention机制对于长序列有较好的预测效果，考虑通过加入时间戳或其它属性来提高预测精度，这块由于比较新，目前我看的论文中没有提到加入其它属性。</li><li>虽然attention在长序列的预测中效率较高，但是由于其机制的根本原因，他不对顺序进行记录，最近看的论文中提到的位置记录模块是通过将位置编码加入到嵌入向量中，考虑是否有其它方法来处理解决顺序预测。</li></ul></li></ol><p><strong>老师，如果对这块有其它好的建议，请给我说哈</strong></p><h2 id="构建论文使用技术框架"><a href="#构建论文使用技术框架" class="headerlink" title="构建论文使用技术框架"></a>构建论文使用技术框架</h2><ol><li>Input data</li></ol><p>这里涉及的主要是日志处理，去除无用信息，根据需求对日志进行分组。<i class="fas fa-tags"></i>这一步很重要，公用数据集给的数据集包函的属性较多也包含一些错误的事件日志，需要在预处理时去除掉，这样才能获得准确的比对权重。<br>2. Predictions type</p><p> 现在还是主要<strong>预测下一个活动</strong>，但是很多论文中会加入其它预测任务，其他预测任务作为辅助任务，可能有助于提高预测性能。<br>唯一的例外是剩余的时间预测问题，因为它可以作为一个直接的预测。</p><ol start="3"><li>Neural Network Type</li></ol><p>LSTM ，Bidirectional LSTM ，包括最近的Transformers都会考虑，尤其LSTM会作为baseline作为对比对象。</p><ol start="4"><li>Sequence encoding</li></ol><p>神经网络都是以固定大小的张量编码方式输入，但是流程序列明显长短不一，所以需要对于输入数据进行规范化。</p><pre><code> 最常用的编码是连续编码和前缀填充编码，因为它们非常通用，可以同时用于cnn和rnn。连续编码和前缀填充编码都是通过填0的方式，使不同长度的序列达到相同的长度。其中又比较了N-gram编码，类似于hash算法将不同长度的序列转化为相同长度的hash值，但是目前只用于自动编码器中，LSTM和Transformer还没有用过，不知道适不适合。TODO：检查N-gram的适用性。</code></pre><ol start="5"><li>Event encoding</li></ol><p>这里主要比较了one-hot和嵌入编码，考虑到日中中流程种类，事件种类较多，而且很多paper验证了嵌入编码是目前预测任务中表现最优的事件编码方式，所以选择了嵌入编码。<br>  6. 数据集</p><p>TODO<br>  7. 验证指标</p><p>TODO<br>  8. 实验</p><p>TODO</p><h2 id="相关算法"><a href="#相关算法" class="headerlink" title="相关算法"></a>相关算法</h2><p>刚开始准备查序列比对的算法，但是目前深度学习中几乎不会用到这种算法，一般只有机器学习中才会用到，当时看的是一个KMP算法；后面考虑到是预处理时，对于长序列进行分段，或者将长序列相似部分进行标记，不会学习预测重复序列，那么这里涉及的是序列查找相似片段相关的算法。所以下一步准备找这些算法。</p><p>如果老师有了解或者看见过相关的算法，请给我推荐一下，我现在也是盲看，这块在预测中没人提出来，所以没有相关算法的介绍，我不知道他们没有提出这种思路是因为这种思路对于精确度的提升没有效果还是有其它原因，但是我看到有的paper中确实对长序列精确度进行了比较，所以感觉可以研究。</p><h2 id="搭建实验室论坛"><a href="#搭建实验室论坛" class="headerlink" title="搭建实验室论坛"></a>搭建实验室论坛</h2><p>局域网内依旧搭建完成了，只需要在公司后台进行nginx配发就可以在公共网络访问了，周一进行尝试后发现失败，然后他们运维在忙，就没弄域名了。</p><h1 id="下周安排"><a href="#下周安排" class="headerlink" title="下周安排"></a>下周安排</h1><ol><li>对于长序列预测的论文进行总结，比较他人的处理方式和优缺点</li><li>对数据集进行初步挖掘，查看长的日志是否与自己理解相似，即长的原因为重复事件较多</li><li>继续查看相关算法</li><li>了解N-gram是否适合于RNN模式</li></ol>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-8-1【周总结】</title>
      <link href="/2021/08/03/2021-8-1%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/08/03/2021-8-1%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h1 id="本周安排"><a href="#本周安排" class="headerlink" title="本周安排"></a>本周安排</h1><ul><li><input checked="" disabled="" type="checkbox"> 分析理解LSTM框架</li><li><input checked="" disabled="" type="checkbox"> 阅读的相关论文</li><li><input disabled="" type="checkbox"> 构建环境，复现一个论文中的代码</li><li><input disabled="" type="checkbox"> 了解项目中神经网络的应用</li></ul><h1 id="完成情况"><a href="#完成情况" class="headerlink" title="完成情况"></a>完成情况</h1><h2 id="对于LSTM的框架进行了简单的理解"><a href="#对于LSTM的框架进行了简单的理解" class="headerlink" title="对于LSTM的框架进行了简单的理解"></a>对于LSTM的框架进行了简单的理解</h2><p><img src="./attachments/Long_Short_Term_Memory_Networks.pdf" alt="Long Short Term Memory Networks"></p><h2 id="精度《基于LSTM神经网络的业务过程预测》"><a href="#精度《基于LSTM神经网络的业务过程预测》" class="headerlink" title="精度《基于LSTM神经网络的业务过程预测》"></a>精度《基于LSTM神经网络的业务过程预测》</h2><p> 这一篇主要是对于事件和时间戳的预测 <img src="./attachments/%E5%9F%BA%E4%BA%8ELSTM%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%BF%87%E7%A8%8B%E9%A2%84%E6%B5%8B%E7%9B%91%E6%8E%A7.pdf" alt="基于LSTM神经网络的业务过程预测监控"> 基本上理解了作者意图和操作，但是我没法理解LSTM层如何学习数据</p><h2 id="略读了几篇论文，试图理解LSTM的运行逻辑"><a href="#略读了几篇论文，试图理解LSTM的运行逻辑" class="headerlink" title="略读了几篇论文，试图理解LSTM的运行逻辑"></a>略读了几篇论文，试图理解LSTM的运行逻辑</h2><ol><li>使用LSTM对于事件类型较少的序列进行迭代循环预测，使用的是one-hot编码将事件类型，事件戳映射到向量特征向量，并使用事件发生的时间特征对其进行补充。<strong>缺点</strong>是当事件类型较多的时候，该方法效果会变差。</li></ol><ul><li>该模型由共享LSTM层构成，其中包括一个专门用于预测事件的LSTM和一个预测事件的LSTM</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021730/1627633758272.png" alt="2017-使用LSTM神经网络进行预测性业务流程监控"></p><ol start="2"><li>使用嵌入维度的LSTMs，可以减少输入长度和增加新的特征。<strong>缺点</strong>是依旧无法处理数值变量，所以也不能预测时间戳。<strong>优点</strong>是可以处理大量事件类型。</li></ol><ul><li>使用两层LSTMs隐藏层。</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021730/1627636620079.png" alt="2017-利用深度学习预测过程行为"></p><ol start="3"><li>使用多阶段深度学习的方法来预测下一个事件。<strong>缺点</strong>是无法处理数值变量，所以也不能预测时间戳。</li></ol><ul><li>首先是将每个事件映射到特征向量</li><li>下一步使用transformations降低输入维度，通常有，通过提取n-gram、使用hash、将输入通过两个自动编码层等方法</li><li>将转化后的输入传给负责预测的前馈神经网络</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202182/1627887742568.png" alt="业务流程事件预测的多阶段深度学习方法"></p><p><strong>总结</strong><br>在阅读了几篇类似的paper后，对于LSTM在其中的作用理解加深，但是每一篇文章的重点或者内容侧重点更多是在数据处理上，而LSTM只是作为个较为优秀的神经网络结构。通过略看论文，感觉这可能就是发论文的方式哇。最后我在理解了LSTM网络层的基本原理后不在纠结于它在实际中的运行原理，也把它理解成一个模块了。</p><h2 id="复现精度论文的代码"><a href="#复现精度论文的代码" class="headerlink" title="复现精度论文的代码"></a>复现精度论文的代码</h2><p>失败了，可能是第一次复现深度学习的项目的原因吧，没有经验，每一步都有错误，整整三天晚上都在调试，错误是解决了不少，但是还是效率太低了，所以决定找个简单的入门，先使用一下LSTM再说。</p><p><strong>一个简单的情感分析</strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202183/1627997675435.png" alt="数据"><br>只是简单的使用LSTM所以用最简单矩阵数据</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202183/1627997947288.png" alt="结果"><br>每个epoch为10，进行语义训练，这次训练数据极度拟合，所以结果没有参考价值，主要是熟悉LSTM的使用。</p><h1 id="下周安排"><a href="#下周安排" class="headerlink" title="下周安排"></a>下周安排</h1><ul><li><input disabled="" type="checkbox"> 再挑一篇新的顶刊论文进行精读</li><li><input disabled="" type="checkbox"> 略读几篇LSTM，Attention</li><li><input disabled="" type="checkbox"> 跑一个简单的Attention框架的代码，考虑一下最后研究是使用那个网络结构</li></ul>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>业务流程的LSTM精准模型</title>
      <link href="/2021/07/29/%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%9A%84LSTM%E7%B2%BE%E5%87%86%E6%A8%A1%E5%9E%8B/"/>
      <url>/2021/07/29/%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%9A%84LSTM%E7%B2%BE%E5%87%86%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>使用LSTM模型对事件下一步，时间戳和调用的资源进行预测。</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>本文主要是对于前人提出在LSTM中利用近似前缀预测—<a href="https://blog.zuishuailcq.xyz/2021/07/19/%E5%9F%BA%E4%BA%8ELSTM%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%BF%87%E7%A8%8B%E9%A2%84%E6%B5%8B%E7%9B%91%E6%8E%A7/">基于LSTM神经网络的业务过程预测监控 | 吾辈之人，自当自强不息！</a>的缺陷的改进，缺陷：</p><ol><li>无法处理数字变量</li><li>不能生成带有时间戳的时间序列</li><li>后续有文章提出通过one-hot编码来对事件进行分类，而不是使用嵌入维度来实现的，这样<strong>随着事件类型的增加，精度就会极度下降</strong>。</li></ol><blockquote><p>知识补充<br>后处理：在模型训练后，人为的修改模型结果使之预测结果更加符合真实情况。<br><a href="https://blog.csdn.net/xieyan0811/article/details/80549001">数据挖掘之_后处理_谢彦的技术博客-CSDN博客_数据后处理</a></p></blockquote><dl><dt><strong><font color="#006400">解决：</font></strong><br>本文通过提出用于建立新的预处理和后处理方法和架构以及使用LSTM神经网络的事件日志的生成模型来解决上述方法的局限性。</dt><dd>具体地说，本文提出了一种方法去学习模型，该方法可以生成由三组(事件类型、角色、时间戳)组成的轨迹(或从给定前缀开始的轨迹的后缀)。提出的方法结合了Tax等人[13]和Evermann等人[2]的优点，<font color="#483D8B">通过使用嵌入维度，同时支持事件日志中的分类属性和数字属性</font>。本文考虑了神经网络中共享层和特有层的不同组合所对应的三种体系结构。</dd></dl><p><strong><font color="#FF8C00">评估：</font></strong></p><ol><li>第一种方法比较了与不同体系结构、预处理和后处理选择相对应的所提出方法的备选实例。该评估的目的是<font color="#00008B">根据获取到的日志的特征</font>，得出关于哪些设计选择更可取的指南。</li><li>比较提出方法在上面三条约束的表现。</li></ol><h1 id="技术背景"><a href="#技术背景" class="headerlink" title="技术背景"></a>技术背景</h1><h2 id="LSTM-当前的进展"><a href="#LSTM-当前的进展" class="headerlink" title="LSTM 当前的进展"></a>LSTM 当前的进展</h2><ol><li>使用LSTM对于事件类型较少的序列进行迭代循环预测，使用的是one-hot编码将事件类型，事件戳映射到向量特征向量，并使用事件发生的时间特征对其进行补充。<strong>缺点</strong>是当事件类型较多的时候，该方法效果会变差。</li></ol><ul><li>该模型由共享LSTM层构成，其中包括一个专门用于预测事件的LSTM和一个预测事件的LSTM</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021730/1627633758272.png" alt="2017-使用LSTM神经网络进行预测性业务流程监控"></p><ol start="2"><li>使用嵌入维度的LSTMs，可以减少输入长度和增加新的特征。<strong>缺点</strong>是依旧无法处理数值变量，所以也不能预测时间戳。<strong>优点</strong>是可以处理大量事件类型。</li></ol><ul><li>使用两层LSTMs隐藏层。</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021730/1627636620079.png" alt="2017-利用深度学习预测过程行为"></p><ol start="3"><li>提出基于RNN的模型MM-Pred来预测下一步事件和流程后续。<strong>缺点</strong>是无法处理数值变量，所以也不能预测时间戳。</li></ol><ul><li>这种方法同时使用控制流信息（事件类型）和案例数据（事件属性）。</li><li>该结构由编码器、调制器和解码器组成。</li><li>编码器和解码器使用LSTM网络将每个事件的属性转换为隐藏表示或从隐藏表示转换为隐藏表示。</li><li>调制器组件求出可变长度序列比对权重向量，其中每个权重表示用于预测未来事件和属性的属性的相关性。</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202182/1627873762436.png" alt="多属性事件序列的深度预测模型"></p><ol start="4"><li>使用多阶段深度学习的方法来预测下一个事件。<strong>缺点</strong>是无法处理数值变量，所以也不能预测时间戳。</li></ol><ul><li>首先是将每个事件映射到特征向量</li><li>下一步使用transformations降低输入维度，通常有，通过提取n-gram、使用hash、将输入通过两个自动编码层等方法</li><li>将转化后的输入传给负责预测的前馈神经网络</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202182/1627887742568.png" alt="业务流程事件预测的多阶段深度学习方法"></p><ol start="5"><li>作者提出一种基于GRU的神经网络架构BINet，用于业务流程执行中的实时异常检测。该架构用于预测下一个事件及属性。</li></ol><ul><li>该方法旨在为跟踪中的每个事件分配一个似然分数，然后用于检测异常。这种方法表明，过程行为的生成模型也可用于异常检测。</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202182/1627907436804.png" alt="基于深度学习的多元业务流程异常检测"></p><ol start="6"><li>作者比较几种真实数据集在MMs，all-k MMs以及基于自动机的模型中预测下一步的准确性和性能。</li></ol><ul><li>结果表明，AKOM模型具有最高的精度（在某些情况下优于RNN体系结构），而基于自动机的模型具有较高的可解释性。</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202182/1627907971849.png" alt="下一个元素预测序列建模方法的跨学科比较"></p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628666548975.png" alt="构建模型的步骤"></p><h2 id="预处理阶段"><a href="#预处理阶段" class="headerlink" title="预处理阶段"></a>预处理阶段</h2><h3 id="Data-transformation"><a href="#Data-transformation" class="headerlink" title="Data transformation"></a>Data transformation</h3><p><strong>根据属性性质（分类或连续）进行特定预处理。</strong></p><p><strong><font color="#294B71">分类：</font></strong></p><p>处理数据：将事件和资源作为类别属性，使用嵌入维度。</p><blockquote><p>向训练网络提供属性之间关联的正面和负面示例，使网络能够识别和定位具有相似特征的近似属性。根据NLP社区4中使用的一项通用建议，嵌入维度的数量被确定为类别数量的第四根，以避免它们之间可能发生冲突。生成的值作为不可训练的参数导出并在所有实验中重用，这样就不会增加模型的复杂性</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628683817654.png" alt="用于训练嵌入层的网络结构和生成的4d空间被缩减为3d的空间"></p><p> <strong><font color="#E9967A">连续：</font></strong></p><p><font color="#1E90FF"> 对数据进行归一化，以供预测模型解释</font>。这里处理的事件之间的相对时间，问题在于不同日志，相对时间可能具有很大的可变性。 这种高可变性可以隐藏有关过程行为的有用信息，例如时间瓶颈或异常行为，如果不小心执行属性缩放，则可以隐藏这些信息。</p><p> 寻求一种合适的缩放方法。</p><p> <img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628685428211.png" alt="最大值和对数归一化两种方法的对比"></p><h3 id="Sequences-creation"><a href="#Sequences-creation" class="headerlink" title="Sequences creation"></a>Sequences creation</h3><p> <strong>提取每个事件日志跟踪的固定大小的n-gram，以创建输入序列和预期事件来训练预测网络。</strong></p><p> <img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628686156534.png" alt="从BPI 2012事件日志的案例id 174770中提取的五个n-gram"></p><p> <em>role表示的是事件与资源的关联</em></p><h2 id="Model-Structure-Definition-Phase"><a href="#Model-Structure-Definition-Phase" class="headerlink" title="Model Structure Definition Phase"></a>Model Structure Definition Phase</h2><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628686308297.png" alt="Baseline architecture"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628687598994.png" alt="Tested architectures"></p><h2 id="Post-processing-Phase"><a href="#Post-processing-Phase" class="headerlink" title="Post-processing Phase"></a>Post-processing Phase</h2><p>从零前缀开始生成业务流程的完整跟踪中，传统使用的是arg max，直接根据下一个事件的最大概率来跟踪，但是这就会所有追踪的事件都倾向于概率最大值，对于低概率发生的事件无法追踪。这里作者使用的是arg max和随机选择的参数作为下一个事件的选择。</p><blockquote><p>我觉得应该使用softmax</p></blockquote><h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><blockquote><p>本节描述了两个实验评估。第一个实验比较了三种架构在前处理和后处理选择方面的不同实例。第二个实验将提出的方法与技术背景中其它论文中的下一个事件、后缀和剩余时间预测任务的三条基线进行比较</p></blockquote><h2 id="Data-Set"><a href="#Data-Set" class="headerlink" title="Data Set"></a>Data Set</h2><pre><code>在本实验中，使用了九个来自不同领域、具有不同特征的真实事件日志</code></pre><ul><li>Helpdesk5事件日志包含来自意大利软件公司helpdesk票务管理过程的记录</li><li>BPI 20126 中的两个事件日志与来自德国金融机构的贷款申请流程相关。 这个过程由三个子过程组成，我们从中使用了 W 子过程，以便与”下一个元素预测序列建模方法的跨学科比较”进行比较 。</li><li>BPI 20137中的事件日志与沃尔沃的IT事件和问题管理有关。我们使用完整的案例学习生成模型</li><li>BPI 20158中的五个事件日志包含五个荷兰城市在四年期间提供的建筑许可证申请数据。原始事件日志分为五个部分（每个市政局一个）。所有事件日志都在子流程级别指定，包括345多个活动。因此，按照”Diagnostics of building per-mit application process in dutch municipalities”中所述的步骤对其进行预处理，以便在阶段级别进行管理</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628688257014.png" alt="Event logs description"></p><ol><li><em><font color="#A9A9A9">SF指根据其在记录道数量、事件、活动和序列长度方面的组成分为简单、中等和复杂。</font></em></li><li><em><font color="#A9A9A9">TV指据每个事件日志的平均持续时间和最大持续时间之间的关系，将时间变异性（TV）分为稳定或可变</font></em></li></ol><h2 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h2><p><strong><font color="#8A2BE2">目的：</font></strong><br>    使用 LSTM 模型从大小为0的前缀开始跟踪生成完整的事件日志，然后将生成的跟踪与原始日志中的流程进行比较。</p><p><font color="#1E90FF">方法：使用两个指标来评估生成的事件日志的相似性。</font></p><ol><li>Demerau-Levinstain（DL）算法根据一个字符串与另一个字符串相等所需的版本数测量序列之间的距离。该算法在每次执行插入、删除、替换和转置等操作时都进行惩罚。因此，我们使用其倒数来衡量生成的活动或角色序列与实际事件日志中观察到的序列之间的相似性。然后，较高的值意味着序列之间的相似性较高。</li><li>平均绝对误差（MAE）度量用于测量预测时间戳的误差。通过取观测值和预测值之间距离的绝对值，然后计算这些震级的平均值来计算该测量值。我们使用该度量来评估每对（生成轨迹、地面真值轨迹）的生成相对时间和观测时间之间的距离。</li></ol><blockquote><p>使用交叉验证，将事件日志分为两部分：70%用于培训，30%用于验证。第一个折叠被用作训练2000个模型的输入（每个事件日志大约220个模型）。<br>这平均220个模型配置了不同的预处理技术和体系结构。配置值是从972个组合的完整搜索空间中随机选择的。然后，使用每个经过培训的模型生成完整事件的新事件日志（参见第3节中描述的选择下一个活动的技术）。生成了每个配置的15个日志，并对其结果进行了平均。评估了32000多个生成的事件日志。</p></blockquote><h2 id="Results-and-Interpretation"><a href="#Results-and-Interpretation" class="headerlink" title="Results and Interpretation."></a>Results and Interpretation.</h2><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628689342024.png" alt="不同配置的事件日志中的相似性结果"></p><ul><li><font color="#A9A9A9">MAE列对应于预测记录道周期时间的平均绝对误差</font> </li></ul><p>结果表明，使用这种方法可以训练学习并可靠地再现原始日志的观察行为模式的模型。此外，研究结果表明，对于LSTM模型来说， <strong><font color="#A52A2A">学习词汇量较大</font></strong> 的序列比学习较长的序列更困难。要了解这些模式，需要更多的示例，如BPI2012和BPI2015的结果所示。这两个日志都有30多个活动，但在跟踪数量上有很大差异（见表2）。BPI2012的高度相似性还表明，使用嵌入维度处理大量事件类型可以改善结果，只要示例数量足以学习底层模式。</p><p>针对本实验中评估的模型结构构件，我们按照预处理、模型结构和超参数选择以及预测等阶段对其进行分析，以构建生成模型。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628689921162.png" alt="Preprocessing phase components comparison"></p><p><strong><font color="#FF8C00">这里主要比较的是对于相对时间缩放方式，和进行缩放的作用。</font></strong></p><ol><li>a 说明了如何使用最大值作为缩放技术，具有很小时间变化的日志呈现更好的结果。相比之下，具有不规则结构的日志使用对数归一化具有较低的<font color="#0000FF"> MAE</font>【横坐标】。</li><li>b 展示了使用不同大小的 n-gram 时的 DL 相似性结果，与事件日志的结构有关。 我们可以观察到，使用更长的n-grams对于trace更长的日志有更好的结果，呈现出稳定的增长趋势。 相比之下，中、简单结构的事件日志趋势不明显。 因此，应将长 n-gram 的使用保留给具有很长跟踪的日志。**<font color="#006400">这里体现的是n-gram size对于预测结果的作用，只有复杂的日志呈现良好的正相关。</font>**</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628690528922.png" alt="共享层的总体相似性"></p><p>关于模型结构定义阶段，图说明连接结构的总体相似度最低。相比之下，仅在分类属性之间共享信息的模型体系结构具有中等最佳性能。然而，它与专门的体系结构并不遥远，尽管它的分布范围更广。这意味着在不同性质的属性之间共享信息会在网络正在处理的模式中产生噪声，从而阻碍学习过程。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628690699173.png" alt="下一个事件选择方法的比较"></p><p>关于预测阶段，图显示了随机选择在所有事件日志中如何优于arg max。这种行为在具有较长和复杂跟踪的事件日志中更为明显。结果表明，无论事件日志结构如何，随机选择都是评估学习过程的可取方法。</p><h2 id="Comparison-Against-Baselines"><a href="#Comparison-Against-Baselines" class="headerlink" title="Comparison Against Baselines"></a>Comparison Against Baselines</h2><h3 id="Experimental-setup-1"><a href="#Experimental-setup-1" class="headerlink" title="Experimental setup"></a>Experimental setup</h3><p><strong><font color="#FF00FF">目的：</font></strong><br>    评估我们的方法在预测下一个事件、剩余事件序列（即后缀）和剩余时间（对于不同长度的跟踪前缀）方面的相对性能。</p><ol><li>next event prediction — 为每个模型提供长度增加的跟踪前缀，从 1 到每个跟踪的长度。 对于每个前缀，我们预测下一个事件并测量准确性（正确预测的百分比）。</li><li> suffix and remaining time prediction — 为模型提供了长度增加的前缀，直到案件结束。</li></ol><p><strong><font color="#8A2BE2">baselines:</font></strong></p><ul><li>next event and suffix prediction</li></ul><ol><li> Predictive business process monitoring with LSTM neural networks</li><li> Predicting process behaviour using deep learning</li><li> A deep predictive model for multi-attribute event sequence</li></ol><ul><li>remaining time prediction</li></ul><ol><li>Predictive business process monitoring with LSTM neural networks【Helpdesk, BPI2012W and BPI2012 event logs】</li></ol><h3 id="Results-and-Interpretation-1"><a href="#Results-and-Interpretation-1" class="headerlink" title="Results and Interpretation"></a>Results and Interpretation</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628691394455.png" alt="下一个事件和后缀预测结果"></p><p><strong>这些结果表明，分类属性的维度控制所采用的措施，使我们的方法即使在长序列中也能获得始终如一的良好性能。</strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021811/1628691420458.png" alt="剩余循环时间MAE的结果（以天为单位）"></p><p>图10显示了剩余循环时间预测的MAE。尽管我们的技术目标不是预测剩余时间，但与Tax等人相比，它在这项任务中实现了类似的性能——在一个日志中略逊于它，在另一个日志中略逊于它的长前缀。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p><strong><font color="#FF8C00">优</font></strong></p><ol><li>评估表明，使用更长的n-gram可获得更高的精度</li><li>对数归一化是适用于高可变性测井的缩放方法，与总是选择最有可能的下一个事件相比，使用LSTM产生的概率随机选择下一个事件可导致更广泛的记录道和更高的精度。论文还表明，该方法在预测剩余事件序列及其从给定跟踪前缀开始的时间戳方面优于现有的基于LSTM的方法</li></ol><blockquote><p>作者预计，所提出的方法可以作为业务流程模拟的工具。实际上，从本质上讲，流程模拟器是一种通用模型，它生成由事件类型、资源和时间戳组成的跟踪集，并从中计算性能度量，如等待时间、循环时间和资源利用率。虽然流程模拟器依赖于可解释的流程模型（例如BPMN模型），但原则上可以使用能够生成事件跟踪的任何模型来模拟流程，其中每个事件都由事件类型（活动标签）、时间戳和资源组成。使用LSTM网络进行流程模拟的一个关键挑战是如何捕获“假设”场景（例如，删除任务或删除资源的效果）。</p></blockquote><p><strong><font color="#2F4F4F">future</font></strong><br>计划应用技术，使用”An eye into the future: Leveraging a-priori knowledge in predictive business process monitoring.”中的约束，从LSTM模型生成事件序列</p>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> paper </tag>
            
            <tag> process mining </tag>
            
            <tag> deep learning </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Long Short Term Memory Networks</title>
      <link href="/2021/07/19/Long%20Short%20Term%20Memory%20Networks/"/>
      <url>/2021/07/19/Long%20Short%20Term%20Memory%20Networks/</url>
      
        <content type="html"><![CDATA[<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1842025914&auto=1&height=66"></iframe><p><a href="https://zhuanlan.zhihu.com/p/32085405">人人都能看懂的LSTM - 知乎</a><br><a href="https://zhuanlan.zhihu.com/p/37644325">RNN、LSTM、GRU基础原理篇 - 知乎</a><br><a href="https://blog.csdn.net/matrix_space/article/details/53374040">机器学习：深入理解 LSTM 网络 (一)_Matrix-11-CSDN博客_lstm 机器学习</a></p><blockquote><p>中文分词、词性标注、命名实体识别、机器翻译、语音识别都属于序列挖掘的范畴。<font color="#DC143C">序列挖掘</font>的特点就是某一步的输出不仅依赖于这一步的输入，还依赖于其他步的输入或输出。在序列挖掘领域传统的机器学习方法有HMM（Hidden Markov Model，隐马尔可夫模型）和CRF（Conditional Random Field，条件随机场），近年来流行深度学习算法RNN（Recurrent Neural Networks，循环神经网络）。</p></blockquote><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626698381786.png" alt="RNN网络架构图"></p><p>比如一个句子中有5个词，要给这5个词标注词性，那相应的RNN就是个5层的神经网络，每一层的输入是一个词，每一层的输出是这个词的词性。<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626698589144.png" alt="讲解"></p><h1 id="RNN的变体"><a href="#RNN的变体" class="headerlink" title="RNN的变体"></a>RNN的变体</h1><h2 id="双向RNN"><a href="#双向RNN" class="headerlink" title="双向RNN"></a>双向RNN</h2><p>双向RNN认为otot不仅依赖于序列之前的元素，也跟tt之后的元素有关，这在序列挖掘中也是很常见的事实。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626698749683.png" alt=" Bidirectional RNNs网络结构"></p><h2 id="深层双向RNN"><a href="#深层双向RNN" class="headerlink" title="深层双向RNN"></a>深层双向RNN</h2><p>在双向RNN的基础上，每一步由原来的一个隐藏层变成了多个隐藏层。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626698820535.png" alt="Deep Bidirectional RNNs网络结构"></p><h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><p>前文提到，由于<font color="#9932CC"><strong>梯度消失/梯度爆炸</strong></font>的问题传统RNN在实际中很难处理长期依赖，而LSTM（Long Short Term Memory）则绕开了这些问题依然可以从语料中学习到长期依赖关系。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626699453120.png" alt="传统RNN每一步的隐藏单元只是执行一个简单的tanh或ReLU操作"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626699501199.png" alt=" LSTM每个循环的模块内又有4层结构:3个sigmoid层，1个tanh层"></p><p><strong><font color="#D2691E">解释LSTM模块：</font></strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626699615537.png" alt="图标说明"></p><ul><li>粉色的圆圈表示一个二目运算。</li><li>两个箭头汇合成一个箭头表示2个向量首尾相连拼接在一起。</li><li>一个箭头分叉成2个箭头表示一个数据被复制成2份，分发到不同的地方去。</li></ul><p> LSTM的关键是细胞状态C，一条水平线贯穿于图形的上方，这条线上只有些少量的线性操作，信息在上面流传很容易保持。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626699717681.png" alt="忘记层"></p><ol><li>忘记层，决定细胞状态中<strong>丢弃什么信息</strong>。把ht−1和xt拼接起来，传给一个sigmoid函数，该函数输出0到1之间的值，这个值乘到细胞状态Ct−1上去。<font color="#FF8C00">sigmoid函数的输出值直接决定了状态信息保留多少</font>。比如当我们要预测下一个词是什么时，细胞状态可能包含当前主语的性别，因此正确的代词可以被选择出来。当我们看到新的主语，我们希望忘记旧的主语。</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626700419154.png" alt="更新细胞状态"><br>2. 上一步的细胞状态Ct−1已经被忘记了一部分，接下来本步应该把哪些信息新加到细胞状态中呢？这里又包含2层：一个tanh层用来产生更新值的候选项C~t，tanh的输出在[-1,1]上，<strong>说明细胞状态在某些维度上需要加强，在某些维度上需要减弱</strong>；还有一个sigmoid层（输入门层），它的输出值要乘到tanh层的输出上，起到一个<strong>缩放</strong>的作用，<em>极端情况下sigmoid输出0说明相应维度上的细胞状态不需要更新</em>。在那个预测下一个词的例子中，我们希望增加新的主语的性别到细胞状态中，来替代旧的需要忘记的主语。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626700649763.png" alt="生成新的细胞状态"><br>3. 现在可以让旧的细胞状态Ct−1与ft（f是forget忘记门的意思）相乘来丢弃一部分信息，然后再加个需要更新的部分it∗C~t（i是input输入门的意思），这就生成了<strong>新的细胞状态Ct</strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626700735024.png" alt="循环模块的输出"><br>4. 最后该决定输出什么了。输出值跟细胞状态有关，把Ct输给一个tanh函数得到输出值的候选项。<strong>候选项中的哪些部分最终会被输出由一个sigmoid层来决定</strong>。在那个预测下一个词的例子中，如果细胞状态告诉我们当前代词是第三人称，那我们就可以预测下一词可能是一个第三人称的动词。</p><h1 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h1><p>GRU（Gated Recurrent Unit）是LSTM最流行的一个变体，比LSTM模型要简单。没有了存储单元</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021719/1626700963311.png" alt="GRU"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>RNN 结构的一个吸引人之处在于其可以利用之前的输入信息。但是一个关键的需要解决的问题是当前的信息与之前的信息的关联度有长有短。<br>LSTM的内部结构。通过门控状态来控制传输状态，<strong>记住需要长时间记忆的，忘记不重要的信息</strong>；而不像普通的RNN那样只能够“呆萌”地仅有一种记忆叠加方式。对很多需要“长期记忆”的任务来说，尤其好用。、<br>但也因为引入了很多内容，导致参数变多，也使得训练难度加大了很多。因此很多时候我们往往会使用效果和LSTM相当但参数更少的GRU来构建大训练量的模型。</p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> process mining </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于LSTM神经网络的业务过程预测监控</title>
      <link href="/2021/07/19/%E5%9F%BA%E4%BA%8ELSTM%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%BF%87%E7%A8%8B%E9%A2%84%E6%B5%8B%E7%9B%91%E6%8E%A7/"/>
      <url>/2021/07/19/%E5%9F%BA%E4%BA%8ELSTM%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%BF%87%E7%A8%8B%E9%A2%84%E6%B5%8B%E7%9B%91%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.youtube.com/watch?v=VAPwMDAm550&list=RDVAPwMDAm550&start_radio=1" title="我還年輕 我還年輕"><img src="https://res.cloudinary.com/marcomontalbano/image/upload/v1626681958/video_to_markdown/images/youtube--VAPwMDAm550-c05b58ac6eb4c4700831b2b3070cd403.jpg" alt="我還年輕 我還年輕"></a></p><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本文研究了长-短期记忆（LSTM）神经网络作为一种预测模型。并证明LSTMs在预测运行案例的下一个事件及其时间戳方面优于现有的技术。</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>作者提到他的目的是提出一个可以适用的框架。本文的研究点：</p><ol><li>LSTMs能否被用于广泛的流程预测，以及如何应用？</li><li>如何保障LSTM在不同数据中的准确度始终如一？</li></ol><p>在不同预测内容中，作者适用了4个日志数据集进行验证比较。</p><h1 id="相关技术"><a href="#相关技术" class="headerlink" title="相关技术"></a>相关技术</h1><p>主要讲的是目前对于三种预测的技术，包括了，时间相关预测、事件结果的预测、正在执行事件的预测</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><ul><li>数据集A</li><li>数据集A中所有序列 $A^{*}$</li><li>一个长度为n的序列 σ =&lt;  $a_{1}$ ,  $a_{2}$ ,  $a_{3}$ , …… ,  $a_{n}$  &gt;,空序列为&lt;&gt;</li><li>$σ_ { 1 } \cdot σ _ { 2 }$ 表示序列 $σ_{1}$ 与 $σ_{2}$ 的串联</li><li> $h d ^ { k } ( o ) = ( a _ { 1 } , a _ { 2 } , \cdots , a _ { k } )$ 为<strong>前缀长度</strong>为k（0&lt;k&lt;n） 的序列 σ的<strong>前缀</strong>。 $t l ^ { k } ( o ) = ( a _ { k + 1 } \cdots , a _ { n } )$ 是它的后缀。</li></ul><p>对于前缀后缀的一个<strong>栗子</strong>：<br>序列： $σ _ { 1 } = ( a , b , c , d , e )$<br>前缀长度为二的前缀： $h d ^ { 2 } ( σ _ { 1 } ) = ( a , b )$<br>后缀为： $t l ^ { 2 } ( σ _ { 1 } ) = ( c , d , e )$</p><ul><li> $\varepsilon$ 【伊普西隆】为所有事件集合，T为时域。</li><li> $\pi _{ \tau }\in \varepsilon  \rightarrow T$ 为事件分配事件戳</li><li> $\pi _{ A }\in \varepsilon  \rightarrow A$ 从事件集A种为一个流程分配活动<h2 id="RNN和LSTM"><a href="#RNN和LSTM" class="headerlink" title="RNN和LSTM"></a>RNN和LSTM</h2></li></ul><p><a href="https://blog.zuishuailcq.xyz/2021/07/19/Long%20Short%20Term%20Memory%20Networks/">Long Short Term Memory Networks | 吾辈之人，自当自强不息！</a></p><h1 id="下一个活动和时间戳预测"><a href="#下一个活动和时间戳预测" class="headerlink" title="下一个活动和时间戳预测"></a>下一个活动和时间戳预测</h1><p>介绍评估多种体系结构预测下一个事件和时间戳。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021728/1627442124718.png" alt="事件预测算法"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021728/1627442195597.png" alt="事件预测算法"></p><p>输入一个事件的前缀，然后预测下一个事件。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><blockquote><p><strong><font color="#D2691E">知识补充</font></strong><br>one hot编码是将类别变量转换为机器学习算法易于利用的一种形式的过程。<br>假设“花”的特征可能的取值为daffodil（水仙）、lily（百合）、rose（玫瑰）。one hot编码将其转换为三个特征：is_daffodil、is_lily、is_rose，这些特征都是二进制的。<br><a href="https://zhuanlan.zhihu.com/p/37471802">什么是one hot编码？为什么要使用one hot编码？ - 知乎</a></p></blockquote><ol><li>首先为LSTM构建特征向量矩阵，作为输入。</li></ol><p>事件e=σ（i）的时间特征指的是在trace中的上一个时间和当前时间之间的时间。转换函数：<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021720/1626745464036.png" alt="enter description here"></p><p>三种时间特征：fvt1表示事件的当前时间特征【与上一个时间的时间间隔】，同时也添加了包函一天时间的特征fvt2和包含一周的时间特征fvt3.这样当事件在工作日或者工作周结束的时候预测下一个活动的事件中时间间隔则会更长。</p><ul><li>LSTM可以通过fvt1学到不同节点的事件宇时间差的依赖关系。</li><li>fvt2，fvt3的加入，是为处理有些有些事件超出了工作日的特殊情况，因为传统的日志处理中只记录工作日中的。</li></ul><ol start="2"><li>对时间步长k【第k个事件的时间】的输出 $o _ { a } ^ { k }$ 进行one-hot编码。</li></ol><p><font color="#6495ED">异常情况</font></p><ul><li>当在时间k为事件的结尾，既没有新的事件可以预测。 </li></ul><p><font color="#B22222"> <strong>解决</strong></font></p><ul><li>当在时间k结束时,给输出的one-hot编码向量增加额外标记值1 </li></ul><ol start="3"><li><p>设置第二个输出值 $o_{t}^{k}$ 为下一个时间间隔的 $fv_{t1}$ 值。当知道当前时间戳，就可以计算到下一个事件的时间戳。</p></li><li><p>使用Adam算法【梯度下降算法】进行神经网络权重优化</p></li></ol><p><strong><font color="#FF1493">如何优化：</font></strong></p><ul><li>最小化基础事件one-hot编码和被预测的下一个事件的one-hot编码的<font color="#0000FF">交叉熵</font>。</li><li>最小化事件和预测事件之间时间的<font color="#FF1493">平均误差</font>（MAE）</li></ul><h2 id="模型的构建"><a href="#模型的构建" class="headerlink" title="模型的构建"></a>模型的构建</h2><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021727/1627371341818.png" alt="单任务层神经网络结构"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021727/1627371437071.png" alt="共享多任务层神经网络结构"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021727/1627371484245.png" alt="n层共享，m层单任务混合神经网络结构"></p><ol><li>使用相同的数据特征，分别单独训练两个模型，一个是预测下一步事件，另一个是预测下一个时间戳，如图a</li><li>多任务学习可以在同一个神经网络结构学习到多个模型，例如图b，同一个LSTM神经网络结构学习输出两个模型。</li><li>混合模型</li></ol><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><ul><li>使用的循环神经网络依赖库Keras构建项目</li><li>硬件是NVidia Tesla k80 GPU，每次epoch时间为15-90s。其中预测时间时间戳是以毫秒为单位的。</li></ul><h2 id="实验准备"><a href="#实验准备" class="headerlink" title="实验准备"></a>实验准备</h2><h3 id="评定标准"><a href="#评定标准" class="headerlink" title="评定标准"></a>评定标准</h3><p>本文使用的<font color="#FF8C00">MAE</font>（平均绝对误差）来作为实验结果比较的参考。在实验效果评价这块，作者通过修改 van der Aalst提出的论文中用于预测剩余时间的模型来作为baseline。</p><h3 id="实验准备-1"><a href="#实验准备-1" class="headerlink" title="实验准备"></a>实验准备</h3><p>使用两个数据集进行预测下一个活动和时间戳。其中2/3的数据用于训练模型，1/3的用于预测。</p><p><i class="fas fa-tags" ></i>这里数据中长度为2的序列进行 $2 \leq k \lt | o |$ 预测，长度小于2则不对其预测。</p><p><strong><font color="#00008B">数据集</font></strong></p><ol><li>帮助中心数据集</li></ol><p>来自于意大利软件公司的票务管理系统，主要包括9中事件，一种事务流程。其中流程总共有3804条，事件有13710个。<br>2. BPI12子数据集W</p><p>此事件日志源自Business Process Intelligence Challenge（BPI’12）2，包含来自大型金融机构金融产品应用程序的数据。此流程由三个子流程组成：一个子流程跟踪应用程序的状态，一个子流程跟踪与应用程序关联的工作项的状态，第三个子流程跟踪报价的状态。在预测未来事件及其时间戳的上下文中，我们对自动执行的事件不感兴趣。因此，我们将评估范围缩小到工作项子流程，<font color="#FF8C00">其中包含手动执行的事件</font>。此外，我们过滤日志以<strong>仅保留complete类型的事件</strong>。</p><h2 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h2><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021727/1627377231055.png" alt="result，前缀为all表示所有前缀的平均值"><br>N表示神经元。MAE为当前配置不同前缀长度的性能。</p><p>表1显示了help desk和BPI’12w子流程日志上各种LSTM体系结构在MAE预测时间和预测下一事件准确性方面的性能。由于BPI12中的流程长度较长，所以前缀较长。</p><p>TODO 前缀不是很懂<br><font color="#7FFF00">分析：</font></p><ol><li>ALL LSTM体系结构在所有前缀上都优于baseline，同时分别比较LSTM模型和baseline模型，可以发现 <strong><font color="#FF00FF">短前缀的增益要比长前缀要好。</font></strong></li><li>数据集helpdesk的预测准确度最好为71%；BPI’12 W数据集预测的最佳精度为76%，高于Breuker等人报告的71.9%的精度和Evermann等人报告的62.3%的精度。</li><li>预测精度最高的模型都为混合模型，尝试将每层的神经元数量减少到75个，对于只有一个共享层的架构，将其增加到150个，但发现这会导致两个任务的性能下降。可能有75个神经元导致模型欠拟合，而150个神经元导致模型过拟合。我们还在单层架构上对传统RNN进行了实验，发现它们在时间和活动预测方面都比LSTM差得多。</li></ol><h1 id="后缀预测"><a href="#后缀预测" class="headerlink" title="后缀预测"></a>后缀预测</h1><blockquote><p><strong><font color="#ff7500">本章理解</font></strong><br>区别于上一节，上一章是单个时间步长预测下一步，而本章是预测一个运行案例的整个延续。</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021728/1627454393652.png" alt="事件预测"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021728/1627454420942.png" alt="时间预测"></p><h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p>通过迭代地预测下一个事件和时间戳，然后再次进行预测直至这个案例结束。这里用 $\perp$ 表示案例结尾。</p><p><strong><font color="#006400">迭代预测：</font></strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021728/1627455885003.png" alt="事件预测算法"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021728/1627456583245.png" alt="时间预测算法"></p><p><font color="#FF1493">当当前事件为END，则不进行预测；否则将预测的结果输入到预测模块迭代预测。</font></p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>对于预测准确度的评价这里采用的是通过计算预测结果与实际结果的编辑距离来衡量。</p><blockquote><p>知识补充：<font color="#2e4e7e">Levenshtein distance</font><br><a href="https://www.cnblogs.com/ivanyb/archive/2011/11/25/2263356.html">字符串相似度算法（编辑距离算法 Levenshtein Distance） - ZYB - 博客园</a></p></blockquote><p><strong>问题：</strong><br>  当处理并发任务的时候，Levenshtein distance并不适用于计算。例如&lt;a,b&gt;为预测的下一个事件，但实际上为&lt;b,a&gt;，这种情况只是因为ab并发顺序导致的，<font color="#DC143C">实际上并无相关</font>。但是Levenshtein distance结果为2,因为将预测序列转换为实际序列需要一次删除和一次插入操作。</p><p><strong>解决</strong><br>Damerau-Levenstein距离是一种更好地反映预测质量的评估度量，它为Levenshtein距离使用的操作集添加了交换操作。Damerau-Levenshtein距离将分配1的转换成本⟨a、 b⟩ 进入⟨b、 a⟩. 为了获得可变长度记录道的可比较结果，我们通过实际案例后缀长度和预测后缀长度的最大值对Damerau-Levenshtein距离进行归一化，归一化的Damerau-Levenshtein距离减1以获得Damerau-Levenshtein相似性（DLS）。</p><p><strong>模型</strong><br>采用的是双层架构，每层100个神经元的LSTM。</p><p><strong>数据集</strong><br>这是荷兰某市政当局环境许可程序的日志每宗个案涉及一份许可证申请。<br>该日志包含937个案例和381种事件类型的38944个事件。几乎每一种情况都遵循一个独特的路径，这使得后缀预测更具挑战性。</p><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021728/1627479266512.png" alt="基于Damerau-Levenshtein相似性的后缀预测结果"><br>Polato为baseline，no duplicates表示去掉案例中的重复事件，但是保留一个【案例结尾即使为重复事件也不去掉】。</p><p>观察可以发现所有数据集中的LSTM预测结果都要好于baseline。在BPI12数据集种很多案例中的事件会重复的出现，这就会导致预测的后缀长于真实案例，因此删除了BPI12中重复的事件并重新进行评估。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li>利用LSTM神经网络预测运行案例的下一个活动及其时间戳的技术。表明，这种技术在现实数据集上优于现有的基线。此外，我们发现通过单一模型（多任务学习）预测下一个活动及其时间戳比使用单独的模型进行预测具有更高的准确性。</li><li>提出了一个运行种的案例整个延续的预测和预测剩余的周期时间的解决方案。</li><li>发现了LSTM模型的局限性，**<font color="#9932CC">即在一个案例种某些事件多次重复出现时，导致后缀过长，性能就会很低</font>**。</li></ol>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> paper </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>损失函数之交叉熵(一般用于分类问题)</title>
      <link href="/2021/07/18/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B9%8B%E4%BA%A4%E5%8F%89%E7%86%B5(%E4%B8%80%E8%88%AC%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98)/"/>
      <url>/2021/07/18/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B9%8B%E4%BA%A4%E5%8F%89%E7%86%B5(%E4%B8%80%E8%88%AC%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98)/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.youtube.com/watch?v=i73Lh3h0DpQ" title="ONE HOUR"><img src="https://res.cloudinary.com/marcomontalbano/image/upload/v1626618085/video_to_markdown/images/youtube--i73Lh3h0DpQ-c05b58ac6eb4c4700831b2b3070cd403.jpg" alt="ONE HOUR"></a></p><p><a href="https://blog.csdn.net/u014453898/article/details/81559462">损失函数之交叉熵(一般用于分类问题)_ZJE-CSDN博客</a></p><h2 id="信息量、信息熵、相对熵"><a href="#信息量、信息熵、相对熵" class="headerlink" title="信息量、信息熵、相对熵"></a>信息量、信息熵、相对熵</h2><h3 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h3><p><font color="#FF8C00">一件事发生的概率越大，其蕴含的信息量就越少，反之，若发生的几率越小，则蕴含的信息量就越大</font>。</p><p>例如，“太阳从东方升起”：这件事发生概率极大，大家都习以为常，所以不觉得有什么不妥的地方，因此蕴含信息量很小。但“国足踢入世界杯”：这就蕴含的信息量很大了，因为这件事的发生概率很小。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626617713541.png" alt="信息量"></p><p>若某事x的发生概率为P(x)，则信息量的计算公式为：<br>$I ( x ) = - \log ( P ( x ) )$</p><p>上式的log的底为2，当然也可以是e、10。在神经网络中，log的底一般是e。当log的底大于1，log的图形就像下图红色线。因为P(x)的取值范围为0<del>1，可以看到，log的图像，在0</del>1的时候是负数，且P(x)越接近0，log越接近负无穷，P(x)越接近1，log越接近0，所以信息量的公式会在log前面加个负号，让log的取值范围为0~∞。当P(x)接近0，log接近无穷，P(x)接近1，log接近0，这符合信息量的概率越小，信息量越大的定义。</p><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p>信息熵可以表达<strong>数据的信息量大小</strong>。<br>信息熵也被称为熵，用来表示所有信息量的<strong>期望</strong>。<br>期望是试验中每次可能结果的概率乘以其结果的总和。<br>信息熵的公式如下：<br>$H ( X ) = - \sum _ { i = 1 } ^ { n } P ( x _ { i } ) \log ( P ( x _ { i } )  )$ $( X = x _ { 1 } , x _ { 2 } , x _ { 3 } , x _ { n - 1 } , x _ { n } )$</p><p>使用明天的天气概率来计算其信息熵：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626618468307.png" alt="天气"><br>$H ( X ) = - ( 0.5 * \log ( 0.5 ) + 0.2 * \log ( 0.2 ) + 0.3 * \log ( 0.3 ) )$</p><h3 id="KL散度（相对熵）—–用于衡量两个概率分布的差异"><a href="#KL散度（相对熵）—–用于衡量两个概率分布的差异" class="headerlink" title="KL散度（相对熵）—–用于衡量两个概率分布的差异"></a>KL散度（相对熵）—–用于衡量两个概率分布的差异</h3><p><strong><font color="#8A2BE2">如何理解 “衡量两个概率分布的差异”？</font></strong></p><p>例如在机器学习中，常常用P(x)表示样本的真实分布，用Q(x)表示模型预测的分布，比如在一个三分类任务中（例如，猫狗马分类器），[x1，x2，x3]分别表示猫，狗，马的概率，输入一张猫的图片，其真实分布为P(x)=[1，0，0]，预测分布为Q(x)=[0.7，0.2，0，1]，那么P(x)和Q(x)就是两个不同的概率分布，可以用KL散度来计算他们的差异。<br>公式为：<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626618687852.png" alt="enter description here"><br>KL散度越小，表示P(x)和Q(x)越接近，所以可以通过反复训练，来使Q(x)逼近P(x)，但KL散度有个特点，就是不对称，就是用P来你和Q和用Q来你和P的KL散度(相对熵)是不一样的，但是P和Q的距离是不变的。</p><p><strong>那KL散度(相对熵)和交叉熵有什么联系呢</strong>？</p><p>我们通过对相对熵公式进行变形：<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626618747252.png" alt="enter description here"><br>H(X)为之前的信息熵，后面那一坨其实就是交叉熵了，所以可以看到：**<font color="#FF00FF">KL散度 = 交叉熵 - 信息熵</font>**</p><p>所以交叉熵的公式如下：<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626618800801.png" alt="enter description here"><br>从信息熵的公式，我们知道，对于同一个数据集，其信息熵是不变的，所以信息熵可以看作一个常数，因此<font color="#9400D3">当KL散度最小时，也即是当交叉熵最小时</font>。在多分类任务中，KL散度(相对熵)和交叉熵是等价的。</p><h2 id="交叉熵的原理"><a href="#交叉熵的原理" class="headerlink" title="交叉熵的原理"></a>交叉熵的原理</h2><p>交叉熵是<font color="#057748">用来衡量两个 概率分布 的距离</font>(也可以叫差别)。[概率分布：即[0.1，0.5，0.2，0.1，0.1]，每个类别的概率都在0~1，且加起来为1]。</p><p>若有两个概率分布p(x)和q(x)，通过q来表示p的交叉熵为：(<strong>注意</strong>，p和q呼唤位置后，交叉熵是不同的)<br>$H ( p , q ) = - \sum p ( x ) \log q ( x )$<br>只要把p作为正确结果(如[0，0，0，1，0，0])，把q作为预测结果(如[0.1，0.1，0.4，0.1，0.2，0.1])，就可以得到两个概率分布的交叉熵了，<strong>交叉熵值越低，表示两个概率分布越靠近</strong>。</p><p><strong>交叉熵计算实例：</strong><br>假设有一个三分类问题，某个样例的正确答案是(1，0，0)，某个模型经过softmax回归之后的预测答案是(0.5，0.4，0.1)，那么他们的交叉熵为：<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626619013263.png" alt="enter description here"><br>如果另一个模型的预测概率分布为(0.8，0.1，0.1)，则这个预测与真实的交叉熵为：<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626619026409.png" alt="enter description here"><br>由于0.1小于0.3，所以第二个预测结果要由于第一个。</p><h2 id="使用交叉熵的背景"><a href="#使用交叉熵的背景" class="headerlink" title="使用交叉熵的背景"></a>使用交叉熵的背景</h2><p>通过神经网络解决分类问题时，一般会设置k个输出点，k代表类别的个数，如下图<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626619104894.png" alt="enter description here"><br>每个输出结点，都会输出该结点对应类别的得分，如[cat，dog，car，pedestrian] 为[44，10，22，5]</p><p>但是输出结点输出的是得分，而不是概率分布，那么就没有办法用交叉熵来衡量预测结果和真确结果了，那怎么办呢，**<font color="#FF00FF">解决方法是在输出结果后接一层 softmax，softmax的作用就是把输出得分换算为概率分布</font>**。</p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> process mining </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于注意力机制的神经网络业务过程预测分析</title>
      <link href="/2021/07/17/%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%9A%E5%8A%A1%E8%BF%87%E7%A8%8B%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/"/>
      <url>/2021/07/17/%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%9A%E5%8A%A1%E8%BF%87%E7%A8%8B%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1842025914&auto=1&height=66"></iframe><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>提出了一种具有注意力机制的神经网络，它是使用公开的事件日志（如BPI Challenge 2013）进行训练。<br>同时使用n-gram模型对比结果和LSTM（长-短期记忆结构的神经网络）对比训练时间。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>提到使用以前较小的数据进行与之前的研究进行对比，同时也使用到了较大过程的日志进行评估。<br>本文的亮点，作者首次提出结合基于自我关注的transformer模型【NLP中常用】进行流程预测。</p><blockquote><p>Transformer：<br><a href="https://zhuanlan.zhihu.com/p/48508221">详解Transformer （Attention Is All You Need） - 知乎</a><br><a href="https://zhuanlan.zhihu.com/p/171875438">李宏毅-Attention，Self-Attention，Transformer - 知乎</a><br>Attention is All You Need<br><a href="https://finance.sina.com.cn/tech/2021-01-26/doc-ikftpnny1935086.shtml">堪比当年的LSTM，Transformer引燃机器学习圈：它是万能的|LSTM|机器学习_新浪科技_新浪网</a></p></blockquote><blockquote><p>残差网络<br>残差网络是为了解决深度神经网络（DNN）隐藏层过多时的网络退化问题而提出。退化（degradation）问题是指：当网络隐藏层变多时，网络的准确度达到饱和然后急剧退化，而且这个退化不是由于过拟合引起的。<br><a href="https://www.jiqizhixin.com/graph/technologies/738e788b-0e3b-4a8f-bd04-e407c7137694">深度残差网络 | 机器之心</a></p></blockquote><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ol><li><p>Attention</p></li><li><p>self-attention</p></li></ol><p><a href="https://blog.csdn.net/At_a_lost/article/details/108469516">Attention机制与Self-Attention机制的区别_At_a_lost的博客-CSDN博客_attention和self attention的区别</a></p><ol start="2"><li><p>Transformer<br>Transformer模型并没有捕捉顺序序列的能力，也就是说无论句子的结构怎么打乱，Transformer都会得到类似的结果。换句话说，Transformer只是一个功能更强大的词袋模型而已。<br>为了解决这个问题，论文中在编码词向量时引入了位置编码（Position Embedding）的特征。—自己设计编码规则</p></li><li><p>前馈神经网络也经常称为多层感知器（Multi-Layer Perceptron，MLP）</p></li></ol><h3 id="事件日志"><a href="#事件日志" class="headerlink" title="事件日志"></a>事件日志</h3><p><strong><font color="#FF8C00">简述日志结构</font></strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626528110183.png" alt="流程结构--UML"></p><p>一个事件日志由多个案例组成，但一个案例总是分配给一个事件日志。案件与事件的关系也是如此；事件的典型属性是<strong>活动、持续时间、优先级或成本</strong>。</p><p>事件日志与事件案例：一对多<br>事件案例与事件：一对多</p><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p><strong>这块需要提前学习Transformer</strong></p><ol><li>通常，序列中的每个位置可以关注序列中的任何其他位置。作者提到为了不让Softmax函数计算时不考虑位置特征，将当前事件之后的位置的值设置为无穷大【忽略位置特征】</li></ol><ul><li>我的理解是位置特征无法通过分类来实现，这也是Transformer无法捕获序列顺序的原因</li></ul><ol start="2"><li>这里为了梯度的稳定，Transformer使用了score归一化，即除以 $\sqrt{d_{k}}$</li></ol><blockquote><p>**<font color="#7FFF00">知识补充</font>**：softmax<br><a href="https://zhuanlan.zhihu.com/p/105722023">一文详解Softmax函数 - 知乎</a><br>多分类、求大</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626531018697.png" alt="Attention函数"></p><p>$W _ { i } ^ { Q } , W _ { i } ^ { K } , W _ { i } ^ { V } \in R^{d_{model}*d_{k}}$ ， $W^{O}\in R^{hd_{k}*d_{model}}$ 【 $d_{model}$ 表示嵌入的长度（可以理解为词嵌入）】</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626531384298.png" alt="self-attention函数"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626531047214.png" alt="相当于h 个不同的self-attention的集成，全连接层"></p><p>通过学习线性变换将Q向量、K向量和V向量投影到h个不同的子空间中，在每个子空间上<strong>并行</strong>计算Attention值。结果被连接并投射到特征空间，使得模型能够联合处理来自不同位置的不同表示子空间的特征。</p><h2 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h2><ol><li>2016年之前主要是使用MMs（生成模型）和聚类算法（KNN或k-means）相结合；剩下的就是一些类似MMs，例如，基于贝叶斯概念的概率有限自动机（概率模型），它使用期望的极大似然估计。 数据来源2012，2013公开的BPI比赛。</li><li>2016至今，几乎都是长短期记忆结构（LSTM）然后与其它模型相结合的方法来预测，比如结合词嵌入的神经网络，使用一个热编码转换事件特征，并将其与生成的时间特征连接到单个特征向量。数据来源2012，2013公开的BPI比赛</li><li>另一种方法将事件预测视为经典的多类分类问题，并使用堆叠的自动编码器提取特征，然后使用深度前馈网络对特征进行分类。然而，这种方法只适用于简单的数据集，因为不同表示的数量随着唯一事件类的数量呈多项式增长。</li></ol><blockquote><p><font color="#FF8C00">知识补充</font> 独热编码<br><a href="https://www.cnblogs.com/zongfa/p/9305657.html">数据预处理：独热编码（One-Hot Encoding）和 LabelEncoder标签编码 - 理想几岁 - 博客园</a></p></blockquote><blockquote><p><font color="#9400D3">知识补充</font> 多项式增长<br>也就是对于变量n，5n^2+2n+1这种就叫做多项式。</p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><strong>本实验数据集：</strong></p><ol><li>BPI Challenge 2013</li><li>一家德国软件公司提供的额外数据集。后一个数据集的事件日志包括律师、会计师和审计员使用一种特殊软件工具进行财务核算、管理付款交易和编制年度财务报表的情况。</li></ol><p>数据集由大约2.08亿个事件组成，由会话id标识，该会话id指示它们所属的情况、事件类型和时间戳。每个用户交互（通常是点击按钮）都被视为一个事件，一个案例从应用程序启动一直持续到关闭。</p><p>难点：<br>作者通过流程挖掘，许多独特的事件类增加了预测的难度。在<strong>较小的数据集中</strong>，大多数情况下都非常短。大约四分之一的病例由五个或更少的事件组成，只有百分之一的流程长度为500或更多。<br>同时数据集中大部分数据为重复的，数据类型不均匀，最常见的五个事件类型几乎占了<strong>整个数据集</strong>的一半。</p><h2 id="建模方法"><a href="#建模方法" class="headerlink" title="建模方法"></a>建模方法</h2><p>模型是在tensorflow上实现的，使用tf.data-API作为输入管道，tf.keras-API构建我们的模型。【不懂，反正tensorflow上的组件哇】</p><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ol><li>整理事件类型，并用整数标记</li><li>将一个流程的所有事件放到一个张量（tensor，多维数组，能够创造更高维度的矩阵、向量。）</li><li>为每个流程添加一个结束标记，并且通过左移一个位置来生成训练标签【没懂为啥要左移生成标签，但是目的是为了生成训练标签，感觉是<strong>通过监控位置标签判断是否为训练数据集</strong>】</li><li>在上一部分中提到数据集长短不一，作者提出通过按照长度将流程分到不同区域中。这里为了确保每个区域中的流程相似，就没有设置固定的长度，而是通过制定上限来控制长度。</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626535517054.png" alt="上限控制"></p><p>$l_{1}&lt;9$ </p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626535685586.png" alt="a为模型，b为attention模块"></p><p>N表示Transformer的数量、 $d_{model}$ 表示嵌入长度、h表示Attention的数量， $d_{l}$ 表示Q，K，V的向量维度。<br>M表示词汇的数量，这里可以理解为事件的数量，n为单个流程的长度，bsz表示流程的数量，单次样本数量。<br>Pos.Encoding  位置编码标记</p><blockquote><p><strong><font color="#DC143C">知识补充</font></strong><br><a href="https://blog.csdn.net/program_developer/article/details/78597738">神经网络中Epoch、Iteration、Batchsize相关理解和说明_Microstrong-CSDN博客_epoch</a><br><strong>epoch</strong>：中文翻译为时期。<br>一个时期=所有训练样本的一个正向传递和一个反向传递。<br>举个例子，训练集有1000个样本，batchsize=10，那么：<br>训练完整个样本集需要：<br>100次iteration，1次epoch。</p></blockquote><blockquote><p><strong>理解辅助：</strong><br>这块主要和Transformer论文中的Shared-Weight Embeddings and Softmax这一部分一样<br>与其他序列转导模型类似，使用可学习的 Embeddings 将 input tokens and output tokens 转换为维度  的向量【序列转序列转为d（model）维度的向量】。通过线性变换和 softmax 函数将解码器的输出向量转换为预测的 token 概率。在 Transformer 模型中，两个嵌入层和 pre-softmax 线性变换之间共享相同的权重矩阵，在 Embeddings 层中，将权重乘以 . 这些都是当前主流的操作。</p></blockquote><ol><li>通过被一个正态分布初始权值的可训练查找矩阵构成的<strong>嵌入层</strong>将输入映射到一个 $d_{model}$ 维度的特征空间【①使用embedding将输入转化为 $d_{model}$ 维度的向量】，同时pre-softmax函数在transformer中使用相同的查找矩阵。</li><li>由于Transformer不对顺序有预测效果，所以将位置编码加入到嵌入向量中【与第一个方法类似结合sin，cos】</li><li>通过交叉熵和标签滑动来进行拟合结果和消除过拟合</li><li>最后作者提到注意计算结果在内部缓存并复用的问题，主要在担心内存溢出，但是实验缓冲所需的空间可忽略不计。</li></ol><blockquote><p><strong><font color="#0000FF">知识补充</font></strong><br>label smoothing(标签平滑)：正则化策略，为了防止过拟合，加入噪声<br><a href="https://zhuanlan.zhihu.com/p/116466239">label smoothing(标签平滑)学习笔记 - 知乎</a><br>交叉熵即预测值与真实值之间的差值，越少越精准。<br><a href="https://blog.zuishuailcq.xyz/2021/07/18/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B9%8B%E4%BA%A4%E5%8F%89%E7%86%B5(%E4%B8%80%E8%88%AC%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98)/">损失函数之交叉熵(一般用于分类问题) | 吾辈之人，自当自强不息！</a></p></blockquote><blockquote><p><strong><font color="#00CED1">知识补充：</font></strong> 模型理解<br><a href="https://zhuanlan.zhihu.com/p/60821628">碎碎念：Transformer的细枝末节 - 知乎</a><br><a href="https://zhuanlan.zhihu.com/p/106867810">Transformer理论源码细节详解 - 知乎</a><br><a href="https://www.codenong.com/cs106837783/">Transformer论文详解，论文完整翻译（七） | 码农家园</a><br><a href="https://congchan.github.io/NLP-attention-03-self-attention/">Transformer &amp; Self-Attention (多头) 自注意力编码 | Fly Me to the Moon</a></p></blockquote><h2 id="结果验证"><a href="#结果验证" class="headerlink" title="结果验证"></a>结果验证</h2><p>作者使用了前面提到的BPI2013和DATSET，每个数据集分为三个部分：培训，验证和测试。对于BPI2013的数据集，作者选的的训练、验证、测试集之间比例80%，10%，10%。DATSET则是96%，2%，2%。<br>BPI2013用了30000个训练模型，DATSET使用了一百万个，一个epoch为1000个。</p><ol><li>BPI2013</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626620621539.png" alt="BPI2013结果"><br>展示了四种超参数的配置 $d_{model}$ 为嵌入长度，h为Attention数量， $d_{ff}$ 规定了点式前馈神经网络的内部第一层输出节点， 为前反馈网络中的参数。</p><p>分析，在最小超参数的配置中，当结合四层Transformer后精确度达到最高。同时随着配置的增加，训练的效果却下降了，这里可能是设置超参数过大，欠拟合。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626622123211.png" alt="近几年比较"><br>【4】”Comprehensible predictive models for business processes” 2016<br>【11】“Predicting process behaviour using deep learning”2016<br>【13】“A multi-stage deep learning approach for business process event prediction”2017</p><p>实验表明，我们的注意力竞争方法通常适用于过程事件预测的任务，并且可以与现有技术相当执行。</p><ol start="2"><li>DATSET</li></ol><p>由于DATSET的数据集较大，这里直接使用较大的超参数，同时结合4和6层的transformer</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626622668082.png" alt="超参数"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626622687231.png" alt="DATSET"></p><pre><code>    训练的时候将超过500的流程筛选出来，这些只占了数据集1%</code></pre><p>分析，最高为0.6218。超参数较小的模型显着更糟糕，这表明它们无法完全模拟数据的复杂性。但是没有以前的数据进行对比，作者使用LSTM基本模型使用相同的超参数【256，N=4】进行对比。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021718/1626622951569.png" alt="LSTM VS  Model"></p><p>证明了所提出的基于关注力的模型比基于LSTM的模型更好。此外，根据LSTM训练时间是我们的两倍。 <strong>TODO</strong> <font color="#FF00FF">这显示了注意机制对于长跟踪长度的优势，它能够一次处理整个跟踪，而不是一次处理一个元素。</font></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文，作者提出了基于注意力机制的业务流程预测模型，通过数据集验证，不仅在较小的数据集上（BPI2013）可以接近现有技术的精确度，同时在预测复杂的的数据集也可以达到良好的效果，同时训练时间更少。</p><p>提到对于复杂的模型处理的新的思路，<strong>对于流程轨迹进行分割，对于重复的事件进行预处理，缩短流程提升预测精度</strong>或者是<strong>仅部分学习预测</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> paper </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注意力机制</title>
      <link href="/2021/07/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
      <url>/2021/07/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/105335191">注意力机制到底是什么——基于常识的基本结构介绍 - 知乎</a><br><a href="https://www.zhihu.com/question/304499365">(96 封私信 / 80 条消息) 「注意力机制」是什么意思？ - 知乎</a><br><a href="https://my.oschina.net/u/876354/blog/3061863">大话注意力机制（Attention Mechanism） - 雪饼的个人空间 - OSCHINA - 中文开源技术交流社区</a><br><a href="https://zhuanlan.zhihu.com/p/148737297">attention机制中的query,key,value的概念解释 - 知乎</a></p><h2 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h2><p>注意力机制(Attention Mechanism)是人们在机器学习模型中嵌入的一种特殊结构，用来自动学习和计算输入数据对输出数据的<font color="#1E90FF"><strong>贡献</strong></font>大小。</p><blockquote><p>目前，注意力机制已经成为深度学习领域，尤其是自然语言处理领域，应用最广泛的“组件”之一。这两年曝光度极高的BERT、GPT、Transformer等等模型或结构，都采用了注意力机制。</p></blockquote><h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><p>来自于认知工程领域提出的，类似人对于信息采集的机制—特征工程。</p><h3 id="人身上的注意力机制"><a href="#人身上的注意力机制" class="headerlink" title="人身上的注意力机制"></a>人身上的注意力机制</h3><p>去超市购物，和朋友去购物，作为提东西的工具人，不仅要体力跟的上，那么我们还需要的是跟的上朋友的步伐，人山人海中要跟上步伐确实比较困难，当我们用眼睛去一个一个寻找，把路人的信息特征衣服，脸，发色，发型~都传入到脑海中一个一个比对寻找朋友的时候，这时候不仅效率极其低而且大脑表示也遭不住，那么我们只需要记到部分明显特征发型身高等，然后扩大视野，这样效率会明显提高。<br>像这种情形，**<font color="#9932CC">有选择的处理信号</font>**，包括人类很多生物在处理外界信号时的策略，这种处理机制就是注意力机制。</p><h3 id="特征工程——模型外部的注意力机制"><a href="#特征工程——模型外部的注意力机制" class="headerlink" title="特征工程——模型外部的注意力机制"></a>特征工程——模型外部的注意力机制</h3><p>严格来说，「注意力机制」更像是一种方法论。没有严格的数学定义，而是根据具体任务目标，对关注的方向和加权模型进行调整。<br>简单的理解就是，在神经网络的隐藏层，增加「注意力机制」的加权。<br>使不符合注意力模型的内容弱化或者遗忘。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626502007361.png" alt="特征工程"></p><h3 id="“key-query-value”理论"><a href="#“key-query-value”理论" class="headerlink" title="“key-query-value”理论"></a>“key-query-value”理论</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626502458858.png" alt="Attention机制"></p><p>将Source中的构成元素想象成是由一系列的&lt;Key,Value&gt;数据对构成，此时给定Target中的某个元素Query，通过计算Query和各个Key的相似性或者相关性，得到每个Key对应Value的权重系数，然后对Value进行加权求和，即得到了最终的Attention数值。所以本质上Attention机制是对Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数。即可以将其本质思想改写为如下公式：<br>$Attention( Q u e r y , Source ) = \sum _ { i = 1 } ^ { L _ { x } }Similarity(Query,Key_{i})*Value_{i}$</p><blockquote><p><strong><font color="#7FFF00">个人理解</font></strong><br>可以把attention机制看作一种软寻址：Source可以看作存储器内存储的内容，元素由地址Key和值Value组成，当前有个Key=Query的查询，目的是取出存储器中对应的Value值，即Attention数值。通过Query和存储器内元素Key的地址进行相似性比较来寻址，之所以说是软寻址，指的不像一般寻址只从存储内容里面找出一条内容，而是可能从每个Key地址都会取出内容，**<font color="#7FFF00">取出内容的重要性根据Query和Key的相似性来决定</font>**，之后对Value进行加权求和，这样就可以取出最终的Value值，也即Attention值。</p></blockquote><p><strong><font color="#008B8B">Attention机制的具体计算过程：</font></strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021717/1626508762885.png" alt="计算过程"></p><ol><li>根据Query和Key计算两者的相似性或者相关性【学习】</li><li>对第一阶段的原始分值进行归一化处理【获取权重系数】</li><li>根据权重系数对Value进行加权求和</li></ol><blockquote><p><strong><font color="#00008B">知识补充</font></strong><br>点乘又叫向量的内积、数量积，是一个向量和它在另一个向量上的投影的长度的乘积；是标量。 <strong>点乘反映着两个向量的“相似度”</strong>，两个向量越“相似”，它们的点乘越大。<br>向量叉乘求的是<strong>垂直</strong>于这两个向量<br>Cosine相似性，求余弦<br>多层感知器（Multilayer Perceptron,缩写MLP）一种通用的函数近似方法，可以被用来拟合复杂的函数，或解决分类问题</p></blockquote><p>第一阶段中根据Query和Key求相似度目前常见的方法包括：求两者的向量点积、求两者的向量 Cosine相似性或者通过再引入额外的<br>神经网络来求值如下：<br>点积：<br>$Similarity(Query,Key_{i})=Query*Key_{i}$</p><p>Cosine相似性：<br>$Similarity(Query,Key_{i})=\frac { Query<em>Key_{i} } { ||Query||</em>||Key_{i}||}$</p><p>MLP网络：<br>$Similarity(Query,Key_{i})=MLP（Query*Key_{i}$</p><p>第二阶段引入类似SoftMax的计算方式对第一阶段的相似度得分进行数值转换，一方面可以进行归一化，将原始计算分值整理成所有元素权重之和为1的概率分布；另一方面也可以通过SoftMax的内在机制更加突出重要元素的权重。<br>$a_{i}=Softmax(Sim_{i})= \frac{e^{Sim_{i}}}{ \textstyle \sum_{j=1}^{L_{x}}e^{Sim_{j}} }$</p><p>最后一阶段是加权求和求Attention数值：<br>$Attention(Query,Source)={\textstyle \sum_{i=1}^{L_{x}}a_{i}\cdot Value_{i}}$</p><h2 id="深度学习领域的注意力机制"><a href="#深度学习领域的注意力机制" class="headerlink" title="深度学习领域的注意力机制"></a>深度学习领域的注意力机制</h2><h3 id="注意力机制的思想和基本框架"><a href="#注意力机制的思想和基本框架" class="headerlink" title="注意力机制的思想和基本框架"></a>注意力机制的思想和基本框架</h3><blockquote><p>一些学者尝试让<font color="#9400D3">模型自己学习如何分配自己的注意力</font>，即为输入信号加权。<em>他们用注意力机制的直接目的，就是为输入的各个维度打分，然后按照得分对特征加权，以突出重要特征对下游模型或模块的影响。这也是注意力机制的基本思想。</em></p></blockquote><p><strong>一般会采用”key-query-value”理论来描述注意力机制的机理。</strong></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> process mining </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习</title>
      <link href="/2021/07/13/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
      <url>/2021/07/13/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/steven-yang/p/6481772.html">强化学习读书笔记 - 00 - 术语和数学符号 - SNYang - 博客园</a><br><a href="https://www.cnblogs.com/wacc/p/5391209.html">强化学习笔记1 - Hiroki - 博客园</a></p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>监督学习在机器学习中取得了重大的成功，然而在<strong>顺序决策制定</strong>和<strong>控制问题</strong>中，比如无人直升机、无人汽车等，难以给出显式的监督信息，因此这类问题中<strong>监督模型无法学习</strong>。<br>强化学习就是为了解决这类问题而产生的。在强化学习框架中，学习算法被称为一个agent，假设这个agent处于一个环境中，两者之间存在交互。<font color="#9400D3">agent通过与环境交互不断增强对环境的适应力，故得名强化学习。</font></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021713/1626145210759.png" alt="强化学习"></p><p>在每个时间步 $t$ ，agent：</p><ul><li>接受状态 $s _ { t }$</li><li>接受标量回报 $r _ { t }$</li><li>执行行动 $a _ { t }$</li></ul><p>环境：</p><ul><li>接受动作 $a _ { t }$</li><li>产生状态 $s _ { t }$</li><li>产生标量回报 $r _ { t }$</li></ul><h2 id="MDP-马尔科夫决策过程"><a href="#MDP-马尔科夫决策过程" class="headerlink" title="MDP(马尔科夫决策过程)"></a>MDP(马尔科夫决策过程)</h2><p>通常我们都是从MDP（马尔科夫决策过程）来了解强化学习的。MDP问题中，我们有一个五元组： $( S , A , P , \gamma , P )$</p><ul><li>$S$ :状态集，由agent所有可能的状态组成</li><li>$A$ :动作集，由agent所有可能的行动构成</li><li>$P ( s , a , s ^ { \prime } )$ :转移概率分布，表示状态s下执行动作a后下个时刻状态的概率分布</li><li>$\gamma$ :折扣因子，0≤ $\gamma$ ≤1，表示未来回报相对于当前回报的重要程度。如果 $\gamma$ =0，表示只重视当前立即回报； $\gamma$ =1表示将未来回报视为与当前回报同等重要。【<font color="#FF8C00">这块不懂，可以看后面下围棋的栗子</font>】</li><li>$R ( s , a , s ^ { \prime } )$ :标量立即回报函数。执行动作a，导致状态s转移到s′产生的回报。可以是关于状态-动作的函数 $S \times A \rightarrow R$ ，也可以是只关于状态的函数 $S \rightarrow R$ 。记t时刻的回报为 $r _ { t }$ ，为了后续表述方便，假设我们感兴趣的问题中回报函数只取决于状态，而状态-动作函数可以很容易地推广，这里暂不涉及。</li></ul><p><strong><font color="#8B008B">注：</font></strong> 这里阐述的MDP称为discounted MDP，即<font color="#00008B">带折扣因子的MDP</font>。有些MDP也可以定义为四元组： $( S , A , P , R )$ ，这是<em>因为这类MDP中使用的值函数不考虑折扣因子</em>。</p><blockquote><p>**<font color="#9932CC">马尔可夫性质</font>*<em>：当一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布<font color="#006400">仅依赖于当前状态</font>；换句话说，在给定现在状态时，它与过去状态（即该过程的历史路径）是<font color="#1E90FF">条件独立</font>的，那么此随机过程即具有马尔可夫性质。<br>例如：</em>明天的天气（是否下大雨）仅与今天的天气（是否刮大风）有关，而与前天及以前的天气无关*。</p></blockquote><p>MDP过程具有马尔科夫性质，即给定当前状态，未来的状态与过去的状态无关。但与马尔科夫链不同的是，MDP还考虑了<strong>动作</strong>，也就是说MDP中状态的转移不仅和状态有关，还依赖于agent采取的动作。</p><p>我们可以通过下面表格了解各种马尔科夫模型的区别：</p><table><thead><tr><th></th><th>不考虑动作</th><th>考虑动作</th></tr></thead><tbody><tr><td>状态可观测</td><td>马尔科夫链（MC）</td><td>马尔科夫决策过程（MDP）</td></tr><tr><td>状态不完全可观测</td><td>隐马尔科夫模型（HMM）</td><td>不完全可观察马尔可夫决策过程（POMDP）</td></tr></tbody></table><p><strong><font color="#FF8C00">MDP的运行过程：</font></strong><br><img src="https://gitee.com/merlynr/img-store/raw/master/2021713/1626158954807.png" alt="MDP"></p><p>我们从初始状态 $s _ { 0 }$ 出发，执行某个动作 $a _ { 0 }$ ，根据转移概率分布确定下一个状态 $s _ { 1 }$ ∼ $P _ { s0a0 }$ ，接着执行动作 $a _ { 1 }$ ，再根据 $P _ { s1a1 }$ 确定 $s _ { 2 }$ …。</p><p>一个discounted MDP中，我们的目标最大化一个<font color="#1E90FF">累积未来折扣回报</font>:<br>$R _ { t } = \sum _ { k = 0 } ^ { \infty } \gamma ^ { k } r _ { t + k + 1 }$</p><p>具体地，我们希望学得一个<strong>策略</strong>（policy），通过执行这个策略使上式最大化。策略一般可以表示为一个函数，它以<font color="#9932CC">状态</font>为输入，输出<font color="#9932CC">对应的动作</font>。策略函数可以是确定的 $\pi ( s ) = a$ ，也可以是不确定的  $\pi ( s , a ) = p ( a | s )$ （这时策略函数是一个<em>条件概率分布</em>，表示给定状态s下执行下一个动作a的概率）。当agent执行一个策略时，每个状态下agent都执行策略指定的动作。</p><p>强化学习通常具有<strong>延迟回报</strong>的特点，以下围棋为例，只有在最终决定胜负的那个时刻才有回报（赢棋为1，输棋为-1），而之前的时刻立即回报均为0。这种情况下， $R _ { t }$ 等于1或-1，这将导致我们很难衡量策略的优劣，因为即使赢了一盘棋，未必能说明策略中每一步都是好棋；同样输了一盘棋也未必能说明每一步都是坏棋。因此我们需要一个目标函数来刻画策略的长期效用。<br>为此，我们可以为策略定义一个<strong>值函数</strong>（value function）来综合评估某个策略的好坏。这个函数既可以是只关于状态的值函数 $V ^ { \pi } ( s )$ ，也可以状态-动作值函数 $Q ^ { \pi } ( s , a )$ 。<font color="#2F4F4F">状态值函数评估agent处于某个状态下的长期收益</font>， 动作值函数评估agent在某个状态下执行某个动作的长期收益。</p><p>本文后续都将以 <strong><font color="#FF8C00">状态值函</font></strong> 数为例，进行阐述。一般常用的有三种形式：</p><ol><li>$V ^ { \pi } ( s ) = E _ { \pi } [ \sum _ { k = 0 } ^ { \infty } r _ { t + k + 1 } | s _ { t } = s ]$</li><li>$V ^ { \pi } ( s ) = E _ { \pi } [ \lim _ { k \rightarrow \infty } \frac { 1 } { k } \sum _ { i = 0 } ^ { k } T _ { t + i + 1 } | s _ { t } = s ]$</li><li>$V ^ { \pi } ( s ) = E _ { \pi } [ \sum _ { k = 0 } ^ { \infty } \gamma ^ { k } r _ { t + k + 1 } | s _ { t } = s ]$</li></ol><p>其中 $E _ { \pi } [ \cdot | s _ { t } = s ]$ 表示从状态s开始，通过执行策略 $π$  得到的累积回报的期望。有些情况下，agent和环境的交互是无止境的，比如一些控制问题，这样的问题称为 <strong><font color="#9400D3">continuing task</font></strong> 。还有一种情况是我们可以把交互过程打散成一个个 **<font color="#9400D3">片段式任务</font>**（episodic task），每个片段有一个起始态和一个终止态（或称为吸收态，absorbing state），比如下棋。当每个episode结束时，我们对整个过程重启随机设置一个起始态或者从某个随机起始分布采样决定一个起始态。<br>上面三种值函数中，我们一般常用第三种形式，我把它叫做 **<font color="#9400D3">折扣值函数</font>**（discounted value function）。</p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> machine leaning </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>暑假学习安排以及前段学习总结</title>
      <link href="/2021/07/11/%E6%9A%91%E5%81%87%E5%AD%A6%E4%B9%A0%E5%AE%89%E6%8E%92%E4%BB%A5%E5%8F%8A%E5%89%8D%E6%AE%B5%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
      <url>/2021/07/11/%E6%9A%91%E5%81%87%E5%AD%A6%E4%B9%A0%E5%AE%89%E6%8E%92%E4%BB%A5%E5%8F%8A%E5%89%8D%E6%AE%B5%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="已完成–前段时间"><a href="#已完成–前段时间" class="headerlink" title="已完成–前段时间"></a>已完成–前段时间</h2><ol><li>观看学习了吴恩达的机器学习课程视频，观看的主要的目的是对于机器学习有个整体的观念，同时我也学到了机器学习实验中简单的调参，验证以及最后结果的分析。</li><li>总结性的略读了几篇业务流程中对于异常的检测的paper，主要还是通过根据时间特征来检测事件的状态，主要包括有：<ul><li>基于时间边界的事件异常检测【通过对事件划分时间边界】</li><li>基于关键路径【确认业务流程关键路径，比对花费所时间】</li><li>通过对于执行时间建模方法来预测【即构建所有活动持续时间直立方图，然后通过比对当前节点和余下节点在图中占比来预测】</li><li>综合时间模型和流程步骤分析【综合运用时间统计模型和通过多个步骤分析方法生成运行时间概率分布、计算异常概率、与阈值比较的方法，提出一种基于运行的异常预测算法来预测工作流中的时间异常，该算法分为即设计时段和运行时段两个阶段，在设计时段，生成该模型所有可能产生的运行轨迹，并计算它们的预计执行时间的概率分布；在运行时段，通过分析计算流程超时的可能性与预设的阈值做比较来判断是否预测为异常】</li></ul></li><li>精读了2019年较为新的paper【基于机器学习的流程异常预测方法】，文中作者提出一种混合模型，就是结合了通过标注时间时间来对超期异常预测，但是由于系统执行时间很容易受到环境等因素导致超过人工标注时间，所以作者提出了通过机器学习学习各个事件在整个流程的流程所消费的时间占比来预测异常。自己对于其中的算法和模型都进行详细了解，同时结合以前略读的论文，感觉这篇论文就是结合了一下前人的方法，没有实际创新点。</li><li>整理了关于业务流程预测中的详细研究方向：<pre><code>- 预测完成一个案件的剩余时间- 流程预测结果评估【二元评估】- 预测下一个事件</code></pre></li><li>对于业务流程预测下一事件进行系统学习【只完成了部分,这一部分吗主要是2016年以前的论文，即普遍是用机器模型，而更复杂的深度学习模型是2016年后被应用到】：<ul><li>利用数据的时间分类特征来预测，使用更高阶马尔可夫模型（HMMs，这里指的是隐马尔可夫模型）和使用序列比对的流程结果来预测过程的下一个步骤。个人理解就是将序列KNN与HMMs相结合，通过HMMs学习数据，获得高阶模型，然后混合了序列KNN的替换矩阵，利用局部序列对比，<strong>降低了高阶HMMs的弱覆盖的缺陷影响</strong>。</li><li>针对处理半结构化业务流程数据，提出一种针对特定事件进程的模型（PPM），个人学习理解它作为过渡模型，主要负责学习记录半结构化业务流程的实例，和替换矩阵，然后映射到扩展马尔可夫链预测【当遇到并行事务的时候通过递归的方式学习转换矩阵】，作者的优点主要体现在针对<strong>半结构化业务流程数据</strong>进行预测。 </li></ul></li></ol><h2 id="未完成及原因–前段时间"><a href="#未完成及原因–前段时间" class="headerlink" title="未完成及原因–前段时间"></a>未完成及原因–前段时间</h2><ol><li>机器学习还是需要实操来检验自己所理解的知识，但是由于前期花费在理论上的时间比较多，同花了很多时间在数学上，虽然准备了环境准备实操但是也没有按时完成，也搁浅了。</li><li>在系统了解学习对于业务异常检测的时候中，还有两篇关于结合积极语义模型和受病毒传播启发病毒传染模型启发的时间延迟传播模型的预测检测的方法没有阅读，主要由于后面确认了自己要研究预测下一步，所以就没有继续阅读了。</li><li>在预测行为异常的论文中多次提到了对数据进行初始标注，但是都没有详细说明，所以这块没有详细研究，后面也没继续关注</li><li>本来应该在七月底将2016年前关于业务流程预测下一步的几篇全部看完，但是由于中间整理实验数据跑一下基本的模型【结果也没跑，数据量过大，笔记本不行，在挖掘流程的时候就很卡】，还有遇到了考试月就耽误了</li></ol><h2 id="暑假安排"><a href="#暑假安排" class="headerlink" title="暑假安排"></a>暑假安排</h2><ol><li>7.25号之前将剩下的四五篇关键论文看完【2016年前】</li><li>8.20系统学习看一下深度学习中在流程预测的使用，目前查阅的主要有循环神经网络，MMs，语法感知技术，基于过程发现技术，基于自动机的预测技术等，我现在收集了相关14篇论文【有一些是重复的改进模型】，开始可能看的慢一点，后面应该会快一点</li><li>读深度学习相关论文的时候，开始我会阅读最早的三四篇，然后后面倒着读剩下的，这样一旦有idea也能知道自己的想法是不是与最新的重复了。</li><li>9.17-9.27回家过个中秋，同时发小结婚</li></ol><h2 id="期望"><a href="#期望" class="headerlink" title="期望"></a>期望</h2><ol><li>老师前面提到与公司项目相结合，使用公司的数据，我当时考虑的是使用公工数据集，这样有对比也易于发表，现在我能想到的是，本来后面要帮老师做那个RPA程序，就想的后面在大论文中加入一部分流程挖掘，正好可以利用公司的日志信息挖掘，然后根据数据训练模型【这一块明天有空和老师聊一下哇，因为老师让我做的那块貌似没有日志哇，所以交流一下哇】</li><li>在我阅读业务流程预测论文的过程中，我开始发现预测事件由传统机器学习中的序列匹配开始向深度学习中的NLP靠拢，通过学习事件之间的因果来预测下一步，可能这块研究没有NLP那么超前，所以基本模型没有配套，但是依旧可以向他们学习，这样更加容易改进模型发表paper</li></ol>]]></content>
      
      
      <categories>
          
          <category> plane </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> summarize </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
            <tag> paper </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>预测精度分析</title>
      <link href="/2021/07/08/%E9%A2%84%E6%B5%8B%E7%B2%BE%E5%BA%A6%E5%88%86%E6%9E%90/"/>
      <url>/2021/07/08/%E9%A2%84%E6%B5%8B%E7%B2%BE%E5%BA%A6%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_41196612/article/details/107265167">R语言实战——基于KNN聚类的时间序列分析预测_三只佩奇不结义的博客-CSDN博客_r语言knn回归及预测</a></p>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>瘾</title>
      <link href="/2021/07/07/%E7%98%BE/"/>
      <url>/2021/07/07/%E7%98%BE/</url>
      
        <content type="html"><![CDATA[<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul><li><input disabled="" type="checkbox"> 酒</li><li><input disabled="" type="checkbox"> 手机</li><li><input disabled="" type="checkbox"> 游戏</li><li><input disabled="" type="checkbox"> 小视频</li></ul><h2 id="HOW"><a href="#HOW" class="headerlink" title="HOW"></a>HOW</h2><ol><li>酒每个月少喝就行了</li><li>分析上瘾手机的原因，太无聊了，找到替代品</li><li>游戏本质就是单身狗</li><li>小视频太闲了，需要找到替代品</li></ol><ul><li><input disabled="" type="checkbox"> 手机不上床</li><li><input disabled="" type="checkbox"> 游戏emmmm</li><li><input disabled="" type="checkbox"> 小视频换个环境，聊聊天什么的就行了</li><li><input disabled="" type="checkbox"> 找个积极的上瘾</li></ul>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KNN（K近邻法 K Nearest Neighbors）</title>
      <link href="/2021/07/05/KNN%EF%BC%88K%E8%BF%91%E9%82%BB%E6%B3%95%20K%20Nearest%20Neighbors%EF%BC%89/"/>
      <url>/2021/07/05/KNN%EF%BC%88K%E8%BF%91%E9%82%BB%E6%B3%95%20K%20Nearest%20Neighbors%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/25994179">一文搞懂k近邻（k-NN）算法（一） - 知乎</a></p><p><a href="https://blog.csdn.net/qq_20412595/article/details/82013677">机器学习算法（2）之K近邻算法_不曾走远的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/pxhdky/article/details/85080980">【机器学习】K近邻法（KNN）与kd树原理详解_齐在的专栏-CSDN博客</a></p><p>TODO 序列KNN</p><h2 id="KNN概述"><a href="#KNN概述" class="headerlink" title="KNN概述"></a>KNN概述</h2><ul><li>常用有监督学习方法</li><li>常用分类方法</li><li>同时也是回归方法</li><li>是懒惰学习</li></ul><blockquote><p><font color="#ff7500">扩展学习</font><br>懒惰学习是一种训练集处理方法，其会<font color="#012C54">在收到测试样本的同时进行训练</font>，与之相对的是急切学习，其会<font color="#8A2BE2">在训练阶段开始对样本进行学习</font>处理。</p></blockquote><p><font color="#FF8C00">基本思路：</font><br>如果一个待分类样本在特征空间中的k个最相似(即特征空间中K近邻)的样本中的大多数属于某一个类别，则该样本也属于这个类别，即近朱者赤，近墨者黑。</p><h2 id="KNN算法介绍"><a href="#KNN算法介绍" class="headerlink" title="KNN算法介绍"></a>KNN算法介绍</h2><h3 id="KNN模型"><a href="#KNN模型" class="headerlink" title="KNN模型"></a>KNN模型</h3><p><strong>kNN使用的模型实际上对应于对特征空间的划分。</strong></p><p><font color="#006400">由三个及基本要素组成：</font></p><ul><li>距离度量</li><li>k值的选择</li><li>决策规划</li></ul><ol><li>距离度量</li></ol><p>KNN中使用的距离度量可以是欧式距离、曼哈顿距离、切比雪夫距离或者一般的闵可夫斯基距离。</p><blockquote><p><font color="#9932CC">知识补充</font><br>设特征空间 $X$ 是 $n$ 维实数向量空间<math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mi>n</mi></msup></math>，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub></math>∈ $X$ ，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mo>(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow></msubsup><mo>)</mo><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow></msubsup><msup><mo>)</mo><mi>T</mi></msup></math>，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>j</mi></msub><mo>=</mo><mo>(</mo><msubsup><mi>x</mi><mi>j</mi><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>j</mi><mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow></msubsup><mo>)</mo><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msubsup><mi>x</mi><mi>j</mi><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow></msubsup><msup><mo>)</mo><mi>T</mi></msup></math></p><ol><li><p>闵可夫斯基距离（Minkowski distance,<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mi>p</mi></msub></math>距离）<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub></math>的<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mi>p</mi></msub></math>距离定义为：<br><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625491452207.png"><br>其中，p ≥ 1 。 </p></li><li><p>曼哈顿距离（Manhattan distance）<br>当p = 1 时，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mi>p</mi></msub></math>距离就变成了曼哈顿距离：<br><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625491491032.png"></p></li><li><p>欧式距离（Euclidean distance）<br>当p = 2时，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mi>p</mi></msub></math>距离就变成了欧式距离：<br><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625491674920.png"></p></li><li><p>切比雪夫距离（Chebyshev distance）<br>当<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo>=</mo><mo>&#x221E;</mo><mo>,</mo><msub><mi>L</mi><mi>p</mi></msub></math>距离就变成了切比雪夫距离，它是各个坐标距离的最大值：<br><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625491693716.png"></p></li></ol></blockquote><ol start="2"><li>k值选择（借鉴李航–统计学习方法）</li></ol><p>如果k值较小，则训练误差减少，只有与输入实例相似的训练实例才会对于预测结果起作用,“学习”<font color="#D2691E">近似误差会减小</font>，但泛化误差提高了，预测结果会对近邻实例点非常敏感。k值较小意味着模型变得复杂，容易发生<font color="#0000FF">过拟合</font>。</p><p>如果k值较大，可以减少泛化误差，其优点是可以<font color="#D2691E">减少学习的估计误差</font>，但训练误差会增加，这时与输入实例相差较远的训练实例也会对预测结果起作用。k值较大意味着模型变得简单，容易发生<font color="#0000FF">欠拟合</font>。</p><p>通常情况下，我们需要对 k 经过多种尝试，来决定到底使用多大的 k 来作为最终参数。k通常会在3～10直接取值，或者是k等于训练数据的<font color="#DC143C">平方根</font>。比如15个数据，可能会取k=4。<br>第二种方法，选择能使测试集达到最优的k kk，即能够使得如MAPE等衡量预测准确度的统计量达到最小；<br>第三种方法，同时训练多个函数不同参数k kk的模型，然后取所有模型的预测值的平均值作为最终的预测值。</p><p>当k = 1时，k近邻算法就是最近邻算法。k值一般<font color="#FF1493">采用交叉验证法选取最优值</font>。</p><ol start="3"><li>决策规划</li></ol><p>通常，在分类任务中使用投票法计算最终预测结果，在回归任务中使用平均法，还可基于距离远近进行加权平均或加权投票。</p><h3 id="KNN算法描述"><a href="#KNN算法描述" class="headerlink" title="KNN算法描述"></a>KNN算法描述</h3><p>下面以<font color="#008B8B">分类</font>任务为例，介绍KNN算法，回归任务与此类似，区别不大。</p><p>输入：训练数据集<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>D</mi><mo>=</mo><mo>{</mo><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo><msubsup><mo>}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup></math>    ，其中，<img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625492364666.png"> 是实例的类别。<br>过程：</p><ul><li>根据给定的距离度量，在训练集D中找出与x最邻近的k个点，涵盖着k 个点的领域记为<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>x</mi><mo>)</mo></math>；</li><li>在<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>x</mi><mo>)</mo></math>中根据分类决策规则决定x的类别y： <img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625492543638.png" alt="所属类别"><br>输出：测试样本x xx所属的类别y yy。</li></ul><h2 id="KNN算法实现"><a href="#KNN算法实现" class="headerlink" title="KNN算法实现"></a>KNN算法实现</h2><h3 id="KNN算法蛮力实现"><a href="#KNN算法蛮力实现" class="headerlink" title="KNN算法蛮力实现"></a>KNN算法蛮力实现</h3><p> 首先我们看看最想当然的方式。</p><pre><code> 既然我们要找到k个最近的邻居来做预测，那么我们只需要计算预测样本和所有训练集中的样本的距离，然后计算出最小的k个距离即可，接着多数表决，很容易做出预测。这个方法的确简单直接，在样本量少，样本特征少的时候有效。但是在实际运用中很多时候用不上，为什么呢？因为我们经常碰到样本的特征数有上千以上，样本量有几十万以上，如果我们这要去预测少量的测试集样本，算法的时间效率很成问题。因此，这个方法我们一般称之为蛮力实现。&lt;font color=&quot;#1E90FF&quot;&gt;比较适合于少量样本的简单模型的时候用&lt;/font&gt;。</code></pre><h3 id="KD树实现原理"><a href="#KD树实现原理" class="headerlink" title="KD树实现原理"></a>KD树实现原理</h3><pre><code>KD树算法没有一开始就尝试对测试样本分类，而是先对训练集建模，建立的模型就是KD树，建好了模型再对测试集做预测。所谓的KD树就是K个特征维度的树，注意这里的K和KNN中的K的意思不同。KNN中的K代表特征输出类别，KD树中的K代表样本特征的维数。为了防止混淆，后面我们称特征维数为n。</code></pre><p>KD树算法包括三步，第一步是建树，第二部是搜索最近邻，最后一步是预测。</p><h4 id="KD树的建立"><a href="#KD树的建立" class="headerlink" title="KD树的建立"></a>KD树的建立</h4><p>我们首先来看建树的方法。KD树建树采用的是从m个样本的n维特征中，分别计算n个特征的取值的方差，用<font color="#DC143C">方差最大</font>的第k维特征<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mi>k</mi></msub></math>来作为<font color="#B22222">根节点</font>。对于这个特征，我们选择特征<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mi>k</mi></msub></math>的取值的中位数<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mi>kv</mi></msub></math>对应的样本作为划分点，对于所有第k维特征的取值小于<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mi>kv</mi></msub></math>的样本，我们划入左子树，对于第k维特征的取值大于等于<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mi>kv</mi></msub></math>的样本，我们划入右子树，对于左子树和右子树，我们采用和刚才同样的办法来找方差最大的特征来做<font color="#B22222">根节点，递归</font>的生成KD树。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625494718364.png" alt="构建KD树"></p><p>比如我们有二维样本6个，{(2,3)，(5,4)，(9,6)，(4,7)，(8,1)，(7,2)}，构建kd树的具体步骤为：</p><ol><li>找到划分的特征。6个数据点在x，y维度上的数据方差分别为6.97，5.37，所以在x轴上方差更大，用第1维特征建树。</li><li>确定划分点（7,2）。根据x维上的值将数据排序，6个数据的中值(所谓中值，即中间大小的值)为7，所以划分点的数据是（7,2）。这样，该节点的分割超平面就是通过（7,2）并垂直于：划分点维度的直线x=7；（很显然，中位数为6 ，这里选择（5,4）或者(7,2)都是可以的。这种情况任选一个即可）</li><li>确定左子空间和右子空间。 分割超平面x=7将整个空间分为两部分：x&lt;=7的部分为左子空间，包含3个节点={(2,3),(5,4),(4,7)}；另一部分为右子空间，包含2个节点={(9,6)，(8,1)}。</li><li>用同样的办法划分左子树的节点{(2,3),(5,4),(4,7)}和右子树的节点{(9,6)，(8,1)}。最终得到KD树。</li><li>后续步骤反复上面的，<font color="#8FBC8F">直到两个子区域没有实例存在时停止（这意味着最后所有训练实例都对应一个叶结点或内部结点），从而形成kd树的区域划分</font>。</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625495422262.png" alt="KD树"></p><p><font color="#DC143C">标准kNN算法的切分特征选择是按顺序的，后来对kd树的一个重大改进是选择方差最大的特征，方差越大，不同实例点区分越明显，更方便进行划分。</font></p><h4 id="KD树搜索最近邻"><a href="#KD树搜索最近邻" class="headerlink" title="KD树搜索最近邻"></a>KD树搜索最近邻</h4><p>当我们生成KD树以后，就可以去预测测试集里面的样本目标点了。对于一个目标点，我们<font color="#9932CC">首先在KD树里面找到包含目标点的叶子节点</font>。<font color="#0000FF">以目标点为圆心，以目标点到叶子节点样本实例的距离为半径，得到一个超球体</font>，<font color="#B22222">最近邻的点一定在这个超球体内部</font>。然后返回叶子节点的父节点，检查另一个子节点包含的超矩形体是否和超球体相交，如果相交就到这个子节点寻找是否有更加近的近邻,有的话就更新最近邻。如果不相交那就简单了，我们直接返回父节点的父节点，在另一个子树继续搜索最近邻。当回溯到根节点时，算法结束，此时保存的最近邻节点就是最终的最近邻。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625496230689.png" alt="目标点为（2，4.5）"></p><p>从上面的描述可以看出，KD树划分后可以大大减少无效的最近邻搜索，很多<font color="#8A2BE2">样本点由于所在的超矩形体和超球体不相交，根本不需要计算距离。大大节省了计算时间。</font></p><p>先进行二叉查找，先从（7,2）查找到（5,4）节点，在进行查找时是由y = 4为分割超平面的，由于查找点为y值为4.5，因此进入右子空间查找到（4,7），形成搜索路径&lt;(7,2)，(5,4)，(4,7)&gt;，但 （4,7）与目标查找点的距离为3.202，而（5,4）与查找点之间的距离为3.041，所以（5,4）为查询点的最近点； 以（2，4.5）为圆心，以3.041为半径作圆，如下图所示。可见该圆和y = 4超平面交割，所以需要进入（5,4）左子空间进行查找，也就是将（2,3）节点加入搜索路径中得&lt;(7,2)，(2,3)&gt;；于是接着搜索至（2,3）叶子节点，（2,3）距离（2,4.5）比（5,4）要近，所以最近邻点更新为（2，3），最近距离更新为1.5；回溯查找至（5,4），直到最后回溯到根结点（7,2）的时候，以（2,4.5）为圆心1.5为半径作圆，并不和x = 7分割超平面交割，如下图所示。至此，搜索路径回溯完，返回最近邻点（2,3），最近距离1.5。</p><h3 id="球树实现原理"><a href="#球树实现原理" class="headerlink" title="球树实现原理"></a>球树实现原理</h3><p>KD树算法虽然提高了KNN搜索的效率，但是在某些时候效率并不高，比如当处理不均匀分布的数据集时,不管是近似方形，还是矩形，甚至正方形，都不是最好的使用形状，因为他们都有角。一个例子如下图：<br><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625496491462.png" alt="enter description here"></p><p>　　如果黑色的实例点离目标点星点再远一点，那么虚线圆会如红线所示那样扩大，导致与左上方矩形的右下角相交，既然相 交了，那么就要检查这个左上方矩形，而实际上，最近的点离星点的距离很近，检查左上方矩形区域已是多余。于此我们看见，KD树把二维平面划分成一个一个矩形，但矩形区域的角却是个难以处理的问题。</p><p>　　为了优化超矩形体导致的搜索效率的问题，有人引入了球树，这种结构可以优化上面的这种问题。</p><p><strong><font color="#7FFF00">球树的建立</font></strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202175/1625496601030.png" alt="球树"></p><ol><li>先构建一个超球体，这个超球体是可以包含所有样本的最小球体。</li><li>从球中选择一个离球的中心最远的点，然后选择第二个点离第一个点最远，将球中所有的点分配到离这两个聚类中心最近的一个上，然后计算每个聚类的中心，以及聚类能够包含它所有数据点所需的最小半径。这样我们得到了两个子超球体，和KD树里面的左右子树对应。（PS:<font color="#B22222">这里选择两个点后，就以这两个点来聚类，所以先确定的是以这两个点为中心来计算其他点到该中心的距离。当所有点都确定自己的中心后，再重新计算一次该超球体的半径和球心</font>。）</li><li>对于这两个子超球体，递归执行步骤2，最终得到了一个球树。</li></ol><p>　　可以看出KD树和球树类似，主要区别在于球树得到的是节点样本组成的最小超球体，而KD得到的是节点样本组成的超矩形体，这个超球体要与对应的KD树的超矩形体小，这样在做最近邻搜索的时候，可以避免一些无谓的搜索。</p><h2 id="KNN优缺点"><a href="#KNN优缺点" class="headerlink" title="KNN优缺点"></a>KNN优缺点</h2><p>优点：</p><ol><li>结构简单；</li><li>无数据输入假定，准确度高，对异常点不敏感。</li><li> 训练时间复杂度比支持向量机之类的算法低，仅为O(n)</li><li> 由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合</li></ol><p>缺点：</p><ol><li>计算复杂度高、空间复杂度高；</li><li>样本不平衡时，对稀有类别预测准确度低；</li><li>使用懒惰学习，预测速度慢。</li><li>KD树，球树之类的模型建立需要大量的内存</li><li>相比决策树模型，KNN模型可解释性不强<h2 id="什么情况下选择KNN"><a href="#什么情况下选择KNN" class="headerlink" title="什么情况下选择KNN"></a>什么情况下选择KNN</h2></li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625667539256.png" alt="choose"></p><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p><a href="https://www.cnblogs.com/ybjourney/p/4702562.html">机器学习（一）——K-近邻（KNN）算法 - Yabea - 博客园</a></p><h2 id="序列KNN"><a href="#序列KNN" class="headerlink" title="序列KNN"></a>序列KNN</h2><p><a href="https://antkillerfarm.github.io/ml/2017/10/19/Machine_Learning_28.html">机器学习（二十八）——KNN, AutoML, 数据不平衡问题</a></p><p><a href="https://blog.csdn.net/qq_41196612/article/details/107265167">R语言实战——基于KNN聚类的时间序列分析预测_三只佩奇不结义的博客-CSDN博客_r语言knn回归及预测</a></p><p><a href="https://www.coder.work/article/383913">python - 如何使用 KNN/K-means 对数据帧中的时间序列进行聚类 - IT工具网</a></p><p><a href="https://github.com/iwuqing/Time-Series-Classification-based-on-KNN">iwuqing/Time-Series-Classification-based-on-KNN: 基于KNN聚类算法结合Dynamic Time Warping（动态时间调整）的时间序列分类</a></p><p><a href="https://github.com/vvanggeng/TSC-KNN">vvanggeng/TSC-KNN: 基于KNN和DTW的时间序列分类</a></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> paper </tag>
            
            <tag> algorithm </tag>
            
            <tag> machine leaning </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markov Model（马尔可夫模型）</title>
      <link href="/2021/07/05/Markov%20Model%EF%BC%88%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%89/"/>
      <url>/2021/07/05/Markov%20Model%EF%BC%88%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/mantch/p/11203748.html">一次性弄懂马尔可夫模型、隐马尔可夫模型、马尔可夫网络和条件随机场！(词性标注代码实现) - mantch - 博客园</a></p><h2 id="马尔可夫网络、马尔可夫模型、马尔可夫过程、贝叶斯网络的区别"><a href="#马尔可夫网络、马尔可夫模型、马尔可夫过程、贝叶斯网络的区别" class="headerlink" title="马尔可夫网络、马尔可夫模型、马尔可夫过程、贝叶斯网络的区别"></a>马尔可夫网络、马尔可夫模型、马尔可夫过程、贝叶斯网络的区别</h2><p>共分六点说明这些概念【<font color="#DC143C">这6点是依次递进的，不要跳跃着看</font>】：</p><ol><li>将随机变量作为结点，若两个随机变量相关或者不独立，则将二者连接一条边；若给定若干随机变量，则形成一个有向图，即构成一个<strong>网络</strong>。</li><li>如果该网络是有向无环图，则这个网络称为<strong>贝叶斯网络</strong>。</li><li>如果这个图退化成线性链的方式，则得到<strong>马尔可夫模型</strong>；因为每个结点都是随机变量，将其看成各个时刻(或空间)的相关变化，以随机过程的视角，则可以看成是<strong>马尔可夫过程</strong>。</li><li>若上述网络是无向的，则是无向图模型，又称<strong>马尔可夫随机场</strong>或者<strong>马尔可夫网络</strong>。</li><li>如果在给定某些条件的前提下，研究这个马尔可夫随机场，则得到<strong>条件随机场</strong>。</li><li>如果使用条件随机场解决标注问题，并且进一步将条件随机场中的网络拓扑变成线性的，则得到<strong>线性链条件随机场</strong>。</li></ol><h2 id="马尔可夫模型"><a href="#马尔可夫模型" class="headerlink" title="马尔可夫模型"></a>马尔可夫模型</h2><h3 id="马尔可夫过程"><a href="#马尔可夫过程" class="headerlink" title="马尔可夫过程"></a>马尔可夫过程</h3><p>马尔可夫过程（Markov process）是一类<font color="#00FFFF">随机</font>过程。它的原始模型是马尔可夫链。<br>该过程具有如下特性：在已知目前状态（现在）的条件下，它未来的演变（将来）<font color="#0000FF">不依赖</font>于它以往的演变 (过去 )。</p><p>每个状态的转移只依赖于之前的n个状态，这个过程被称为1个n阶的模型，其中n是影响转移状态的数目。最简单的马尔可夫过程就是一阶过程，<font color="#006400">每一个状态的转移只依赖于其之前的那一个状态</font>，这个也叫作<strong>马尔可夫性质</strong>。</p><p>假设这个模型的每个状态都只依赖于之前的状态，这个假设被称为<font color="#1E90FF">马尔科夫假设</font>，这个假设可以大大的简化这个问题。显然，这个假设可能是一个非常糟糕的假设，导致很多重要的信息都丢失了。<br><img src="https://gitee.com/merlynr/img-store/raw/master/202176/1625557564343.png"></p><p>假设天气服从<strong>马尔可夫链</strong>：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202176/1625557700847.png" alt="天气"></p><p>从上面这幅图可以看出：</p><ul><li>假如今天是晴天，明天变成阴天的概率是0.1</li><li>假如今天是晴天，明天任然是晴天的概率是0.9，和上一条概率之和为1，这也符合真实生活的情况。</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202178/1625728052403.png" alt="表格"></p><p>由上表我们可以得到马尔可夫链的<strong>状态转移矩阵</strong>：<br><img src="https://gitee.com/merlynr/img-store/raw/master/202176/1625557951076.png" alt="状态转移矩阵"></p><p>因此，一阶马尔可夫过程定义了以下三个部分：</p><ul><li>状态：晴天和阴天</li><li>初始向量：定义系统在时间为0的时候的状态的概率</li><li>状态转移矩阵：每种天气转换的概率</li></ul><p>马尔可夫模型（Markov Model）是一种<font color="#DC143C">统计模型</font>，广泛应用在语音识别，词性自动标注，音字转换，概率文法等各个自然语言处理等应用领域。经过长期发展，尤其是在语音识别中的成功应用，使它成为一种通用的统计工具。到目前为止，它一直被认为是实现快速精确的语音识别系统的最成功的方法。</p><h2 id="隐马尔可夫模型（HMM）"><a href="#隐马尔可夫模型（HMM）" class="headerlink" title="隐马尔可夫模型（HMM）"></a>隐马尔可夫模型（HMM）</h2><blockquote><p> 在某些情况下马尔科夫过程不足以描述我们希望发现的模式。回到之前那个天气的例子，一个隐居的人可能不能直观的观察到天气的情况，但是有一些海藻。民间的传说告诉我们海藻的状态在某种概率上是和天气的情况相关的。在这种情况下我们有两个状态集合，一个可以观察到的状态集合（海藻的状态）和一个隐藏的状态（天气的状况）。我们希望能找到一个算法可以根据海藻的状况和马尔科夫假设来预测天气的状况。</p></blockquote><p>而这个算法就叫做**隐马尔可夫模型(HMM)**。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202176/1625559690747.png" alt="HMM"></p><p>隐马尔可夫模型 (Hidden Markov Model) 是一种<strong>统计模型</strong>，用来描述一个含有隐含未知参数的马尔可夫过程。<strong>它是结构最简单的动态贝叶斯网，这是一种著名的有向图模型，</strong> 主要用于<font color="#FF00FF">时序</font>数据建模，在语音识别、自然语言处理等领域有广泛应用。</p><h3 id="隐马尔可夫三大问题"><a href="#隐马尔可夫三大问题" class="headerlink" title="隐马尔可夫三大问题"></a>隐马尔可夫三大问题</h3><p><font color="#9400D3">注意</font></p><ol><li>给定模型，如何有效计算产生观测序列的概率？换言之，如何评估模型与观测序列之间的<font color="#FF1493">匹配程度</font>？</li><li>给定模型和观测序列，如何找到与此观测序列最匹配的状态序列？换言之，如何根据观测序列推断出隐藏的<font color="#B22222">模型状态</font>？</li><li>给定观测序列，如何调整模型参数使得该序列出现的概率最大？换言之，如何训练模型使其能最好地<font color="#B22222">描述</font>观测数据？</li></ol><p>前两个问题是模式识别的问题：1) 根据隐马尔科夫模型得到一个可观察状态序列的概率(<strong>评价</strong>)；2) 找到一个隐藏状态的序列使得这个序列产生一个可观察状态序列的概率最大(<strong>解码</strong>)。第三个问题就是根据一个可以观察到的状态序列集产生一个隐马尔科夫模型（<strong>学习</strong>）。</p><p>对应的三大问题解法：</p><ol><li>向前算法(Forward Algorithm)、向后算法(Backward Algorithm)</li><li>维特比算法(Viterbi Algorithm)</li><li>鲍姆-韦尔奇算法(Baum-Welch Algorithm) (约等于EM算法)</li></ol><blockquote><p>小明现在有三天的假期，他为了打发时间，可以在每一天中选择三件事情来做，这三件事情分别是散步、购物、打扫卫生(<strong>对应着可观测序列</strong>)，可是在生活中我们所做的决定一般都受到天气的影响，可能晴天的时候想要去购物或者散步，可能下雨天的时候不想出门，留在家里打扫卫生。而天气(晴天、下雨天)就属于<strong>隐藏状态</strong>，用一幅概率图来表示这一马尔可夫过程：</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/202176/1625563725550.png" alt="场景"></p><p>那么，我们提出三个问题，分别对应马尔可夫的<font color="#B22222">三大</font>问题：</p><ol><li>已知整个模型，我观测到连续三天做的事情是：散步，购物，收拾。那么，根据模型，计算产生这些行为的概率是多少。</li><li>同样知晓这个模型，同样是这三件事，我想猜，这三天的天气是怎么样的。</li><li>最复杂的，我只知道这三天做了这三件事儿，而其他什么信息都没有。我得建立一个模型，晴雨转换概率，第一天天气情况的概率分布，根据天气情况选择做某事的概率分布。</li></ol><h3 id="第一个问题解法"><a href="#第一个问题解法" class="headerlink" title="第一个问题解法"></a>第一个问题解法</h3><ol><li><strong>遍历算法</strong></li></ol><p>假设第一天(T=1 时刻)是晴天，想要购物，那么就把图上的对应概率相乘就能够得到了。<br>第二天(T=2 时刻)要做的事情，在第一天的概率基础上乘上第二天的概率，依次类推，最终得到这三天(T=3 时刻)所要做的事情的概率值，这就是遍历算法，简单而又粗暴。但问题是<font color="#2F4F4F">用遍历算法的复杂度会随着观测序列和隐藏状态的增加而成指数级增长。</font></p><p><font color="#B22222">复杂度为</font>：<math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mi>T</mi><msup><mi>N</mi><mi>T</mi></msup></math></p><p><font color="#8A2BE2">理解：</font>每次计算行为发生概率都从最开始遍历计算</p><ol start="2"><li><p><strong>前向算法</strong></p><ol><li>假设第一天要购物，那么就计算出第一天购物的概率(包括晴天和雨天)；假设第一天要散步，那么也计算出来，依次枚举。</li><li>假设前两天是购物和散步，也同样计算出这一种的概率；假设前两天是散步和打扫卫生，同样计算，枚举出前两天行为的概率。</li><li>第三步就是计算出前三天行为的概率。</li></ol></li></ol><p>第二步中要求的概率可以在第一步的基础上进行，同样的，第三步也会<font color="#0000FF">依赖</font>于第二步的计算结果。那么这样做就能够<strong>节省很多计算环节，类似于动态规划</strong>。</p><p><font color="#B22222">复杂度为</font>：<math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>N</mi><mn>2</mn></msup><mi>T</mi></math></p><ol start="3"><li>后向算法</li></ol><p>跟前向算法相反，我们知道总的概率肯定是1，那么B_t=1，也就是最后一个时刻的概率合为1，先计算前三天的各种可能的概率，在计算前两天、前一天的数据，<font color="#696969">跟前向算法相反</font>的计算路径。</p><h3 id="第二个问题解法"><a href="#第二个问题解法" class="headerlink" title="第二个问题解法"></a>第二个问题解法</h3><ol><li>维特比算法（Viterbi）</li></ol><blockquote><p>维特比算法是一个特殊但应用最广的<strong>动态规划算法</strong>。利用动态规划，可以解决任何一个图中的<strong>最短</strong>路径问题。而维特比算法是针对一个特殊的图—篱笆网络（Lattice）的有向图最短路径问题而提出的。它之所以重要，是因为凡是使用<font color="#057748">隐含马尔可夫模型</font>描述的问题都可以用它来解码，包括今天的数字通信、语音识别、机器翻译、拼音转汉字、分词等。</p></blockquote><p>维特比算法一般用于模式识别，通过观测数据来<font color="#FF1493">反推出隐藏状态</font>。</p><p>因为是要根据观测数据来反推，所以这里要进行一个假设，<strong>假设这三天所做的行为分别是：散步、购物、打扫卫生</strong>，那么我们要求的是这三天的天气(路径)分别是什么。</p><ol><li>初始计算第一天下雨和第一天晴天去散步的概率值：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>△</mi><mn>1</mn></msub><mo>(</mo><mi>R</mi><mo>)</mo></math>表示第一天下雨的概率<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>&#x3C0;</mi><mi>R</mi></msub></math>表示中间的状态(下雨)概率<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>b</mi><mi>R</mi></msub><mo>(</mo><msub><mi>O</mi><mn>1</mn></msub><mo>=</mo><mi>w</mi><mo>)</mo></math>表示下雨并且散步的概率<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>a</mi><mrow><mi>R</mi><mo>-</mo><mi>R</mi></mrow></msub></math>表示下雨天到下雨天的概率</li></ol><p><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>△</mi><mn>1</mn></msub><mo>(</mo><mi>R</mi><mo>)</mo></math>=<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>&#x3C0;</mi><mi>R</mi></msub><mo>*</mo><msub><mi>b</mi><mi>R</mi></msub><mo>(</mo><msub><mi>O</mi><mn>1</mn></msub><mo>=</mo><mi>w</mi><mo>)</mo></math>=0.6 * 0.1 = 0.06</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>△</mi><mn>1</mn></msub><mo>(</mo><mi>S</mi><mo>)</mo></math>=<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>&#x3C0;</mi><mi>S</mi></msub><mo>*</mo><msub><mi>b</mi><mi>S</mi></msub><mo>(</mo><msub><mi>O</mi><mn>1</mn></msub><mo>=</mo><mi>w</mi><mo>)</mo></math>=0.4 * 0.6 = 0.24</p><p><font color="#006400">初始路径</font>为：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>&#x3D5;</mi><mn>1</mn></msub><mo>(</mo><mi>R</mi><mo>)</mo></math>=Rainy<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>&#x3D5;</mi><mn>1</mn></msub><mo>(</mo><mi>S</mi><mo>)</mo></math>=Sunny</p><ol start="2"><li>计算第二天下雨和第二天晴天去购物的概率值:</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625641072263.png" alt="行为概率"></p><p><font color="#00FFFF">对应路径为：</font></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625642052293.png" alt="对应路径"></p><ol start="3"><li>计算第三天下雨和第三天晴天去打扫卫生的概率值：</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625642832307.png" alt="第三天概率"></p><p><font color="#228B22">对应路径为：</font></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625642928241.png" alt="行为路径"></p><ol start="4"><li><p>比较每一步中△的概率大小，选取最大值并找到对应的路径，依次类推就能找到最有可能的隐藏状态路径。</p><ol><li>第一天的概率最大值为 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>△</mi><mn>1</mn></msub><mi>S</mi></math>，对应路径为Sunny，</li><li>第二天的概率最大值为 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>△</mi><mn>2</mn></msub><mi>S</mi></math>，对应路径为Sunny，</li><li>第三天的概率最大值为 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>△</mi><mn>3</mn></msub><mi>S</mi></math>，对应路径为Rainy。</li></ol></li><li><p>合起来的路径就是Sunny-&gt;Sunny-&gt;Rainy，这就是我们所求。</p></li></ol><h3 id="第三个问题解法"><a href="#第三个问题解法" class="headerlink" title="第三个问题解法"></a>第三个问题解法</h3><p>鲍姆-韦尔奇算法(Baum-Welch Algorithm) (约等于<strong>EM</strong>算法)</p><p>如果训练数据只有观测序列而没有状态序列，即{<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>O</mi><mn>1</mn></msub><mo>,</mo><msub><mi>O</mi><mn>2</mn></msub><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msub><mi>O</mi><mi>S</mi></msub></math>}此时HMM的学习就得使用EM算法了，这是<font color="#FF1493">非监督</font>学习。</p><p>通常，如果给定数据和已经模型，那么求模型参数我们会用<font color="#8A2BE2">极大似然估计法</font>，但是<font color="#8B008B">如果变量中含有隐变量，无法用极大似然求解</font>（对数式子里面有求和，难以求出解析解），此时就可以使用EM算法。考虑HMM，观测序列 O是显变量，而状态变量I  则是隐变量，所以HMM实际上是<font color="#556B2F">含有隐变量的概率模型</font></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625646003916.png" alt="HMM的概率模型 | λ为模型参数"></p><blockquote><p><font color="#00FFFF">知识补充</font><br>极大似然估计<br>利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值！<br>换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“<font color="#FF8C00">模型已定，参数未知</font>”。</p></blockquote><p>可以使用EM算法来求得模型参数。</p><p>关于EM算法流程，有多个版本，但是仔细学习可以发现是大同小异的，以下使用《统计学习方法》上介绍的EM算法流程。</p><p><a href="https://blog.csdn.net/qq_37334135/article/details/86302735">HMM学习笔记（二）：监督学习方法与Baum-Welch算法_成都往右的博客-CSDN博客</a></p><h2 id="马尔可夫网络"><a href="#马尔可夫网络" class="headerlink" title="马尔可夫网络"></a>马尔可夫网络</h2><h3 id="因子图"><a href="#因子图" class="headerlink" title="因子图"></a>因子图</h3><p>WiKIpedia：将一个具有多变量的全局函数因子分解，得到几个局部函数的乘积，以此为基础得到的一个双向图叫做<font color="#00CED1">因子图</font>（Factor Graph）。</p><p>通俗来讲，所谓因子图就是对函数进行因子分解得到的一种<strong>概率图</strong>。一般内含两种节点：变量节点和函数节点。我们知道，一<font color="#FF1493">个全局函数通过因式分解能够分解为多个局部函数的乘积</font>，这些局部函数和对应的变量关系就体现在因子图上。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625649785149.png" alt="栗子"></p><p>其中fA,fB,fC,fD,fE为各函数，表示变量之间的关系，可以是条件概率也可以是其他关系。其对应的因子图为：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625659847778.png" alt="变量-函数之间因子图"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625659895044.png" alt="变量-函数之间因子图"></p><h3 id="马尔可夫网络-1"><a href="#马尔可夫网络-1" class="headerlink" title="马尔可夫网络"></a>马尔可夫网络</h3><blockquote><p>我们已经知道，<strong>有向</strong>图模型，又称作<font color="#bf242a">贝叶斯网络</font>，但在有些情况下，强制对某些结点之间的边增加方向是不合适的。<strong>使用没有方向的无向边，形成了无向图模型</strong>（Undirected Graphical Model,UGM）, 又被称为<strong>马尔可夫随机场或者马尔可夫网络</strong>（Markov Random Field, MRF or Markov network）。</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625660204643.png" alt="MRF"></p><p>设X=(X1,X2…Xn)和Y=(Y1,Y2…Ym)都是<font color="#006400">联合随机变量</font>，若随机变量Y构成一个无向图 G=(V,E)表示的马尔可夫随机场（MRF），则条件概率分布P(Y|X)称为<strong>条件随机场</strong>（Conditional Random Field, 简称CRF，后续新的博客中可能会阐述CRF）。如下图所示，便是一个线性链条件随机场的无向图模型：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625664493380.png" alt="CRF"></p><p>在概率图中，求某个变量的边缘分布是常见的问题。这问题有很多求解方法，其中之一就是<font color="#A52A2A">把贝叶斯网络或马尔可夫随机场转换成因子图，然后用sum-product算法求解</font>。换言之，基于因子图可以用<strong>sum-product 算法</strong>高效的求各个变量的边缘分布。</p><p>详细的sum-product算法过程，请查看博文：<a href="https://blog.csdn.net/v_july_v/article/details/40984699">从贝叶斯方法谈到贝叶斯网络_结构之法 算法之道-CSDN博客_贝叶斯</a></p><h2 id="条件随机场-CRF"><a href="#条件随机场-CRF" class="headerlink" title="条件随机场(CRF)"></a>条件随机场(CRF)</h2><p><strong>一个通俗的例子</strong></p><p>假设你有许多小明同学一天内不同时段的照片，从小明提裤子起床到脱裤子睡觉各个时间段都有（小明是照片控！）。现在的任务是对这些照片进行分类。比如有的照片是吃饭，那就给它打上吃饭的标签；有的照片是跑步时拍的，那就打上跑步的标签；有的照片是开会时拍的，那就打上开会的标签。问题来了，你准备怎么干？</p><p>一个简单直观的办法就是，不管这些照片之间的时间顺序，想办法训练出一个多元分类器。就是用一些打好标签的照片作为训练数据，训练出一个模型，直接根据照片的特征来分类。例如，如果照片是早上6:00拍的，且画面是黑暗的，那就给它打上睡觉的标签;如果照片上有车，那就给它打上开车的标签。</p><p>乍一看可以！但实际上，由于我们忽略了这些照片之间的时间顺序这一重要信息，我们的分类器会有缺陷的。举个例子，假如有一张小明闭着嘴的照片，怎么分类？显然难以直接判断，需要参考闭嘴之前的照片，如果之前的照片显示小明在吃饭，那这个闭嘴的照片很可能是小明在咀嚼食物准备下咽，可以给它打上吃饭的标签；如果之前的照片显示小明在唱歌，那这个闭嘴的照片很可能是小明唱歌瞬间的抓拍，可以给它打上唱歌的标签。</p><p>所以，为了让我们的分类器能够有更好的表现，<strong>在为一张照片分类时，我们必须将与它相邻的照片的标签信息考虑进来</strong>。这——就是条件随机场(CRF)大显身手的地方！这就有点类似于词性标注了，只不过把照片换成了句子而已，本质上是一样的。</p><p>如同马尔可夫随机场，条件随机场为具有<strong>无向</strong>的图模型，图中的顶点代表随机变量，顶点间的连线代表随机变量间的相依关系，在条件随机场中，随机变量Y 的分布为条件机率，给定的观察值则为随机变量 X。下图就是一个线性连条件随机场。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202177/1625665022911.png" alt="线性连条件随机场"></p><p>条件概率分布P(Y|X)称为条件随机场。</p><h2 id="EM算法、HMM、CRF的比较"><a href="#EM算法、HMM、CRF的比较" class="headerlink" title="EM算法、HMM、CRF的比较"></a>EM算法、HMM、CRF的比较</h2><ol><li><strong>EM算法</strong>是<font color="#8FBC8F">用于含有隐变量模型</font>的极大似然估计或者极大后验估计，有两步组成：E步，求期望（expectation）；M步，求极大（maxmization）。本质上EM算法还是一个迭代算法，通过不断用上一代参数对隐变量的估计来对当前变量进行计算，直到收敛。注意：EM算法是对初值敏感的，而且EM是不断求解下界的极大化逼近求解对数似然函数的极大化的算法，也就是说<font color="#B22222">EM算法不能保证找到全局最优值</font>。对于EM的导出方法也应该掌握。</li><li><strong>隐马尔可夫模型</strong>是<font color="#8FBC8F">用于标注问题的生成模型</font>。有几个参数（π，A，B）：初始状态概率向量π，状态转移矩阵A，观测概率矩阵B。称为马尔科夫模型的三要素。马尔科夫三个基本问题：<br>  <strong>概率计算问题</strong>：给定模型和观测序列，计算模型下观测序列输出的概率。–》前向后向算法<br> <strong>学习问题</strong>：已知观测序列，估计模型参数，即用极大似然估计来估计参数。–》Baum-Welch(也就是EM算法)和极大似然估计。<br> <strong>预测问题</strong>：已知模型和观测序列，求解对应的状态序列。–》近似算法（贪心算法）和维比特算法（动态规划求最优路径）</li><li><strong>条件随机场CRF</strong>，给定一组输入随机变量的条件下另一组输出随机变量的条件概率分布密度。条件随机场假设输出变量构成马尔科夫随机场，而我们平时看到的大多是线性链条随机场，也就是由输入对输出进行预测的判别模型。求解方法为<font color="#B22222">极大似然估计或正则化的极大似然估计。</font></li><li>之所以总把HMM和CRF进行比较，主要是因为CRF和HMM都利用了图的知识，但是CRF利用的是马尔可夫随机场（无向图），而HMM的基础是贝叶斯网络（有向图）。而且CRF也有概率计算问题、学习问题和预测问题。大致计算方法和HMM类似，只不过不需要EM算法进行学习问题。</li><li>HMM和CRF对比：其根本还是在于基本的理念不同，一个是生成模型，一个是判别模型，这也就导致了求解方式的不同。</li></ol>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> paper </tag>
            
            <tag> algorithm </tag>
            
            <tag> machine leaning </tag>
            
            <tag> deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用于业务流程事件和结果预测的混合模型</title>
      <link href="/2021/07/05/%E7%94%A8%E4%BA%8E%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E4%BA%8B%E4%BB%B6%E5%92%8C%E7%BB%93%E6%9E%9C%E9%A2%84%E6%B5%8B%E7%9A%84%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/"/>
      <url>/2021/07/05/%E7%94%A8%E4%BA%8E%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E4%BA%8B%E4%BB%B6%E5%92%8C%E7%BB%93%E6%9E%9C%E9%A2%84%E6%B5%8B%E7%9A%84%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>对于多样性流程进行异常预测</p><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><ol><li>序列k近邻法（KNN）</li><li>基于序列比对的马尔科夫模型扩展法</li></ol><p><font color="#1E90FF">思路：</font><br>利用数据的时间分类特征，利用高阶马尔可夫模型预测过程的下一步，并利用序列对比技术预测过程的结果。通过考虑基于k个最近邻的相似过程序列的子集，增加了数据的多样性方面。</p><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>已经证明，通过一组实验，序列k最近邻提法比原始提供更好的结果;我们的扩展马尔可夫模型优于随机猜测、马尔可夫模型和隐马尔可夫模型。</p><blockquote><p><font color="#2e4e7e">知识补充</font><br><a href="https://blog.zuishuailcq.xyz/2021/07/05/KNN%EF%BC%88K%E8%BF%91%E9%82%BB%E6%B3%95%20K%20Nearest%20Neighbors%EF%BC%89/">KNN（K近邻法 K Nearest Neighbors） | 吾辈之人，自当自强不息！</a><br><a href="https://blog.zuishuailcq.xyz/2021/07/05/Markov%20Model%EF%BC%88%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%89/">Markov Model（马尔可夫模型） | 吾辈之人，自当自强不息！</a></p></blockquote><h2 id="阐述"><a href="#阐述" class="headerlink" title="阐述"></a>阐述</h2><p>在进行流程预测的前，我们需要从日志中挖掘流程。通过分析数据，可以得知数据为带有<strong>时间序列</strong>的数据。1999年已经有人证明MMs适用于研究用户网上浏览行为。同时事件序列也可用于训练已经<strong>编码后续事件之间的转换概率</strong>的马尔可夫模型，<br>类似其它机器学习模型，越是高阶的模型越是拟合数据，预测结果也更加准确。</p><blockquote><p><font color="#FF1493">知识补充</font><br>在马尔可夫链的每一步，系统根据概率分布，可以从一个状态变到另一个状态,也可以保持当前状态。状态的改变叫做过渡，与不同的状态改变相关的概率叫做<strong>过渡概率</strong><br><font color="#006400">TODO </font>默认预测的提出没有仔细研究<br>当给定数据集很少时，导致无法机器学习和准确预测，所以为了解决这个问题，提出了几个为了解决特征和默认事件之间的非线性依赖关系的模型，通过补充特征默认值来补充数据，进行预测。<strong>默认预测</strong></p></blockquote><p>但是当数据多样化同时不聚集的时候，会导致高阶模型弱覆盖，对于未被覆盖的序列，就需要默认预测。但是默认预测会降低模型的准确度。<br><em>在马尔可夫模型中</em>，为了平衡覆盖与准确性，一般解决思想是合并多个不同阶的MMs的转换状态，然后在预测的时候遵循“冗余”状态。例如可选择马尔可夫模型（selective Markov model）</p><blockquote><p>TODO<br>遵循“冗余”状态的实际意义是什么？它的实际表现是什么<br>an extension of All Kth order Markov models (Deshpande &amp; Karypis, 2004)</p></blockquote><blockquote><p><font color="#2F4F4F">知识补充</font><br>个人理解<strong>弱覆盖</strong>是由于特征广而弱，无法高效学习，导致有一些特征被丢弃没有学习到。</p></blockquote><p>第二部部分讲述的是采用kNN算法来预测过程结果，即通过比对给定领域内的序列，找到最相似的序列。06年有研究者发表“预测使用电信公司的数据流失”，用欧几里德距离来计算给定序列与样本之间的距离。</p><blockquote><p>TODO 生物顺序结合没懂</p></blockquote><p>在本文中作者将KNN与生物学的序列对齐组合形成顺序kNN。</p><blockquote><p><font color="#bf242a">知识补充</font><br><strong>编辑距离</strong>是针对二个字符串（例如英文字）的差异程度的量化量测，量测方式是看至少需要多少次的处理才能将一个字符串变成另一个字符串。</p></blockquote><h3 id="creation"><a href="#creation" class="headerlink" title="creation"></a>creation</h3><blockquote><p>TODO 不理解下面的匹配机制</p></blockquote><p>首先是为了解决高阶MMs弱覆盖，提出了MMs和序列对准融合的技术。当预测模型无法找到预测实例对应的序列时，<strong>应用匹配过程</strong>以便从与给定序列中最相似的转换矩阵中提取那些序列（图案）。</p><p>其次是提出一种预测结果的序列kNN方法，即通过比对序列局部结果，然后比对相似程度，获得预测结果</p><h2 id="序列比对"><a href="#序列比对" class="headerlink" title="序列比对"></a>序列比对</h2><p><font color="#FF1493">为了确定序列相似性</font><br>序列比对主要类似于生物学中的新的DNA序列与DNA数据库进行比较。将DNA序列的事务与蛋白质数据库进行比较，以验证它们之间的关系是否可能发生在发生概率之间。</p><blockquote><p>序列比对<br>包括全局比对和局部比对<br>全局比对是提供了全局优化解决方案，遍历所有查询序列的整个长度。<br>局部比对旨在从两个查询序列中找到最相似的段</p></blockquote><p>我们在MMs中并不是使用当前的序列比对算法，而是使用序列比对的思想；同时作者提出<strong>局部序列比对与kNNs的结合</strong>使用方法：【替换矩阵】</p><blockquote><p><font color="#006400">知识补充</font><br>在序列比对算法中的<strong>替换矩阵</strong>又称为打分矩阵，其数学本质是统计权重。<br><a href="https://zhuanlan.zhihu.com/p/150582377">替换矩阵（计分矩阵）| 原理和作用 - 知乎</a><br>在序列比对中，我们一般需要给出一个定量的数值来描述两者的一致性和相似性。在此过程中，替换矩阵用来评价碱基或残基之间的相似性，在长期实践中，人们发现一些特定的碱基替换或者残基替换的频率是要高于另一些替换的，因此人们可以通过统计方法或者基于进化的突变模型来给每一种替换定义不同的分值，来体现出不同碱基或残基之间发生替换的可能性。其可以分成核酸序列替换矩阵和蛋白质序列替换矩阵。</p></blockquote><p> <strong><font color="#9932CC">替换矩阵：</font></strong><br> <em>生物学中用于描述单位时间内，一个氨基酸转换为另一个氨基酸的速率</em>。本文中替换矩阵作为单位矩阵，主对角线的元素是1，其他元素都是0。为了呈现突变，使用了更复杂形式的替代矩阵。上边<font color="#1E90FF">知识补充</font>中提到不同的矩阵不同值可以更好表现序列单元之间转换的可能性与频率。<font color="#FF00FF">我的理解是序列对比的权重表</font>。</p><p> <strong><font color="#9932CC">打分矩阵</font></strong><br> 即模型打分矩阵函数：</p><p> <img src="https://gitee.com/merlynr/img-store/raw/master/2021710/1625901529848.png" alt="初始化"></p><p> <img src="https://gitee.com/merlynr/img-store/raw/master/2021710/1625901755301.png" alt="计算公式"><br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>s</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub><mo>)</mo></math>是替换矩阵中Xi与Yj的替换分数。<br><font color="#483D8B">TODO</font> 公式中有个别参数读不懂</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021710/1625902300497.png" alt="栗子"></p><p><strong><font color="#FF8C00">案例：</font></strong><br>序列ABCDE与序列EBCAD对应的打分矩阵，根据分数高低来寻找最佳片段，然后沿着对角线从最高点到左上角，直至分数为0，来确定匹配序列，如图栗子中为BC。</p><h2 id="预测模型"><a href="#预测模型" class="headerlink" title="预测模型"></a>预测模型</h2><p><strong><font color="#9932CC">前提：</font></strong><br>本模型目的是在流程实例中预测<math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>s</mi><mrow><mi>i</mi></mrow><mrow><mo>(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></msubsup></math>下一事件<math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>s</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo>(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></msubsup></math>。其中<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mrow><mi>N</mi><mo>+</mo><mn>1</mn></mrow></msub></math>业务流程中的事件的预测是基于<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi><mo>=</mo><mo>{</mo><msub><mi>S</mi><mn>1</mn></msub><mo>,</mo><msub><mi>S</mi><mn>2</mn></msub><mo>&#x22EF;</mo><msub><mi>S</mi><mi>N</mi></msub><mo>}</mo></math></p><p>其中一个业务流程实例（Sj）是按时间顺序排列的离散事件(或任务)的组合Sj=<img src="https://gitee.com/merlynr/img-store/raw/master/2021710/1625906179169.png" alt="enter description here">，而单个事件是来自于事件类型的有限集合<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>E</mi><mo>=</mo><mo>{</mo><msub><mi>e</mi><mn>1</mn></msub><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msub><mi>e</mi><mi>L</mi></msub><mo>}</mo></math></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021710/1625907751234.png" alt="predict model"></p><h3 id="MMs"><a href="#MMs" class="headerlink" title="MMs"></a>MMs</h3><p><a href="https://blog.zuishuailcq.xyz/2021/07/05/Markov%20Model%EF%BC%88%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%89/">Markov Model（马尔可夫模型） | 吾辈之人，自当自强不息！</a></p><p>同时文中为了保障预测模型准确性，提出构建 <strong><font color="#006400">动态MMs</font></strong> ，通过存储单个事件在数据集中的次数、紧跟事件发生的下一个事件在数据集中的次数（事件A的下一个事件为B，这里指B的次数）和转换矩阵。还可以通过将折扣因子与事件数量结合，这样就可以在加入新数据时更新折扣因子来提供更多权重。</p><blockquote><p><strong><font color="#9400D3">知识补充</font></strong> 折扣因子<br><a href="https://www.zhihu.com/question/61389929">(95 封私信 / 79 条消息) 马尔可夫决策过程中为什么需要discount factor ，也就是问为啥时间近的状态影响越大？ - 知乎</a><br><a href="https://www.jianshu.com/p/678f57342d0b">#David Silver Reinforcement Learning # 笔记2-MDP - 简书</a><br><a href="https://www.cnblogs.com/wacc/p/5391209.html">强化学习笔记1 - Hiroki - 博客园</a></p></blockquote><h3 id="HMM"><a href="#HMM" class="headerlink" title="HMM"></a>HMM</h3><p><a href="https://blog.zuishuailcq.xyz/2021/07/05/Markov%20Model%EF%BC%88%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%89/">Markov Model（马尔可夫模型） | 吾辈之人，自当自强不息！</a></p><h3 id="混合模型"><a href="#混合模型" class="headerlink" title="混合模型"></a>混合模型</h3><blockquote><p>主要是平衡准确性和覆盖</p></blockquote><p>结合高阶MMs与序列比对技术（Waterman 1994），以保持高阶马尔可夫模型的高精度，同时弥补缺乏覆盖面积【个人感觉是通过通过增加区别序列对比消除过拟合】，提出了MSA（Markov sequence alignment 马尔可夫序列比对）【一种基于相似序列可能产生相同结果的假设，<font color="#E9967A">指处理没有遇到过的新的序列，然后在转换矩阵中找最类似的</font>】</p><p>通过构建矩阵比较两个序列的重量，最小则最为接近。<br>规则：<br>节点事件相同，则重量为0<br>如果事件不同则为1或者 $δ$</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021713/1626182437859.png" alt="栗子"></p><ol><li>从两个序列中删除的第一事件A和E导致重量为1</li><li>两个序列中的第二个事件是B并且具有重量0</li><li>第四个事件A从EBCAD中删除，以便将两个D事件匹配在两个序列中的第四和第五位置，重量加 $δ$</li><li>最后，我们从ABCDE序列中删除最后一个事件E，增加重量 $δ$</li><li>匹配两个序列的总重量是 $w = 1 + 0 + 0 + δ + δ = 1 + 2δ$</li></ol><p><font color="#8B0000">以下示例将说明我们的方法</font>，通过一个三阶MMs的转换矩阵和序列BCC。此序列尚未发生在矩阵之前并未存储在矩阵中。<font color="#FF8C00">目的是从矩阵找到最相似的序列，并使用它们的预测来为给定序列BCC生成预测。</font></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021713/1626183826410.png" alt="替换矩阵"></p><ol><li>我们首先将BCC与ABC相匹配</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021713/1626183855711.png" alt="BCC to ABC"></p><p>weight： $w=δ+0+δ=2δ$</p><ol start="2"><li>类似地，匹配CBC和BCC的得到的重量</li></ol><p>weight: $w=2δ$</p><ol start="3"><li>BAA和BCC</li></ol><p>weight: $w=2$</p><p>这一块理解的是当无法通过删除操作达到序列匹配的时候则加重为1，否则通过删除和插入惩罚达 $δ$ 到序列匹配，文中提到的是0.4。<br>通过比重，ABC与CBC一样小，所以<font color="#9400D3">ABC与CBC都和BCC最相似</font>，但是它们的预测载体分别是（0.1,0.2,0.7）和（0.1,0.5,0.4），基于这些向量，就是预测{B，C}的下一步。<br>这两个事件的发生的权重和频率是相等的;因此，由于两个序列中较高的转换概率分别是 $m _ { 13 }=0.7$ 和  $m _ { 22 }=0.5$ ，因此给定的序列预测的下一步是具有更高的转移概率C。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021713/1626185939137.png" alt="算法一"></p><ol><li>比对序列，识别通过删除/插入符号匹配两个序列的最佳编辑过程</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021713/1626185957405.png" alt="算法二"><br>2. 计算匹配两个序列的分数</p><p><font color="#D2691E">算法1和2说明了通过删除和插入惩罚来匹配两个序列的过程</font></p><h3 id="KNN结合序列比对"><a href="#KNN结合序列比对" class="headerlink" title="KNN结合序列比对"></a>KNN结合序列比对</h3><p>KNN基本上是一种非参数方法;因此，其中一个优点是不需要训练模型。序列KNN的核心思想是**<font color="#FF1493">找到类似的序列</font>** ，期望这些序列具有共同的行为和结果。<br>业务流程的比对需要加入时间特征，这里采用生物学的序列对准技术结合KNN，通过与序列对准组合，kNN允许我们顺序地比较符号序列，提出了K最近序列比对（KnsSA）。</p><p>首先根据给的N个序列，构建了距离矩阵 $( d _ { i j } ) N * N$ ，然后使用距离矩阵的元素对序列进行排序。通过使用局部对齐匹配每对序列来获得距离矩阵的元素</p><h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><h3 id="过程分析和数据预处理"><a href="#过程分析和数据预处理" class="headerlink" title="过程分析和数据预处理"></a>过程分析和数据预处理</h3><pre><code>确定了MSA（Markov sequence alignment 马尔可夫序列比对）和KnsSA（KNN序列比对）</code></pre><blockquote><p><font color="#00CED1">非对应知识补充</font>：MSA<br><a href="https://blog.csdn.net/weixin_39569389/article/details/111647915">序列两两比对算法_多重序列比对(MSA)分析工具怎么选，看这一篇就够了_weixin_39569389的博客-CSDN博客</a><br><a href="https://www.jianshu.com/p/31fb919f1c91">【陪你学·生信】九、多序列比对-Multiple Sequence Alignment（MSA） - 简书</a></p></blockquote><blockquote><p><font color="#B8860B">非对应知识补充</font>：MSA<br><a href="https://zhuanlan.zhihu.com/p/92254686">替代梯度下降——基于极大值原理的深度学习训练算法 - 知乎</a><br>MSA可以替代梯度下降函数<br>优一：MSA的每次迭代的收敛速度确实比梯度下降方法快一些<br>优二：梯度下降法的一大问题就是如果参数初始化得不好，那么就有可能会遇到一些局部平坦的区域，导致收敛速度变慢，而MSA方法则不会受到这个问题的影响<br>缺点：每轮迭代的时间会比梯度下降慢得多，这是可以理解的，毕竟MSA的每轮迭代都需要去找到一个最大值，而梯度下降只需要计算一次梯度就行了。这就导致了<strong>虽然MSA每次迭代收敛地更快，但是从时间上来看却反而更慢了</strong><br><img src="https://gitee.com/merlynr/img-store/raw/master/2021714/1626226968387.png" alt="总结"></p></blockquote><p>第一个数据集（DS1）由电信线路故障修复记录为9个月。第二（DS2）涵盖1个月的时间，并表示固定宽带断层的过程。第三数据集DS3来自不同的故障修复过程。数据集DS1和DS2用于我们扩展马尔可夫模型的实验中。数据集DS3和DS4用于KNSSA实验。</p><p>数据复杂且长短不一。【文中没有提到整理数据方式，只是进行可视化】</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021713/1626187757351.png" alt="通过工具Aperture挖掘10%的DS1的数据形成的可视化"></p><h3 id="扩展马尔可夫模型实验"><a href="#扩展马尔可夫模型实验" class="headerlink" title="扩展马尔可夫模型实验"></a>扩展马尔可夫模型实验</h3><blockquote><p>扩展马尔可夫模型实验</p></blockquote><ol><li>RM - 随机模型</li></ol><p>为了找到当前之后的下一个任务，我们随机从潜在的下一个任务中选择。例如，从历史数据得知事件a来自于序列A属于集合{C，D，E}的任务，我们随机选择从该设置的值作为预测的下一步。【不通，反正就是一个baseline，在有限的范围内进行下一步】</p><ol start="2"><li>高阶MMs</li></ol><p>从一阶到kth阶生成许多不同的秩马尔可夫模型。给定序列，我们从最高阶MMs开始。如果在转换矩阵中找不到给定序列，我们通过删除序列中的第一个事件来创建新的较短序列。然后，我们将使用下一个下阶MMs继续过程，直到我们在转换矩阵中找到一个匹配项，或者在尝试第一阶Markov模型之后，需要默认预测。【只通过降阶来预测 <strong><font color="#FF8C00">所有</font></strong> 序列】</p><ol start="3"><li>HMM</li></ol><p>我们测试了几个具有不同长度的多个序列HMM，用于输入序列和不同数量的隐藏状态，并选择了最佳状态。</p><p>**<font color="#9932CC">结果分析对比</font>**：<br>90%用于训练，10%做预测。使用十折交叉验证预测结果</p><blockquote><p><font color="#006400">知识补充</font>交叉验证<br><a href="https://zhuanlan.zhihu.com/p/267910629">8. Sklearn — 交叉验证(Cross-Validation) - 知乎</a></p></blockquote><p>首先是构建一阶到七阶MSAs，然后通过通过MSAs选取数据集的最适合 $l$ ,其中DS1取值为5，DS2取值3。</p><blockquote><p>$l$ 表示序列选取长度</p></blockquote><p>下图一，二别说明了DS1和DS2这两个数据集的MSAa准确性。结果表明，通过引入<font color="#FF00FF">默认预测</font>改进模块，MSA优于其他可比模型，尤其是当马尔可夫模型的阶数增加时。这是因为 <strong><font color="#D2691E">序列之间比较的相关性与其长度成正比。</font></strong></p><blockquote><p>数字表示阶层<br>蓝色表示原生MMs的预测准确度，红加蓝表示加上默认预测模块改进后的预测精确度。</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021714/1626252630431.png" alt="图一，使用数据集DS1在MMs中应用默认预测模块前后的正确预测百分比"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021714/1626253369803.png" alt="图二，使用数据集DS2在MMs中应用默认预测模块前后的正确预测百分比"></p><p><font color="#9932CC">分析：</font><br>二阶MSAs在一系列不同阶MSAs中表现最好，就DS1而言，正确预测27%；三阶MSAs在DS2中表现最好，可以达到70%的准确率。同时可以分析得到在五阶MSAs预测时，默认预测模块的作用明显增加。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021715/1626314785957.png" alt="四种模型预测比较，第一个为全阶MMs"></p><p>这里选择的是五阶段MSA和全五阶MMs，因为全阶段MMs在高阶时是具有优势的，这里为了验证默认预测的作用所以使用五阶。该图显示了两个数据集下所有模型的性能。可以看出，RM表现最差，DS2的成功率只有10%左右。当应用于更大的数据集DS1时，结果下降到接近2%（MSAs是其14倍）。同时可以发现选择正确的下一个任务的概率随着集合大小的增加而降低。结果突出了处理复杂数据集的难度。当数据不是太多样化(即DS2)时，MSA(五阶)获得最高数量的正确预测，结果为63%。与其他基准相比，MSA结果优于达到57%的五阶马尔可夫模型、达到60%的全Kth (K=5)马尔可夫模型和达到43%的隐马尔可夫模型。</p><h3 id="连续KNN实验"><a href="#连续KNN实验" class="headerlink" title="连续KNN实验"></a>连续KNN实验</h3><h4 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h4><p>这块作者提出的预测流程结果，所以需要给数据做标记，用于区分输出结果是成功还是失败。但是不同数据集输出的结果判断标注不同，<font color="#FF8C00">同一个数据集中不同流程的结果判断标注也不同</font>，这就无法统一对预测结果进行判定。</p><p><font color="#9932CC">为了寻找到不同业务流程相统一的结果判断标准，这里采用的是通过设置时间阈值来衡量流程结果的成功与否。</font></p><pre><code>然而，在DS4的情况下，实际交付日期和向客户承诺的交付日期之间的差被用作确定成功和失败的标准。特别是，如果实际交付日期在约定日期之前，则该流程实例被归类为成功，否则被归类为失败。</code></pre><h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h3><blockquote><p><font color="#7FFF00">通过另外两种baseline来评估KnsSA</font></p></blockquote><ol><li>RM – random model(随机模型)：为了找到过程的结果，我们随机生成一个介于0和1之间的数字；如果生成的数字大于0.5，则结果为成功(1)，反之亦然；如果生成的数字小于0.5，则结果为失败(0)</li><li>Original KNN： 我们选择K个最近的序列是因为它们有共同的独特任务。例如，给定两个序列A、B、D和A、A、C，第一个序列中有一个A、一个B和一个D；第二个中有两个As和一个C。每个独特的任务可以被视为一个类别。每个类别的距离计算为相应任务出现次数的差值。为了获得任意两个给定序列之间的总距离，对所有类别进行求和。例如，前面给出的两个序列由四个类别A、B、C和D组成。类别A的距离分别为dA= 1，类别B、C和D的距离分别为dB=1、dC=1和dD= 1。这两个序列的总距离为d=dA+dB+dC+dD=4【每个流程中每个事件进行求总距离】</li></ol><p>该模型是局部序列比对技术与KNN的结合模型，所以选择KNN的k值，结合实验中标签是0和1，这里作者k值选择为<font color="#FF8C00">奇</font>数；同时考虑数据集的多样性，k值应该<font color="#FF8C00">较小</font>。</p><blockquote><p>**<font color="#B8860B">知识补充</font>**： k值为什么选择奇数<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021715/1626333046633.png" alt="k值为什么选择奇数"></p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021715/1626333229424.png" alt="Local KnsSA模型对DS3，DS4预测结果"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021715/1626333425840.png" alt="Local KnsSA，KNN，RM对于数据集预测结果"></p><p><strong>结果表明</strong>，该模型优于原始KNN和随机猜测的基准模型。这也意味着数据的时间特性对于预测过程结果很重要。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文的设计构思，首先通过MMs和HMM生成数据集的替换矩阵，然后作者提出一种序列比对的马尔可夫扩展模型（MSAs）。为了验证该模型的有效性，与MMs和HMMs进行对比，发现其准确率由于其它至少10%。<br>同时表明了高阶马尔可夫模型预测准确率高于一阶【图五】。从五阶以后加入缺省默认预测模块后可以大幅度提高预测准确度。<br>第二个贡献是提出新的序列比对KNN（KnsSA）。该方法优于基准模型，证明了数据的序列特征在预测过程结果中的重要作用。相将相似序列进行分类，然后进行下一步处理。</p><h2 id="下一步构思"><a href="#下一步构思" class="headerlink" title="下一步构思"></a>下一步构思</h2><p>未来的研究将着眼于使用序列比对和K均值聚类将数据聚类成K个组，然后用合适的方法处理每个组</p>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> RPA </tag>
            
            <tag> paper </tag>
            
            <tag> deep learning </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>七月前完成</title>
      <link href="/2021/06/27/%E4%B8%83%E6%9C%88%E5%89%8D%E5%AE%8C%E6%88%90/"/>
      <url>/2021/06/27/%E4%B8%83%E6%9C%88%E5%89%8D%E5%AE%8C%E6%88%90/</url>
      
        <content type="html"><![CDATA[<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul><li><input disabled="" type="checkbox"> 机器学习</li><li><input disabled="" type="checkbox"> 预测算法</li><li><input disabled="" type="checkbox"> 五篇小论文</li><li><input disabled="" type="checkbox"> 考虑数据源与公司想结合</li></ul><h2 id="done"><a href="#done" class="headerlink" title="done"></a>done</h2><ol><li>XES文档2.5</li><li>使用ProMLite</li></ol>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
            <tag> daily/weekly </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习与循环神经网络在预测下一个过程事件问题上的初步应用</title>
      <link href="/2021/06/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E9%A2%84%E6%B5%8B%E4%B8%8B%E4%B8%80%E4%B8%AA%E8%BF%87%E7%A8%8B%E4%BA%8B%E4%BB%B6%E9%97%AE%E9%A2%98%E4%B8%8A%E7%9A%84%E5%88%9D%E6%AD%A5%E5%BA%94%E7%94%A8/"/>
      <url>/2021/06/25/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E9%A2%84%E6%B5%8B%E4%B8%8B%E4%B8%80%E4%B8%AA%E8%BF%87%E7%A8%8B%E4%BA%8B%E4%BB%B6%E9%97%AE%E9%A2%98%E4%B8%8A%E7%9A%84%E5%88%9D%E6%AD%A5%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p><font color="#DC143C">TITLE</font>: A Deep Learning Approach for Predicting Process Behaviour at Runtime</p><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>描述深度学习与循环神经网络在预测下一个过程事件问题上的初步应用</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>主要介绍了流程预测与自然语言的处理有很多地方类似，同时也有不同之处。</p><p><font color="#FF1493">流程预测与自然语言不同：</font></p><ul><li>过程预测（事件类型数量）中词汇量的大小远小于自然语言词汇的大小</li><li>轨迹的长度远远超过自然语言中的典型句子长度</li><li>通过内部过程逻辑确定或约束过程事件序列，通常通过基于案例数据确定的决策规则确定。然而，以语法和形态规则的形式，自然语言也受到限制</li></ul><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p><strong><font color="#B22222">这块主要讲了一下业务流程预测相关的研究</font></strong></p><h3 id="预测完成一个案件的剩余时间"><a href="#预测完成一个案件的剩余时间" class="headerlink" title="预测完成一个案件的剩余时间"></a>预测完成一个案件的剩余时间</h3><ol><li>使用事件频率、事件时间和案例数据的增强回归</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624673781121.png" alt="When will this case finally be finished?"><br>2. 将隐马尔可夫模型应用于事件序列和执行时间[基于一个带注释的转换系统]</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624674466379.png" alt="A test-bed for the evaluation of bussiness process prediction techniques"><br>3. 使用聚类树和有限状态机(FSM)来预测运行过程案例的剩余时间</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624674870904.png" alt="Context-aware predictions on bussiness processes: An ensemble-based solution"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624674967541.png" alt="Discovering context-aware models for predicting business process performances"><br>4. 将复杂的事件处理（CEP）应用于事件序列，并培训以预测其未来行为</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624675079138.png" alt="Facilitating predictive event-driven process analytics"><br>5. 使用随机petri网模拟</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624675153578.png" alt="Prediction of remaining service execution time using stochastic petri nets with arbitrary firing delays"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624675288618.png" alt="Prediction of bussiness process durations using non-markovian stochastic petri nets"><br>6. 基于案例数据聚类和回归的预测技术</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624675498447.png" alt="A data-driven prediction framework for analyzing and monitoring business process performances"><br>7. 对部分和全部案例采用聚类方法</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624675713998.png" alt="Process remaining time prediction using query catalogs"><br>8. 提出了两种基于带注释的转换系统的方法，以及支持向量回归和朴素贝叶斯分类器</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624675768877.png" alt="Data-aware remaining time prediction of business process instances"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624675838918.png" alt="Time and activity sequence prediction of business process instances"></p><h3 id="流程预测结果评估【二元评估】"><a href="#流程预测结果评估【二元评估】" class="headerlink" title="流程预测结果评估【二元评估】"></a>流程预测结果评估【二元评估】</h3><ol><li>在时间、资源和案例数据上使用决策树</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624676985594.png" alt="Predictive business operations management"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624677076066.png" alt="Business process intelligence"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624677129344.png" alt="Improving bussiness "><br>2. 使用支持向量机</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624686889124.png" alt="Periodic berformance prediction for real-time business process monitoring"><br>3. 基于聚类和局部离群点检测</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624687171172.png" alt="Real-time business process monitoring method for prediction of abnormal termination using knni-based LOF prediction"><br>4. 使用决策树来预测违反线性时序逻辑限制</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624687372135.png" alt="Predictive monitoring of business processes"><br><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624687442053.png" alt="Predictive monitoring of business processes"><br>5. 使用随机森林</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624687491226.png" alt="Complex symbolic sequence encodings for predictive monitoring of business processes"><br>6. 采用神经网络、约束满足和服务质量聚合</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624687569443.png" alt="Comparing and combining predictive business process monitoring techniques"><br>7. 聚类和回归</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021626/1624687617567.png" alt="A prediction framework for proactive monitoring aggregate process-performance indicators"></p><h2 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h2><h2 id="Process-Prediction-using-RNN"><a href="#Process-Prediction-using-RNN" class="headerlink" title="Process Prediction using RNN"></a>Process Prediction using RNN</h2><h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><h2 id="扩展学习"><a href="#扩展学习" class="headerlink" title="扩展学习"></a>扩展学习</h2><h3 id="阅读paper36【P10】"><a href="#阅读paper36【P10】" class="headerlink" title="阅读paper36【P10】"></a>阅读paper36【P10】</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021627/1624759564094.png" alt="paper36"></p><h3 id="递归神经网络与循环神经网络"><a href="#递归神经网络与循环神经网络" class="headerlink" title="递归神经网络与循环神经网络"></a>递归神经网络与循环神经网络</h3><p><font color="#0000FF">Recursive Neural Network || Recurrent Neural Network</font></p><h3 id="Hidden-Markov-Models-HHM"><a href="#Hidden-Markov-Models-HHM" class="headerlink" title="Hidden Markov Models(HHM)"></a>Hidden Markov Models(HHM)</h3><h3 id="LSTM与RNN"><a href="#LSTM与RNN" class="headerlink" title="LSTM与RNN"></a>LSTM与RNN</h3>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> paper </tag>
            
            <tag> deep learning </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>总结“基于机器学习的业务流程系统的预测”中的技术点</title>
      <link href="/2021/06/24/%E6%80%BB%E7%BB%93%E2%80%9C%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%A2%84%E6%B5%8B%E2%80%9D%E4%B8%AD%E7%9A%84%E6%8A%80%E6%9C%AF%E7%82%B9/"/>
      <url>/2021/06/24/%E6%80%BB%E7%BB%93%E2%80%9C%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%A2%84%E6%B5%8B%E2%80%9D%E4%B8%AD%E7%9A%84%E6%8A%80%E6%9C%AF%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<h2 id="论文总体流程"><a href="#论文总体流程" class="headerlink" title="论文总体流程"></a>论文总体流程</h2><p>本文针对三个预测任务提 出 了 两个预测模型 。 一个预测模型是 用来预测流 程结果 的 模 型 ， 本文提 出 了 利 用 深度 学 习 中 序 列 处理 网 络 Ｌ Ｓ ＴＭ算法模 型去<font color="#183B64">预测流程结果 </font>的方法 ， 此方法 旨 在将流程结果 的预测 问 题与 自 然语言处理方 向 相 结合 ， 提供 一个新 的解决思路 。另 一个预测模型 则是用 来<font color="#1E90FF">预测事件活动与 时 间 相关任务</font> 的模 型 ， 此预测 模型 将本文研 究 的预测流程下 一时刻活动与 时 间 、预测流程后续时刻事件 活动 与 时 间 （ 即 剩余周 期 时 间 ） 两个预测任务利 用 一个预测模型 实现 。</p><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><h3 id="关注点"><a href="#关注点" class="headerlink" title="关注点"></a>关注点</h3><p><font color="#9400D3">关注点</font></p><ul><li>预测业务流程的<font color="#008B8B">下一时刻活动和与时间相关活动</font></li><li>预测业务流程中运行案例的未来路径</li><li>预测业务流程运行的剩余周期时间</li><li>预测业务流程执行<font color="#006400">结果</font>以及预测业务流程执行结束后的性能</li></ul><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><h4 id="预测流程结果"><a href="#预测流程结果" class="headerlink" title="预测流程结果"></a>预测流程结果</h4><ol><li>序列处理网络LSTM算法模型【将流程结果的预测问题与自然语言处理方向相结合】</li><li>决策树</li><li>使用支持向量机（SVM）【此方法可以提供描述实时业务的流程当前性能的实施指标，缺点是评估指标仅为准确率，较为单一】</li><li>基于KNN算法和局部异常值检测，此方法提出了 一个通过替换未观察到的属性来生成实例的插补方法，但并未验证其泛用性</li></ol><h4 id="预测事件活动与时间相关任务的模型"><a href="#预测事件活动与时间相关任务的模型" class="headerlink" title="预测事件活动与时间相关任务的模型"></a>预测事件活动与时间相关任务的模型</h4><ol><li>利用自然语言处理中的GRU网络结构、双向循环网络结构、Word2vec技术以及Attention机制进行预测【将本文研 究 的预测流程下一时刻活动与时间、预测流程后续时刻事件活动与时间（  剩余周期时间）两个预测任务利用一个预测模型实现】</li></ol><h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> summarize </tag>
            
            <tag> plan </tag>
            
            <tag> paper </tag>
            
            <tag> algorithm </tag>
            
            <tag> process mining </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-6-22[daily]</title>
      <link href="/2021/06/21/2021-6-22%5Bdaily%5D/"/>
      <url>/2021/06/21/2021-6-22%5Bdaily%5D/</url>
      
        <content type="html"><![CDATA[<h2 id="NEED-TODO"><a href="#NEED-TODO" class="headerlink" title="NEED TODO"></a>NEED TODO</h2><ul><li><input disabled="" type="checkbox"> 阅读论文SpinalFlow: An Architecture and Dataflow Tailored for Spiking Neural Networks</li><li><input disabled="" type="checkbox"> 制作相关演讲PPT</li><li><input disabled="" type="checkbox"> 学习三个吴恩达机器学习视频</li><li><input disabled="" type="checkbox"> 学习一个中等，一个简单算法</li><li><input disabled="" type="checkbox"> 学习Java相关进阶</li></ul><h2 id="Plan"><a href="#Plan" class="headerlink" title="Plan"></a>Plan</h2><ol><li>10.20-11.20，阅读论文</li><li>13.40-15.30，阅读论文</li><li>15.40-16.20，看机器学习视频</li><li>16.30-17.20，学习算法</li><li>18.10-21.10，看论文</li><li>21.20-22.40，看Java进阶</li></ol><h2 id="Completion-Status"><a href="#Completion-Status" class="headerlink" title="Completion Status"></a>Completion Status</h2><h2 id="TODO-Tomorrow"><a href="#TODO-Tomorrow" class="headerlink" title="TODO Tomorrow"></a>TODO Tomorrow</h2>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>555~四级</title>
      <link href="/2021/06/01/555~%E5%9B%9B%E7%BA%A7/"/>
      <url>/2021/06/01/555~%E5%9B%9B%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="写作"><a href="#写作" class="headerlink" title="写作"></a>写作</h2><p><img src="https://gitee.com/merlynr/img-store/raw/master/202161/1622551964785.png" alt="作文要求"></p><ol><li>时间很紧，第一遍就需要写在纸上</li><li>手写，需要注意字体，建议衡水体</li><li>写的时候右侧也对齐，同时写85%，这样美观</li><li>背一些句型和一些常用词汇的替换词</li><li>切记不要跑题，介意通过直接更改题干来立题</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/202161/1622552071072.png" alt="衡水体"></p><h3 id="衔接词"><a href="#衔接词" class="headerlink" title="衔接词"></a>衔接词</h3><p>due to 因为<br>in spite of尽管，<br>thus因此，<br>on the contrary相反地<br>首先 in the first place, to begin with, first of all, for one thing<br>然后，而且 in addition, what’s more,moreover, besides, for another thing<br>最后 last but not the least<br>表举例 for instance<br>表对比 in contrast, on the contrary</p><h3 id="专业词汇"><a href="#专业词汇" class="headerlink" title="专业词汇"></a>专业词汇</h3><p><a href="https://www.bilibili.com/video/BV1MN411Z7Lu?spm_id_from=333.788.b_765f64657363.3">热点词</a></p><h3 id="例句"><a href="#例句" class="headerlink" title="例句"></a>例句</h3><ol><li>It is obvious that the cartoon is trying to tell us…</li><li>Currently, there is a growing tendency that people in mounting numbers are showing great enthusiasm for sth.</li><li>From my perspective/As for me, at no time should we ignore the importance of A.</li><li>“<strong><strong><strong>” is the opinion held by</strong></strong></strong> . This remark has been confirmed time and again by more and more people. “______”是______的观点，而且被越来越多的人反复证实。</li><li>The advantages of A are much greater than those of B.</li><li>A number of factors are accountable for this situation. 造成这种情况的因素有很多。</li></ol><h2 id="听力"><a href="#听力" class="headerlink" title="听力"></a>听力</h2><ol><li>利用一切时间，读题，找关键词</li><li>可以去预判一些常考的考点【因果、并列、转折、举例、男女对话即为换题的标志】</li><li>一般事请都会有波折，即往不好的方向发展</li><li>当没听清时，往主旨上蒙，越是详细越可能出错</li></ol><h2 id="阅读"><a href="#阅读" class="headerlink" title="阅读"></a>阅读</h2><p><font color="#00CED1">20mins</font></p><ol><li>原句<font color="#FF1493">重复出现，200%错</font>。正确的都是有改动的，即同意替换。</li><li>文章是<font color="#9400D3">按顺序出题</font>的。你要觉得不是，就是你做错了。</li><li>选项中意思完全相反的2个选项，<font color="#E9967A">其中之一是对的</font>。（要有这个意识）。</li><li>就一般而言，some people，表作者不认同的观点。<font color="#006400">few people，表作者的观点</font>。</li><li>用文章里<font color="#9400D3">举例的句子来作为选项</font>，直接排除。200%错。（要有能辨别这个选项是不是文章中例子的能力）。</li><li>某某人说的话，或者是带引号的，一定要高度<font color="#8B008B">重视</font>。尤其是在段落的后半部分。很有可能就是某个问题的同意替换。即题眼。</li><li>有的时候，一句话可以设2个问题。不过这种情况很少出现了，非常少。。</li><li>文章基本以5段为主（也有6段、7段的），要把握每段之间的关系。一般来说，一段一个题，只是一般来说喔。。</li><li>一篇文章总会有5、6+个长难句，且总会在这里设问题。所以，<font color="#FF8C00">长难句必须要拿下</font>！！</li><li><font color="#9932CC">每段的第一句很重要</font>。尤其总分结构的段。有的时候第一句话就是题眼。考研英语，总分结构或者总分总的段落很多。。</li><li>若文章首段以why为开头的，这里若设题的话，选项里有because的，往往就是正确选项。不过这种类型的题，很少见了。。</li><li>有时候每段的第一句话，仅仅是一个表述。而在第2或3句以后，会出现对比或者转折。一般来说，<font color="#00FFFF">转折后面的是作者的态度</font>。你要注意的是，作者对什么进行了转折。那个关键词你要找出来。</li><li>在应该出现答案的地方，没有答案。。接着往下读。答案可能会在下一段的开头部分。因为文章都是接着说的。要有连贯性。这和7选5的技巧有些相似。不过这种情况并不多见。。</li><li>一个长句看不懂，接着往下看，下一句可能是这个长句的解释说明。是的话，这的地方可能会出题。出的话，答案就在这附近。而实际情况是，文章在谈论某个问题或提出某个观点时，有时会再做进一步的解释说明。这种情况下，这里往往会设问题。不过，这种情况很少见了。。</li><li>有些句子仅仅是解释补充，或者是起过渡作用的。这样句子的特点是，句子比较短。注意，答案一般不会在这儿出现。选项中出现，肯定是<font color="#9932CC">干扰项</font>。你要知道的是，同意替换的句子，大都是长难句。一些作为过渡的句子，不可能是答案。在你读不懂的情况下，要有这个判断力。</li><li>正确选项都是原文中的个别几个词的<font color="#D2691E">同义替换</font>。阅读理解历年的所有真题，都是同意替换！！就看你能不能找得到。考研英语，考的就是这个！！那个关键词，就看你找没找得到，不管是什么类型的题。。</li><li>每一个问题，在原文中，都要有一个定位。然后精读，找出那个中心句或者关键词。要抓文章的中心主旨和各段落的大意，阅读理解考的就是这个“<font color="#057748">中心句</font>”。</li><li>选项中的几个单词，是该段中不同句子里的单词拼凑的，有时看上去很舒服，注意，干扰项。还有从不同的段落里的词拼凑到一起的，直接排除。总之，选项的单词是<font color="#A52A2A">拼凑的</font>，肯定错。</li><li>一定要注意文章中句子的宾语部分，尤其是长难句中主干的宾语。上面说了，考研英语大都是长难句里设题。你要知道的是，长难句里，最可能是出题的就是句子的主干部分！主干的主语、宾语是什么，一定要知道。<font color="#FF1493">正确选项</font>的题眼往往就在这儿。当然，还有一些起修饰、限定作用的词，一定要看仔细。小心陷阱。</li><li>若某个问题，是特别长的一个句子，一定要看清问的是什么，别打马虎眼。这是做题时需要留意的地方。</li><li>注意问题的主语是谁，它和原文题眼的主语原则上是一致的。主语不一致，一般来说，都是<font color="#9400D3">错的。</font></li><li>即第6条，某某人说的话，尤其特别长的句子，或者是带引号的。60%以上会出题。题眼就在这儿。这里又提了一遍，就是要引起你的<font color="#057748">重视</font>。</li><li>错误的选项，往往是就文章某一方面而说的，其特点是：所涉及的，仅仅是某一个小问题，或者很具体，<font color="#B22222">非常具体的一件实事</font>。200%错误选项。这是考研英语最经常遇到的干扰项。一定要会识别。</li><li>中国人出的题。多是总-分结构，或者总-分-总。所以每段开头结尾，都要注意。（这里指的是中间没有出现转折的段落）。整篇文章的<font color="#057748">开头结尾</font>。也要重视。</li><li>文章的结构，要么总-分或总-分-总，要么转折、对比，要么举例说明。就这么几个套路。</li><li>对选项中的“重点词”（即主语、宾语、修饰语）都要看清楚。有的时候，选项中，会对原文中本来正确的事做错误的修改，来作为干扰项。你要注意的是，选项句子的主语（与原文）是否一致、宾语是否符合原文意思，或者用一些牵强的修饰词，来做一些特殊的限定。要看清楚。这是干扰项的特点之一。</li><li>某人说过的话，有时并不是题眼，但可以从侧面或某个角度来反映作者的观点，也就是作者想表达的。<font color="#00FFFF">正确答案都是和这样的观点相一致的</font>。要把握关键词，有感情色彩的词。做题时，要有这个意识。</li><li>就某个词或者某个句子设问题，不用猜词。<font color="#057748">就一条，文章主旨</font>！ 不用去研究这个词什么意思，把握主旨即可。全文主旨和段落主旨（前者更重要）。</li><li>接着28条说，不管什么题型，上面说的还是其他别的题型。很绝对的说，反映主旨的肯定对，前提是你能确定它就是主旨。考研英语，一直到2011年，这一条还没变过。所以，文章读不太懂，但能把握作者想表达的意思即可。如2011年争议题37题。</li><li>注意中心句（即题眼）和前后句子之间的关系，是接着说的，还是转折关系。这里出题的话，要把握和<font color="#8A2BE2">前后句子之间的关系</font>。是并列关系的，可以从这些句子里找同义词。是转折关系的，就通过转折关系句子里的关键词的相反意思来判断。前提是在你读不懂的情况下。</li><li>凡是举例的，都是为了说明观点的。那么，这个观点（中心句），一般来说，会在举例之前就表达了。但有时候也在举例之后。总之，<font color="#bf242a">作者举例想说明的这个观点，你一定要找出来</font>。</li><li>排除2个选项以后，选出和文章主旨相关的选项即可。不知道主旨就把握关键词。</li><li>词汇题的正确答案，往往隐藏在原文的该处附近（就是那个<font color="#0000FF">同义替换词</font>），原文这附近的句子，是并列关系或者解释说明句的，就从这些句子的关键词的相近意思去把握。是转折关系的，就从关键词的相反意思去把握。总之，你要找的就是那个关键词。和30条一起理解吧。。</li><li>如果原文中出现“ A is B and C”。若某一问题，选项中出现了B没C，或者只出现C没B。<font color="#A52A2A">肯定错</font>，直接排除。可能你会问了，同时出现B and C 咋办？ 目前还没出现过这种情况。。注意，这里说的B和C，是单词或者短语。。这是干扰项的特点之一。 实际情况是，这个<font color="#B22222">句子不是题眼</font>。</li><li>接34题说，还一种情况是，若B和C是2个长句子，中间用分号隔开的。且这两个句子都是作者想表达的，选项中都出现了。。一般来说，选项中会对其中之一做错误的修改来作为干扰项。而另一个是对的。（如05年TEXT1 ，第一题。不过总体来说，这种题型非常非常少见。偶在这里想说的是34条。这样的干扰项，你要会识别。）</li><li>注意几个词，yet表转折，hardly表否定。while 有时是比较，有时也表转折。比较的时候，注意比较的对象，要弄清楚。转折的时候，你<font color="#0000FF">要知道作者对什么进行了转折</font>。</li><li>如果你对“关键词”比较蒙，或者你想问：我怎么知道哪个是关键词？解释一下，关键词就是句子中主干的宾语。尤其是一些你觉得比较重要的句子。这样的句子多数是长难句。一般来说，一个句子主干的主语，宾语，和其他的修饰部分，都是很重要的！！ 宾语是主语的宾语，所以，和主语是要对上号的，对不上不行。（也就是26条的主语是否一致）。至于修饰的部分，干扰项常常在这里做手脚，比如会有一些特殊的限定，千万要留意，别疏忽了。。</li><li>什么是中心句？即反应文章的主旨和每一段的中心意思的一句话。这句话是客观存在的。也就是作者的观点。中心句即题眼，选出正确答案，看的就是中心句。只有中心句才能选出正确答案。所以，中心句不知道在哪，或者读不懂，很难选出正确答案。中心句的具体位置，见下条。</li><li><font color="#7FFF00">很关键的一条</font>，抓住每段的中心意思，也就是中心句。每段至少一句，最多2句。 一般来说，总分结构的段落，中心句一般在段首。举例段一般在举例前后。转折段，中心句在出现转折的地方，或者后一句（一般来说在该段的第三行上下浮动）。再就是某某人说的话。要注意这句话和前后句的关系，是并列还是转折。然后来把握这句话的意思，把握不了就通过前后句是并列还是转折关系的关键词来把握。</li><li>每个问题，要还原到文章具体的某一段落。若此问题在某段的后半部分，且你没有太看懂，这段已经完事了。。要养成一个习惯。<font color="#1E90FF">接着看一下段的第一句话</font>。实在做不出来的话，就选那个和下一段第一句话的意思差不多的选项。只能这样了。。 （貌似是13条的重复）补充下，这只是小技巧，只起补充作用，有时候用不上。。</li><li>每段的第三行，一般来说，也是该段的第3句话（也可能是第2、4句话）。其特点是：句子很长，由两句或者两句以上组成，是个长难句。尤其是 that mean ，the notion is that 之类的，一定要重视。要把握句子的主干。作者想说的是什么（把握作者强调的是哪个句子）。看清楚哪句话是为了修饰哪句话的。这样的句子，若出题的话，句子的主干就是正确选项。起补充修饰作用的一定要看清楚。。每段最重要的三个地方：<font color="#0000FF">段首，段尾，和这儿</font>。再就是带引号的。中心句一般就在这几个地方。 其实也就这么几个地方。。别的地方一般都是过渡句。。</li><li>若是转折段的话，要注意转折的那个句子，一般都是在<font color="#0000FF">41条</font>的那个地方（即第三行上下浮动）。转折前后都要看，看对比的是什么。在看不懂的情况下，通过前面的，来翻译后面的（<font color="#00FFFF">反向翻译</font>），来找关键词。反之亦然。</li><li>最后一段，主要看段首和段尾。（最后一段是转折段的情况很少）。若是叙事段的话，叙事部分以外的，重点看。叙事部分尽量看懂。<font color="#725e82">非叙事部分非常重要</font>。一般段首若出现答案的话，段尾可能会作干扰项（见54条），但也不是绝对的（有时段首段尾都会有答案的提示）。段尾若出现答案的话，段首可能会很普通。 一定要把握哪一句话是重点，选项中有相近意思的不是片面的叙述，一般就是正确答案。要把握重点的句子提到的被说明对象（句子主干的宾语），也就是作者关注的。</li><li>选项中出现<font color="#7FFF00">ONLY </font>的，目前还没有对的。</li><li>说明原因的，且<font color="#057748">仅仅是说明原因</font>而已。目前没有对的。</li><li>中心句特别长的，2小句组成，选项中这2句都出现了，怎么排除？反映主旨的是对的。就是作者关注的对象！还一选项是对其进行具体的解释说明，或者补充，或是对主旨的一个具体现象的反应，或是对其造成的后果的叙述。这一选项一般会做错误的修改而作为<font color="#A52A2A">干扰项</font>（即使不做错误的修改也一样是干扰项）总之，这样的题，符合<font color="#1E90FF">28、29</font>条的就是对的。符合<font color="#B22222">23</font>条的，就是错的。</li><li>一定要注意，谁是用来修饰谁的。<font color="#B22222">起修饰作用</font>的词或句子，来做选项，一般是错的。<font color="#057748">被修饰的那部分</font>来作选项，一般是对的。</li><li>因果关系的题，很直接、很简单的因果关系，直接排除。间接的因果，反映主旨的，可能是对的。 总之，因果关系的题，把握主旨就可以了。文中提到的直接因果，如具体的事或是什么的。<font color="#8B0000">都是干扰项</font>。</li><li>48的补充，正确选项反应的，往往是实质的，根本的内容。选项反应的若是<font color="#bf242a">很具体</font>的某一表现，一般都是干扰项。</li><li>干扰项有时出现的生词（可能是你不认识的），是与文章主题无关的词，而非同意替换。（这就需要你的基本功了）</li><li>新趋势，有些题要懂文章才能做出来。读不懂很难选出来。而且，长难句明显增多。有时，它会让你崩溃到单词都认识，却不知道文章说的是什么。这时候什么技巧都不好使了。所以，一定要提高基本功。起码你要知道文章大概说的是啥，也就是谁和谁的关系。任何一篇文章的主旨，基本上都可以用“谁和谁的关系”来概括。</li><li>、通过首段或者前两段，来把握信息点。也就是作者想说的，<font color="#008B8B">是谁和谁的关系</font>？</li><li>接着上面说，一篇文章谈的是什么，或者说“谁与谁的关系”，一定要弄懂。这个具体的什么“关系”弄不懂的话，“谁与谁”一定要弄明白。比如，<font color="#00008B">一篇文章说的是A与B之间如何如何。若问题问你A，选项有B的，往往就是正确答案。若问你B，你就可以先把没有A的选项排除</font>。</li><li>最新趋势，最后一段，段尾很明显不是总结，而是以补充为主的句子。注意，这里可能会<font color="#FF1493">以干扰项的形式出现。</font></li><li>如上所说，中心句出现的地方无非就是段首、段中、段尾，或者带引号的句子。但是，这也是干扰项常常出现的地方。所以，你的基本功，对文章理解的程度，是你必须具备的能力。任何一门考试都有技巧，但是想拿理想的分数，光靠技巧是不现实的。</li><li>有的时候，你会遇到出现2到3个否定词的句子。否定再否定，或者否定否定再否定。遇到了，尤其是3重否定的，基本上<font color="#00008B">这里会设题</font>，这句话里的关键词一定要找出来。这个地方是要练的，到时候出现了，别蒙，别犯怵。。</li><li>再补充一条，<font color="#00008B">however 后面的句子一定要重视</font>。比如有一年的其中一篇的3个题，题眼都是however 后面的句子。 所以，这个词一定要敏感。</li></ol><p><strong><font color="#FF8C00">技巧done</font></strong></p><h2 id="段落匹配"><a href="#段落匹配" class="headerlink" title="段落匹配"></a>段落匹配</h2><p><font color="#9400D3">10mins</font></p><ol><li>看选项，勾关键词【能看懂的】<font color="#FF8C00">3~4mins</font></li><li>找对应的两个及以上的关键词</li></ol><p><strong><font color="#FF8C00">技巧done</font></strong></p><h2 id="选词填空"><a href="#选词填空" class="headerlink" title="选词填空"></a>选词填空</h2><p><font color="#9400D3">10mins</font></p><ol><li>先标词性在选词 </li></ol><h2 id="翻译"><a href="#翻译" class="headerlink" title="翻译"></a>翻译</h2><ol><li>替换+尬写</li><li>看一下<a href="https://www.bilibili.com/video/BV1MN411Z7Lu?spm_id_from=333.788.b_765f64657363.3">热点词</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> exam </category>
          
      </categories>
      
      
        <tags>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
            <tag> exam </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二分类之类别不平衡</title>
      <link href="/2021/05/31/%E4%BA%8C%E5%88%86%E7%B1%BB%E4%B9%8B%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1/"/>
      <url>/2021/05/31/%E4%BA%8C%E5%88%86%E7%B1%BB%E4%B9%8B%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/massquantity/p/8550875.html">机器学习之类别不平衡问题 (1) —— 各种评估指标 - massquantity - 博客园</a><br><a href="https://www.zhihu.com/question/269698662">欠采样（undersampling）和过采样（oversampling）会对模型带来怎样的影响？</a><br><a href="https://www.cnblogs.com/inchbyinch/p/12642760.html">详解类别不平衡问题 - 天地辽阔 - 博客园</a></p><h2 id="类别不平衡-class-imbalance"><a href="#类别不平衡-class-imbalance" class="headerlink" title="类别不平衡(class-imbalance)"></a>类别不平衡(class-imbalance)</h2><blockquote><p><font color="#D2691E"> 惯例</font><br>在二分类问题中，一般将数目少的类别视为正例，数目多的类别视为负例</p></blockquote><p><font color="#228B22">也叫数据倾斜，数据不平衡指分类任务中不同类别的训练样例数目差别很大的情况。</font></p><h2 id="各种评估指标"><a href="#各种评估指标" class="headerlink" title="各种评估指标"></a>各种评估指标</h2><p><a href="https://www.cnblogs.com/massquantity/p/8550875.html">机器学习之类别不平衡问题 (1) —— 各种评估指标 - massquantity - 博客园</a></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202167/1623024781731.png" alt="混淆矩阵图"></p><ul><li>True Positive(真正例，TP)：实例为正例，预测为正例</li><li>False Negative (假负例，FN)：实际为正例，预测为负例。</li><li>True Negative (真负例，TN)：实际为负例，预测为负例。</li><li>False Positive (假正例，FP)：实际为负例，预测为正例。</li></ul><ol><li>Precision (查准率) = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></math> ，Precision衡量的是<font color="#7FFF00">所有被预测为正例的样本中有多少是真正例</font>。<font color="#A52A2A">但Precision并没有表现有多少正例是被错判为了负例(即FN)</font>，举个极端的例子，分类器只将一个样本判为正例，其他所有都判为负例，这种情况下Precision为100%，但其实遗漏了很多正例，所以Precision常和下面的Recall (TPR) 相结合。</li><li>True Positive Rate (TPR，真正例率) = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></math> ，又称__Recall__(查全率,召回率)，Sensitivity(灵敏性)。Recall (TPR)衡量的是所有的正例中有多少是被<font color="#008B8B">正确分类</font>了，也可以看作是为了<font color="#057748">避免假负例(FN)的发生</font>，<font color="#0000FF">即将真正例分类到真正中而不是通过假负来判断的</font>，因为TPR高意味着FN低。Recall的问题和Precision正相反，没有表现出有多少负例被错判为正例(即FP)，若将所有样本全划为正例，则Recall为100%，但这样也没多大用。</li><li>True Negative Rate (TNR，真负例率) = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></math> ，又称Specificity(特异性)。Specificity衡量的是<font color="#006400">所有的负例中有多少是被正确分类</font>了，由于<font color="#1E90FF">类别不平衡问题中通常关注正例能否正确被识别，Specificity高则FP低，意味着很少将正例错判为负例，即该分类器对正例的判别具有“特异性”，在预测为正例的样本中很少有负例混入</font>。</li><li>False Positive Rate (FPR，假正例率) = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></math> = 1− $TNR$ , 由混淆矩阵可以看出该指标的<font color="#D2691E">着眼点</font>在于负例，意为有多少负例被错判成了正例。在ROC曲线中分别以TPR和FPR作为纵、横轴作图，显示出一种正例与负例之间的“<font color="#9400D3">博弈</font>”，在下篇文章中详解。</li></ol><p>F1 score = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>2</mn><mrow><mfrac><mn>1</mn><mtext>&#xA0;recall&#xA0;</mtext></mfrac><mo>+</mo><mfrac><mn>1</mn><mtext>&#xA0;precision&#xA0;</mtext></mfrac></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><mo>&#xD7;</mo><mtext>&#xA0;precision&#xA0;</mtext><mo>&#xD7;</mo><mtext>&#xA0;recall&#xA0;</mtext></mrow><mrow><mtext>&#xA0;precision&#xA0;</mtext><mo>+</mo><mtext>&#xA0;recall&#xA0;</mtext></mrow></mfrac></math></p><p>F1分数（F1-Score），又称为平衡F分数（BalancedScore），是一个综合指标,它被定义为精确率和召回率的调和平均数 (harmonic mean),数值上一般接近于二者中的<font color="#1E90FF">较小值</font>，因此如果F1 score比较高的话，意味着Precision和Recall都较高。</p><blockquote><p><font color="#7FFF00"> 知识补充</font><br>调和平均数（harmonic mean）又称倒数平均数，是总体各统计变量倒数的算术平均数的倒数。调和平均数是平均数的一种。<br>算数平均数中，重要性取决于绝对值大的一方（强），而在调和平均数中，<font color="#057748">重要性</font>取决于<font color="#8B0000">绝对值小的一方</font>（弱）。</p></blockquote><p>FP和FN还有个还有个与之相关的概念，那就是统计假设检验中的<font color="#483D8B">第一类错误</font> (Type I error)和<font color="#483D8B">第二类错误 (Type II error)</font> 。由于我们比较关心正例，所以将负例视为零假设，正例视为备选假设，则第一类错误为错误地拒绝零假设 (负例)，选择备选假设，则为FP；第二类错误为错误地接受零假设，则为FN。</p><blockquote><p><font color="#006400">知识补充</font><br>零假设的内容一般是希望证明其错误的假设。</p></blockquote><hr><p>上面介绍的这些指标都没有考虑检索结果的先后顺序，而像搜索问题中我们通常希望第一个结果是与查询最相关的，第二个则是次相关的，以此类推，因而有时候不仅要预测准确，<font color="#6495ED">对于相关性的顺序也非常看重</font>。所以最后介绍两个广泛应用的<font color="#9400D3">排序指标</font>。</p><p>Mean Average Precision (MAP，平均准确率均值)，对于<font color="#B8860B">单个</font>信息需求，返回结果中在每篇相关文档上 Precision 的平均值被称为 Average Precision (AP)，然后对<font color="#D2691E">所有</font>查询取平均得到 MAP。<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>AP</mi><mo>=</mo><mfrac><mrow><msubsup><mo>&#x2211;</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>P</mi><mo>(</mo><mi>k</mi><mo>)</mo><mo>&#xD7;</mo><mo>rel</mo><mo>(</mo><mi>k</mi><mo>)</mo></mrow><mi>M</mi></mfrac></math><br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>MAP</mi><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>Q</mi></munderover><mfrac><msub><mi>AP</mi><mi>q</mi></msub><mi>Q</mi></mfrac></math><br>其中 P(k) 为前 k 个结果的 Precision，又可写为P@k。 rel(k) 表示第 k 个结果是否为相关文档，相关为1不相关为0，M 表示所有相关文档的数量，n 表示所有文档数量。如果只关心<font color="#00008B">前 K 个查询的情况</font>，则是下式：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>AP</mi><mo>@</mo><mi>K</mi><mo>=</mo><mfrac><mrow><msubsup><mo>&#x2211;</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mi>P</mi><mo>(</mo><mi>k</mi><mo>)</mo><mo>&#xD7;</mo><mo>rel</mo><mo>(</mo><mi>k</mi><mo>)</mo></mrow><msub><mi>M</mi><mi>K</mi></msub></mfrac></math><br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>MAP</mi><mo>@</mo><mi>K</mi><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>Q</mi></munderover><mfrac><mrow><msub><mi>AP</mi><mi>q</mi></msub><mo>@</mo><mi>K</mi></mrow><mi>Q</mi></mfrac></math><br>这里的 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>M</mi><mi>K</mi></msub></math> 为前 K 个结果中相关文档的数量。</p><p>对于单个信息需求来说，Average Precision 是<font color="#bf242a"> PR 曲线</font>下面积的近似值，因此 MAP 可粗略地认为是某个查询集合对应的多条 PR 曲线下面积的平均值。</p><p><strong>Normalized Discounted Cumulative Gain</strong> (NDCG，归一化折扣累计增益) 。如果说 <font color="#0000FF">MAP 是基于 0/1 二值描述相关性</font>，那么 <font color="#9932CC">NDCG 则是可将相关性分为多个等级的指标</font>。<br>对于信息检索和推荐之类的问题，每一个返回的结果都被赋予一个相关性分数 rel，则 NDCG 中的 CG 表示前 k 个结果的分数之和，即累计增益 ：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>CG</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>rel</mi><mi>i</mi></msub></math></p><p>CG 没有考虑推荐的次序，所以在此基础上引入对结果顺序的考虑，即<font color="#DC143C">相关性高的结果</font>若排在后面则会受更多的惩罚，于是就有了 DCG (discounted CG)，折扣累积增益。公式如下：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>DCG</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mfrac><mrow><msup><mn>2</mn><msub><mi>rel</mi><mi>i</mi></msub></msup><mo>-</mo><mn>1</mn></mrow><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mfrac></math></p><p>i 表示一个结果在结果集中的顺序，如果该结果 rel 很高，但排在后面，意味着分母 log2(i+1) 会变大，则相应的总体 DCG 会变小 (注意这里的 log 是以 2 为底的)。</p><p>对于不同的查询，往往会返回不同的结果集，而不同结果集之间因为大小不同难以直接用 DCG 进行比较，所以需要进行<font color="#006400">归一化</font>，这其实和机器学习中不同特征因量纲不同要进行归一化差不多意思。这个归一化后的指标就是 NDCG ：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>NDCG</mi><mi>k</mi></msub><mo>=</mo><mfrac><msub><mi>DCG</mi><mi>k</mi></msub><msub><mi>IDCG</mi><mi>k</mi></msub></mfrac></math><br>其中 IDCG 表示 Ideal DCG， 指<font color="#006400">某个查询所能返回的最好结果集</font>，IDCG 的值也是结果集中最大的。将所有结果按相关性大小排序，计算出的 DCG 即为前 k 个结果的 IDCG：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>IDCG</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo>|</mo><mi>R</mi><mi>E</mi><mi>L</mi><mo>|</mo></mrow></munderover><mfrac><mrow><msup><mn>2</mn><msub><mi>rel</mi><mi>i</mi></msub></msup><mo>-</mo><mn>1</mn></mrow><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mfrac></math><br>其中 |REL| 表示按相关性顺序排列的结果集。因此 DCG 的值介于 (0, IDCG] ，故 NDCG 的值介于(0,1]，这样就起到了归一化的效果。不同查询或用户的 NDCG 平均起来可以用以评估一个搜索引擎或推荐系统的整体效果。</p><p>NDCG 的缺点是<font color="#483D8B">需要预先指定每一个返回结果的相关性</font>，这个超参数需要人为指定。</p><h2 id="常用的评估方法"><a href="#常用的评估方法" class="headerlink" title="常用的评估方法"></a>常用的评估方法</h2><h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>ROC曲线常用于二分类问题中的模型比较，主要表现为一种<font color="#0000FF">真正例率 (TPR) </font>和<font color="#0000FF">假正例率 (FPR) </font>的权衡。</p><p><strong><font color="#ff7500">概述：</font></strong> 是在不同的分类阈值 (threshold) 设定下分别以TPR和FPR为纵、横轴作图。由ROC曲线的两个指标，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mi>P</mi></mfrac><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></math>，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mi>N</mi></mfrac><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></math> 可以看出，当一个样本被分类器判为正例，若其本身是正例，则TPR增加；若其本身是负例，则FPR增加，因此ROC曲线可以看作是随着阈值的不断移动，所有样本中正例与负例之间的“对抗”。曲线越靠近左上角，意味着<font color="#FF1493">越多的正例优先于负例，模型的整体表现也就越好</font>。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202167/1623072321656.png" alt="ROC曲线"></p><p> <strong><font color="#008B8B">AUC (Area Under the Curve)</font></strong></p><p> <img src="https://gitee.com/merlynr/img-store/raw/master/202167/1623073223653.png" alt="ROC space"></p><p>先看一下ROC曲线中的随机线，图中[0,0]到[1,1]的虚线即为随机线，该线上所有的点都<font color="#00FFFF">表示该阈值下TPR=FPR</font><br>根据定义，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mi>P</mi></mfrac></math>，表示所有正例中被预测为正例的概率；<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mi>N</mi></mfrac></math>，表示所有负例中被被预测为正例的概率。<font color="#B8860B">若二者相等，意味着无论一个样本本身是正例还是负例，分类器预测其为正例的概率是一样的，这等同于随机猜测</font>（注意这里的“随机”不是像抛硬币那样50%正面50%反面的那种随机）。</p><p>上图中B点就是一个随机点，无论是样本数量和类别如何变化，始终将75%的样本分为正例。</p><p><font color="#B8860B">ROC曲线围成的面积 (即AUC)可以解读为</font>：从所有正例中随机选取一个样本A，再从所有负例中随机选取一个样本B，分类器将A判为正例的概率比将B判为正例的概率大的可能性。可以看到位于随机线上方的点(如图中的A点)被认为好于随机猜测。在这样的点上TPR总大于FPR，意为正例被判为正例的概率大于负例被判为正例的概率。<br>从另一个角度看，由于画ROC曲线时都是先将所有样本按分类器的<font color="#1E90FF">预测概率</font>排序，<font color="#B22222">所以AUC反映的是分类器对样本的排序能力</font>，依照上面的例子就是A排在B前面的概率。<font color="#008B8B">AUC越大，自然排序能力越好</font>，即分类器将越多的正例排在负例之前。</p><p><font color="#8B0000">ROC曲线的绘制方法</font>：假设有P个正例，N个反例，首先拿到分类器对于每个样本预测为正例的概率，根据概率对所有样本进行<font color="#006400">逆序排列</font>，然后将<font color="#0000FF">分类阈值设为最大</font>，即把所有样本均预测为反例，此时图上的点为 (0,0)。然后将分类阈值依次设为每个样本的预测概率，即依次将每个样本划分为正例，如果该样本为真正例，则TP+1，即<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mi>P</mi><mi>R</mi><mo>+</mo><mfrac><mn>1</mn><mi>P</mi></mfrac></math>; 如果该样本为负例，则FP+1，即<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>+</mo><mfrac><mn>1</mn><mi>N</mi></mfrac></math>。最后的到所有样本点的TPR和FPR值，用线段相连。</p><blockquote><p><a href="https://github.com/massquantity/Class-Imbalance/tree/master/">massquantity/Class-Imbalance: 《机器学习之类别不平衡问题》文章代码</a></p></blockquote><h4 id="ROC的优点"><a href="#ROC的优点" class="headerlink" title="ROC的优点"></a>ROC的优点</h4><p><img src="https://gitee.com/merlynr/img-store/raw/master/202168/1623131643148.png" alt="混淆矩阵图"></p><ol><li><p>兼顾正例和负例的权衡。因为TPR聚焦于正例，FPR聚焦于与负例，使其成为一个比较均衡的评估方法。</p></li><li><p>ROC曲线选用的两个指标，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mi>P</mi></mfrac><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></math>，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mi>N</mi></mfrac><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></math>，都不依赖于具体的类别分布。</p><p> 注意TPR用到的TP和FN同属<font color="#FF1493">P</font>列，FPR用到的FP和TN同属<font color="#1E90FF">N</font>列，<font color="#7FFF00">所以即使P或N的整体数量发生了改变，也不会影响到另一列</font>。也就是说，即使正例与负例的比例发生了很大变化，ROC曲线也不会产生大的变化，而像Precision使用的TP和FP就分属两列，则易受类别分布改变的影响。</p></li></ol><p><a href="https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf">参考文献</a>中举了个例子，负例增加了10倍，ROC曲线没有改变，而PR曲线则变了很多。作者认为这是ROC曲线的优点，即具有<font color="#0000FF">鲁棒性</font>，在类别分布发生明显改变的情况下依然能客观地识别出较好的分类器。</p><blockquote><p><font color="#006400">代码验证</font><br><a href="https://www.cnblogs.com/massquantity/p/8592091.html">相关资料</a></p></blockquote><h4 id="ROC的缺点"><a href="#ROC的缺点" class="headerlink" title="ROC的缺点"></a>ROC的缺点</h4><ol><li>上文提到ROC曲线的优点是不会随着类别分布的改变而改变，但这在某种程度上也是其缺点。因为负例N增加了很多，而曲线却没变，这等于产生了大量FP。像信息检索中如果主要关心正例的预测准确性的话，这就不可接受了。</li><li>在类别不平衡的背景下，负例的数目众多致使FPR的增长不明显，导致ROC曲线呈现一个过分乐观的效果估计。ROC曲线的横轴采用FPR，根据<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>FPR</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mi>N</mi></mfrac><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></math>，当负例N的数量远超正例P时，FP的大幅增长只能换来FPR的微小改变。<font color="#B22222">结果是虽然大量负例被错判成正例，在ROC曲线上却无法直观地看出来。</font>（当然也可以只分析ROC曲线左边一小段）<br>举个例子，假设一个数据集有正例20，负例10000，开始时有20个负例被错判，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mn>20</mn><mrow><mn>20</mn><mo>+</mo><mn>9980</mn></mrow></mfrac><mo>=</mo><mn>0</mn><mo>.</mo><mn>002</mn></math>，接着又有20个负例错判，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><msub><mi>R</mi><mn>2</mn></msub><mo>=</mo><mfrac><mn>40</mn><mrow><mn>40</mn><mo>+</mo><mn>9960</mn></mrow></mfrac><mo>=</mo><mn>0</mn><mo>.</mo><mn>004</mn></math>，在ROC曲线上这个变化是很细微的。而与此同时Precision则从原来的0.5下降到了0.33，在PR曲线上将会是一个大幅下降。</li></ol><h3 id="PR-Precision-Recall-曲线"><a href="#PR-Precision-Recall-曲线" class="headerlink" title="PR(Precision Recall)曲线"></a>PR(Precision Recall)曲线</h3><p>PR曲线展示的是Precision vs Recall的曲线，PR曲线与ROC曲线的相同点是都采用了TPR (Recall)，都可以用AUC来衡量分类器的效果。不同点是ROC曲线使用了FPR，而PR曲线使用了Precision，因此<font color="#8A2BE2">PR曲线的两个指标都聚焦于正例</font>。<font color="#8A2BE2">类别不平衡问题中由于主要关心正例</font>，所以在此情况下PR曲线被广泛认为<font color="#FF8C00">优于</font>ROC曲线。</p><p>PR曲线的绘制与ROC曲线类似，PR曲线的AUC面积计算公式为：</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><munder><mo>&#x2211;</mo><mi>n</mi></munder><mo>(</mo><msub><mi>R</mi><mi>n</mi></msub><mo>-</mo><msub><mi>R</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>)</mo><msub><mi>P</mi><mi>n</mi></msub></math></p><blockquote><p><a href="https://github.com/massquantity/Class-Imbalance/tree/master/">massquantity/Class-Imbalance: 《机器学习之类别不平衡问题》文章代码</a></p></blockquote><p><strong><font color="#FF00FF">使用场景</font></strong></p><ol><li>ROC曲线由于<font color="#1E90FF">兼顾</font>正例与负例，所以适用于评估分类器的<font color="#B22222">整体性</font>能，相比而言PR曲线完全聚焦于<font color="#FF00FF">正例</font>。</li><li>如果有多份数据且存在不同的类别分布，比如信用卡欺诈问题中每个月正例和负例的比例可能都不相同，这时候如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合，因为<font color="#1E90FF">类别分布改变</font>可能使得PR曲线发生变化时好时坏，这种时候难以进行模型比较；反之，如果想<font color="#FF00FF">测试不同类别分布下对分类器的性能</font>的影响，则PR曲线比较适合。</li><li>如果想要评估在相同的类别分布下正例的预测情况，则宜选PR曲线。</li><li>类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好。</li><li>最后可以根据具体的应用，在曲线上找到最优的点，得到相对应的precision，recall，f1 score等指标，去调整模型的阈值，从而得到一个符合具体应用的模型。</li></ol><h2 id="采样方法"><a href="#采样方法" class="headerlink" title="采样方法"></a>采样方法</h2><blockquote><p><font color="#FF1493">前提：</font>章节二三主要谈的是类别不平衡的评估指标，因此我们可以选择选择具体的类别不平衡问题的方法。</p></blockquote><p>采样方法大致可分为<font color="#00CED1">过采样 (oversampling)</font> 和<font color="#2F4F4F">欠采样 (undersampling) </font>，虽然过采样和降采样主题思想简单，但这些年来研究出了很多变种，本篇挑一些来具体阐述。见下思维导图：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202168/1623137294136.png" alt="采样方法"></p><h3 id="过采样"><a href="#过采样" class="headerlink" title="过采样"></a>过采样</h3><ol><li>随机过采样</li></ol><p>随机过采样顾名思义就是从样本少的类别中随机抽样，再将抽样得来的样本添加到数据集中。然而这种方法如今已经不大使用了，因为重复采样往往会导致<font color="#1E90FF">严重的过拟合</font>，因而现在的主流过采样方法是通过某种方式人工合成一些少数类样本，从而达到类别平衡的目的，而这其中的鼻祖就是SMOTE。</p><ol start="2"><li>SMOTE</li></ol><p>SMOTE (synthetic minority oversampling technique) 的思想概括起来就是在<font color="#00FFFF">少数类</font>样本之间进行插值来产生额外的样本。具体地，对于一个少数类样本<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">X</mi><mi>i</mi></msub></math>使用K近邻法(k值需要提前指定)，求出离<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">X</mi><mi>i</mi></msub></math>距离最近的k个少数类样本，其中距离定义为样本之间n维特征空间的欧氏距离。然后从k个近邻点中随机选取一个，使用下列公式生成新样本：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">x</mi><mtext>new&#xA0;</mtext></msub><mo>=</mo><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub><mo>+</mo><mfenced><mrow><msub><mover><mi mathvariant="bold">x</mi><mo>^</mo></mover><mi>i</mi></msub><mo>-</mo><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></mrow></mfenced><mo>&#xD7;</mo><mi>&#x3B4;</mi></math><br>其中 <math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi mathvariant="bold">X</mi><mo>^</mo></mover></math> 为选出的k近邻点，δ∈[0,1]是一个随机数。下图就是一个SMOTE生成样本的例子，使用的是3-近邻，可以看出SMOTE生成的样本一般就在<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></math>和<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mover><mi mathvariant="bold">x</mi><mo>^</mo></mover><mi>i</mi></msub></math>相连的直线上：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623220386942.png" alt="SMOTE生成的样本"></p><p>SMOTE会随机选取少数类样本用以合成新样本，而不考虑周边样本的情况，这样容易带来两个<font color="#FF1493">问题</font>：</p><ol><li>如果选取的少数类样本周围也都是少数类样本，则新合成的样本不会提供太多有用信息。这就像支持向量机中远离margin的点对决策边界影响不大。</li><li>如果选取的少数类样本周围都是多数类样本，这类的样本可能是噪音，则新合成的样本会与周围的多数类样本产生大部分重叠，致使分类困难。</li></ol><p>总的来说我们希望新合成的少数类样本能处于两个类别的边界附近，这样往往能提供足够的信息用以分类。而这就是下面的 <strong>Border-line SMOTE</strong> 算法要做的事情。</p><blockquote><p><font color="#bf242a">知识补充</font><a href="https://blog.csdn.net/lemonaha/article/details/53410465#31-k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95">k近邻法–统计学习方法总结_lemonaha的博客-CSDN博客</a><br> k近邻法（k-nearest neighbor,<font color="#0000FF"> k-NN</font>）是一种基本分类与回归方法。这里只讨论分类问题中的k近邻法。k近邻法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。k近邻法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方法进行预测。因此，k近邻法不具有显式的学习过程。k近邻法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。**<font color="#1E90FF">k值的选择、距离度量及分类决策规则是k近邻法的三个基本要素</font>**。</p></blockquote><ol start="3"><li>Border-line SMOTE</li></ol><p>这个算法会先将所有的少数类样本分成三类，如下图所示：</p><ul><li>“noise” ： 所有的k近邻个样本都属于多数类</li><li>“danger” ： 超过一半的k近邻样本属于<font color="#0000FF">多</font>数类</li><li>“safe”： 超过一半的k近邻样本属于<font color="#0000FF">少</font>数类</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623220611894.png" alt="Border-line SMOTE"></p><p>  <font color="#ff7500">Border-line SMOTE</font>算法只会从处于”<em>danger</em>“状态的样本中随机选择，然后用SMOTE算法产生新的样本。处于”danger“状态的样本代表靠近”边界“附近的少数类样本，而处于边界附近的样本往往更<font color="#B8860B">容易被误分类</font>。因而 Border-line SMOTE 只对那些靠近”边界“的少数类样本进行人工合成样本，而 SMOTE 则对所有少数类样本一视同仁。</p><p>Border-line SMOTE 分为两种: Borderline-1 SMOTE 和 Borderline-2 SMOTE。 Borderline-1 SMOTE 在合成样本时,是式中的<math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi mathvariant="bold">x</mi><mo>^</mo></mover></math>是一个<font color="#1E90FF">少数类样本</font>，而 Borderline-2 SMOTE 中的<math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi mathvariant="bold">x</mi><mo>^</mo></mover></math>则是k近邻中的<font color="#FF1493">任意</font>一个样本。</p><ol start="4"><li>ADASYN</li></ol><p><font color="#8B008B">ADASYN</font>名为自适应合成抽样(adaptive synthetic sampling)，其最大的特点是<font color="#006400">采用某种机制自动决定每个少数类样本需要产生多少合成样本</font>，而不是像SMOTE那样对每个少数类样本合成同数量的样本。具体流程如下：</p><ol><li><p>首先计算需要合成的样本总量：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>G</mi><mo>=</mo><mfenced><mrow><msub><mi>S</mi><mrow><mi>m</mi><mi>a</mi><mi>j</mi></mrow></msub><mo>-</mo><msub><mi>S</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></mfenced><mo>&#xD7;</mo><mi>&#x3B2;</mi></math><br>其中<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mrow><mi>m</mi><mi>a</mi><mi>j</mi></mrow></msub></math>为多数类样本数量，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>min</mi></msub></math>为少数类样本数量，β∈[0,1]为系数。G即为总共想要<font color="#8A2BE2">合成的少数类样本数量</font>，如果β=1则是合成后各类别数目相等。</p></li><li><p>对于每个少类别样本xi，找出其K近邻个点，并计算：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>&#x393;</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>&#x394;</mi><mi>i</mi></msub><mo>/</mo><mi>K</mi></mrow><mi>Z</mi></mfrac></math><br>其中Δi为K近邻个点中多数类样本的数量，Z为规范化因子以确保 Γ 构成一个分布。这样若一个少数类样本<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></math>的周围多数类样本越多，则其 Γi 也就越高。</p></li><li><p>最后对每个少类别样本<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></math>计算需要合成的样本数量<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">g</mi><mi>i</mi></msub></math>，再用SMOTE算法合成新样本：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>g</mi><mi>i</mi></msub><mo>=</mo><msub><mi>&#x393;</mi><mi>i</mi></msub><mo>&#xD7;</mo><mi>G</mi></math><br>可以看到ADASYN利用分布Γ来自动决定每个少数类样本所需要合成的样本数量，这等于是给每个少数类样本施加了一个权重，周围的多数类样本越多则权重越高。ADASYN的缺点是<font color="#A52A2A">易受离群点的影响</font>，如果一个少数类样本的K近邻都是多数类样本，则其权重会变得相当大，进而会在其周围生成较多的样本。</p></li></ol><p>下面利用sklearn中的 <em>make_classification</em> 构造了一个不平衡数据集，各类别比例为{0:54, 1:946}。原始数据，SMOTE，Borderline-1 SMOTE，Borderline-2 SMOTE和ADASYN的比较见下图，<font color="#0000FF">左侧为过采样后的决策边界</font>，<font color="#8B008B">右侧为过采样后的样本分布情况</font>，<font color="#B8860B">可以看到过采样后原来少数类的决策边界都扩大了，导致更多的多数类样本被划为少数类了</font>：</p><blockquote><p><font color="#0000FF">知识补充</font><br>决策边界顾名思义就是需要分类的数据中，区分不同类别的边界。</p></blockquote><pre><code>    原始数据</code></pre><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623222264899.png" alt="原始数据"><br>        SMOTE<br><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623222317451.png" alt="SMOTE过采样"><br>        Borderline-1 SMOTE<br><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623222382482.png" alt="Borderline-1 SMOTE"><br>        Borderline-2 SMOTE<br><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623222404250.png" alt="Borderline-2 SMOTE"><br>        ADASYN<br><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623222425227.png" alt="ADASYN"></p><p>从上图我们也可以比较几种过采样方法各自的特点。用 <code>SMOTE</code> 合成的样本分布比较平均，而<code>Border-line SMOTE</code>合成的样本则集中在类别边界处。<code>ADASYN</code>的特性是一个少数类样本周围多数类样本越多，则算法会为其生成越多的样本，从图中也可以看到生成的样本大都来自于原来与多数类比较靠近的那些少数类样本。</p><h3 id="欠采样"><a href="#欠采样" class="headerlink" title="欠采样"></a>欠采样</h3><ol><li><p>随机欠采样</p><p> 随机欠采样的思想同样比较简单，就是从多数类样本中随机选取一些剔除掉。这种方法的缺点是<font color="#0000FF">被剔除的样本可能包含着一些重要信息</font>，致使学习出来的模型效果不好。</p></li><li><p>EasyEnsemble 和 BalanceCascade<br>  EasyEnsemble和BalanceCascade采用集成学习机制来<font color="#8A2BE2">处理传统随机欠采样中的信息丢失</font>问题。</p></li></ol><ul><li>EasyEnsemble将多数类样本随机<font color="#00FFFF">划分成n个子集</font>，每个子集的数量等于少数类样本的数量，这相当于欠采样。接着将每个子集与少数类样本结合起来分别训练一个模型，最后将n个模型集成，这样虽然每个子集的样本少于总体样本，但集成后总信息量并不减少。</li><li>如果说EasyEnsemble是基于无监督的方式从多数类样本中生成子集进行欠采样，那么BalanceCascade则是采用了<font color="#7FFFD4">有监督</font>结合Boosting的方式。在第n轮训练中，将从多数类样本中抽样得来的子集与少数类样本结合起来训练一个基学习器H，训练完后多数类中能被H正确分类的样本会被剔除。在接下来的第n+1轮中，从被剔除后的多数类样本中产生子集用于与少数类样本结合起来训练，最后将不同的基学习器集成起来。BalanceCascade的有监督表现在每一轮的基学习器起到了在多数类中选择样本的作用，而其Boosting<font color="#bf242a">特点则体现在每一轮丢弃被正确分类的样本，进而后续基学习器会更注重那些之前分类错误的样本。</font></li></ul><blockquote><p><font color="#0000FF">知识补充</font>基学习器<br><a href="https://www.biaodianfu.com/boosting.html">机器学习算法之Boosting – 标点符</a><br>同质集成中的个体学习器又称为基学习器（base learner），相应的学习算法也被称为基学习算法（base learning algorithm）。</p></blockquote><ol start="3"><li>NearMiss</li></ol><p><font color="#725e82"><strong>NearMiss</strong></font>本质上是一种<font color="#BDB76B">原型选择</font>(prototype selection)方法，即从多数类样本中选取最具代表性的样本用于训练，主要是为了缓解随机欠采样中的信息丢失问题。NearMiss采用一些<font color="#A52A2A">启发式的规则</font>来选择样本，根据规则的不同可分为3类：</p><ul><li>NearMiss-1：选择到最近的K个少数类样本平均距离最近的多数类样本</li><li>NearMiss-2：选择到最远的K个少数类样本平均距离最近的多数类样本</li><li>NearMiss-3：对于每个少数类样本选择K个最近的多数类样本，目的是保证每个少数类样本都被多数类样本包围</li></ul><p>NearMiss-1和NearMiss-2的计算<font color="#0000FF">开销很大</font>，因为需要计算每个多类别样本的K近邻点。另外，NearMiss-1易受离群点的影响，如下面第二幅图中合理的情况是处于边界附近的多数类样本会被选中，然而由于右下方一些少数类离群点的存在，其附近的多数类样本就被选择了。相比之下NearMiss-2和NearMiss-3不易产生这方面的问题。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623224933174.png" alt="图一Oniginal data"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623225034300.png" alt="图二Resampling using Nearmiss-1"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623225086130.png" alt="图三Resampling using Nearmiss-2"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623225124104.png" alt="图四Resampling using Nearmiss-3"></p><ol start="4"><li>数据清洗方法 (data cleaning tichniques)</li></ol><p>这类方法主要<font color="#8A2BE2">通过某种规则来清洗重叠的数据</font>，从而达到欠采样的目的，而这些规则往往也是启发性的，下面进行简要阐述：</p><ul><li><p><font color="#ff7500">Tomek Link</font>：Tomek Link表示<font color="#7FFFD4">不同类别</font>之间距离最近的一对样本，即<font color="#bf242a">这两个样本互为最近邻且分属不同类别</font>。这样如果两个样本形成了一个Tomek Link，则要么其中一个是噪音，要么两个样本都在边界附近。这样通过移除Tomek Link就能“清洗掉”类间重叠样本，使得互为最近邻的样本皆属于同一类别，从而能更好地进行分类。</p><pre><code>  下图一上为原始数据，图二上为SMOTE后的数据，图三虚线标识出Tomek Link，图四为移除Tomek Link后的数据集，可以看到不同类别之间样本重叠减少了很多。</code></pre></li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623226151018.png" alt="图一"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623226162443.png" alt="图二"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623226175192.png" alt="图三"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623226186988.png" alt="图四"></p><ul><li><font color="#ff7500"> Edited Nearest Neighbours(ENN)</font>：对于属于多数类的一个样本，如果其K个近邻点有超过一半都不属于多数类，则这个样本会被剔除。这个方法的另一个变种是所有的K个近邻点都不属于多数类，则这个样本会被剔除。、</li></ul><p>最后，数据清洗技术<font color="#0000FF">最大的缺点</font>是无法控制欠采样的数量。由于都在某种程度上采用了K近邻法，而事实上大部分多数类样本周围也都是多数类，因而能剔除的多数类样本比较有限。</p><h3 id="过采样和欠采样结合"><a href="#过采样和欠采样结合" class="headerlink" title="过采样和欠采样结合"></a>过采样和欠采样结合</h3><p>上文中提到SMOTE算法的缺点是生成的少数类样本容易与周围的多数类样本产生重叠难以分类，而数据清洗技术恰好可以处理掉重叠样本，所以可以将二者结合起来形成一个pipeline，先过采样再进行数据清洗。主要的方法是 <code>SMOTE + ENN</code> 和 <code>SMOTE + Tomek</code> ，其中 <code>SMOTE + ENN</code> 通常能清除更多的重叠样本，如下图：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623227628385.png" alt="Resampling using Original"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623227661187.png" alt="Resampling using SMOTE"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623227708226.png" alt="Resampling using SMOTE + ENN"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202169/1623227766137.png" alt="Resampling using SMOTE + TOMEK"></p><hr><p><strong><font color="#DC143C">★ 采样方法的效果</font></strong></p><p><a href="https://www.cnblogs.com/massquantity/p/9382710.html">机器学习之类别不平衡问题 (3) —— 采样方法 - massquantity - 博客园</a></p><h2 id="省心的方法"><a href="#省心的方法" class="headerlink" title="省心的方法"></a>省心的方法</h2><h3 id="主动收集数据"><a href="#主动收集数据" class="headerlink" title="主动收集数据"></a>主动收集数据</h3><p>针对少量样本数据，可以尽可能去扩大这些少量样本的数据集，或者尽可能去增加他们特有的特征来丰富数据的多样性（尽量转化成情况1）。譬如，如果是一个情感分析项目，在分析数据比例时发现负样本（消极情感）的样本数量较少，那么我们可以尽可能在网站中搜集更多的负样本数量，或者花钱去买，毕竟数据少了会带来很多潜在的问题。</p><h3 id="将任务转换成异常检测问题、"><a href="#将任务转换成异常检测问题、" class="headerlink" title="将任务转换成异常检测问题、"></a>将任务转换成异常检测问题、</h3><p>如果少数类样本太少，少数类的结构可能并不能被少数类样本的分布很好地表示，那么用平衡数据或调整算法的方法不一定有效。如果这些少数类样本在特征空间中再分布的比较散，情况会更加糟糕。这时候不如将其转换为无监督的异常检测算法，不用过多的去考虑将数据转换为平衡问题来解决。</p><h3 id="调整权重"><a href="#调整权重" class="headerlink" title="调整权重"></a>调整权重</h3><p>可以简单的设置损失函数的权重，让模型增加对多数类的惩罚，更多的关注少数类。在python的scikit-learn中我们可以使用class_weight参数来设置权重。</p><p>另外，调整权重方法也适合于这种情况：不同类型的错误所造成的后果不同。例如在医疗诊断中，错误地把健康人诊断为患者可能会带来进一步检查的麻烦，但是错误地把患者诊断为健康人，则可能会丧失了拯救生命的最佳时机；再如，门禁系统错误地把可通行人员拦在门外，将使得用户体验不佳，但错误地把陌生人放进门内，则会造成严重的安全事故；在信用卡盗用检查中，将正常使用误认为是盗用，可能会使用户体验不佳，但是将盗用误认为是正常使用，会使用户承受巨大的损失。为了权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价”（unequal cost）。</p><h3 id="阈值调整（threshold-moving）"><a href="#阈值调整（threshold-moving）" class="headerlink" title="阈值调整（threshold moving）"></a>阈值调整（threshold moving）</h3><p>直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将原本默认为0.5的阈值调整到 <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mo>|</mo><mi>P</mi><mo>|</mo></mrow><mrow><mo>(</mo><mo>|</mo><mi>P</mi><mo>|</mo><mo>+</mo><mo>|</mo><mi>N</mi><mo>|</mo><mo>)</mo></mrow></mfrac></math>即可。（大部分是负样本，因此分类器倾向于给出较低的分数）</p><h2 id="类别不平横影响模型的输出"><a href="#类别不平横影响模型的输出" class="headerlink" title="类别不平横影响模型的输出"></a>类别不平横影响模型的输出</h2><p>许多模型的输出是基于阈值的，大部分模型的默认阈值为输出值的中位数。比如逻辑回归的输出范围为[0,1]，当某个样本的输出大于0.5就会被划分为正例，反之为反例。在数据的类别不平衡时，采用默认的分类阈值可能会导致输出全部为反例，产生虚假的高准确度，导致分类失败。</p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> machine learning </tag>
            
            <tag> data mining </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>孤立森林（Isolation Forest）</title>
      <link href="/2021/05/31/%E5%AD%A4%E7%AB%8B%E6%A3%AE%E6%9E%97%EF%BC%88Isolation%20Forest%EF%BC%89/"/>
      <url>/2021/05/31/%E5%AD%A4%E7%AB%8B%E6%A3%AE%E6%9E%97%EF%BC%88Isolation%20Forest%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622426214147.png" alt="数据蛋糕"></p><p>假设我们用一个随机超平面来切割（split）数据空间（data space）, 切一次可以生成两个子空间（想象拿刀切蛋糕一分为二）。</p><p>之后我们再继续用一个随机超平面来切割每个子空间，循环下去，直到每子空间里面只有一个数据点为止。</p><blockquote><p><font color="#8B008B">满足的条件</font></p><ul><li>数据本身不可再分割</li><li>二叉树达到限定的最大深度</li></ul></blockquote><p>直观上来讲，我们可以发现那些密度很高的簇是可以被切很多次才会停止切割，但是那些密度很低的点很容易很早的就停到一个子空间里了。</p><p><font color="#6495ED">异常检测原理的理解：</font>由于异常值的数量较少且与大部分样本的疏离性，因此，异常值会被更早的孤立出来，也即异常值会距离iTree的根节点更近，而正常值则会距离根节点有更远的距离。</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>孤立森林算法主要针对的是<strong>连续型结构化</strong>数据中的异常点。</p><p><font color="#FF1493">理论前提</font></p><ul><li>异常数据占总样本量的比例很小</li><li>异常点的特征值与正常点的差异很大</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622426925434.png" alt="数据"></p><p>上图中，中心的白色空心点为正常点，即处于高密度群体中。四周的黑色实心点为异常点，散落在高密度区域以外的空间。</p><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p>孤立森林算法是基于 <strong>Ensemble</strong> 的异常检测方法，因此具有<font color="#7FFF00">线性的时间复杂度</font>。且精准度较高，在处理大数据时速度快，所以目前在工业界的应用范围比较广。常见的场景包括：网络安全中的攻击检测、金融交易欺诈检测、疾病侦测、噪声数据过滤（数据清洗）等。</p><blockquote><p><font color="#006400">知识补充</font>集成学习算法 (Ensemble Learning)<br>统机器学习算法 (例如：决策树，人工神经网络，支持向量机，朴素贝叶斯等) 的目标都是寻找一个最优分类器尽可能的将训练数据分开。集成学习 (Ensemble Learning) 算法的基本思想就是将多个分类器<font color="#8FBC8F">组合</font>，从而实现一个预测效果更好的<font color="#8A2BE2">集成分类器</font>。</p></blockquote><blockquote><p><font color="#FF00FF">知识补充：</font><br><a href="https://blog.zuishuailcq.xyz/2021/05/31/%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/">算法的性能指标 | 吾辈之人，自当自强不息！</a></p></blockquote><h2 id="孤立森林的创新点"><a href="#孤立森林的创新点" class="headerlink" title="孤立森林的创新点"></a>孤立森林的创新点</h2><ol><li><font color="#D2691E">Partial models</font>：在训练过程中，每棵孤立树都是随机选取部分样本</li><li><font color="#D2691E">No distance or density measures</font>：不同于 KMeans、DBSCAN 等算法，孤立森林不需要计算有关距离、密度的指标，可大幅度提升速度，减小系统开销</li><li><font color="#D2691E"> Linear time complexity</font>：因为基于 ensemble，所以有线性时间复杂度。通常树的数量越多，算法越稳定</li><li><font color="#D2691E">Handle extremely large data size</font>：由于每棵树都是独立生成的，因此可部署在大规模分布式系统上来加速运算</li></ol>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> machine learning </tag>
            
            <tag> data mining </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拟合</title>
      <link href="/2021/05/31/%E6%8B%9F%E5%90%88/"/>
      <url>/2021/05/31/%E6%8B%9F%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/72038532#:~:text=%E5%AF%B9%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%88%96%E6%9C%BA%E5%99%A8,%E7%A7%B0%E4%B8%BA%E6%B3%9B%E5%8C%96%E8%AF%AF%E5%B7%AE%E3%80%82">欠拟合、过拟合及如何防止过拟合 - 知乎</a></p><h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><p>对于深度学习或机器学习模型而言，我们不仅要求它对训练数据集有很好的拟合（训练误差），同时也希望它可以对未知数据集（测试集）有很好的拟合结果（泛化能力），所产生的测试误差被称为泛化误差。度量泛化能力的好坏，最直观的表现就是模型的过拟合（overfitting）和欠拟合（underfitting）。过拟合和欠拟合是用于描述模型在训练过程中的两种状态。一般来说，训练过程会是如下所示的一个曲线图。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622461280602.png" alt="训练过程"></p><p>训练刚开始的时候，模型还在学习过程中，处于欠拟合区域。随着训练的进行，训练误差和测试误差都下降。在到达一个临界点之后，训练集的误差下降，测试集的误差上升了，这个时候就进入了过拟合区域——由于训练出来的网络过度拟合了训练集，对训练集以外的数据却不有效。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622461630220.png" alt="拟合"></p><h2 id="欠拟合"><a href="#欠拟合" class="headerlink" title="欠拟合"></a>欠拟合</h2><p><font color="#9932CC">欠拟合</font>是指模型不能在训练集上获得足够低的误差。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622461604985.png" alt="欠拟合"></p><p><strong>如何解决欠拟合？</strong></p><p>欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。但是如果真的还是存在的话，可以通过<font color="#7FFF00">增加网络复杂度</font>或者在模型中<font color="#7FFF00">增加特征</font>，这些都是很好解决欠拟合的方法。</p><h2 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h2><p><font color="#9932CC">过拟合</font>是指训练误差和测试误差之间的差距太大。换句换说，就是模型复杂度高于实际问题，<font color="#ff7500">模型在训练集上表现很好，但在测试集上却表现很差。</font>模型对训练集”死记硬背”（记住了不适用于测试集的训练集性质或特点），没有理解数据背后的规律，泛化能力差。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622461615228.png" alt="过拟合"></p><p><font color="#FF1493">出现原因</font></p><ol><li><strong>训练数据集样本单一，样本不足。</strong> 如果训练样本只有负样本，然后那生成的模型去预测正样本，这肯定预测不准。所以训练样本要尽可能的全面，覆盖所有的数据类型。</li><li><strong>训练数据中噪声干扰过大。</strong> 噪声指训练数据中的干扰数据。过多的干扰会导致记录了很多噪声特征，忽略了真实输入和输出之间的关系。</li><li><strong>模型过于复杂</strong>。模型太复杂，已经能够“死记硬背”记下了训练数据的信息，但是遇到没有见过的数据的时候不能够变通，泛化能力太差。我们希望模型对不同的模型都有稳定的输出。模型太复杂是过拟合的重要因素。</li></ol><p><strong><font color="#FF8C00">如何防止过拟合</font></strong><br>要想解决过拟合问题，就要显著减少测试误差而不过度增加训练误差，从而提高模型的泛化能力。我们可以使用正则化（Regularization）方法。</p><blockquote><p>正则化是指修改学习算法，使其降低泛化误差而非训练误差。</p></blockquote><h3 id="正则化方法"><a href="#正则化方法" class="headerlink" title="正则化方法"></a>正则化方法</h3><blockquote><p>常用的正则化方法根据具体的使用<font color="#D2691E">策略</font>不同可分为：<br>（1）直接提供正则化约束的参数正则化方法，如L1/L2正则化；<br>（2）通过工程上的技巧来实现更低泛化误差的方法，如提前终止(Early stopping)和Dropout；<br>（3）不直接提供约束的隐式正则化方法，如数据增强等。</p></blockquote><ol><li> 获取和使用更多的数据（数据集增强）——解决过拟合的<font color="#DC143C">根本性</font>方法</li></ol><p>让机器学习或深度学习模型泛化能力更好的办法就是使用更多的数据进行训练。但是，在实践中，我们拥有的数据量是有限的。解决这个问题的一种方法就是<font color="#7FFF00">创建“假数据”并添加到训练集中——数据集增强</font>。通过增加训练集的额外副本来增加训练集的大小，进而改进模型的泛化能力。</p><ol start="2"><li>采用合适的模型（控制模型的复杂度）</li></ol><p>过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律”deeper is better”。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。</p><p>根据<font color="#E9967A">奥卡姆剃刀</font>法则：在同样能够解释已知观测现象的假设中，我们应该挑选“最简单”的那一个。对于模型的设计而言，我们应该选择简单、合适的模型解决复杂的问题。</p><ol start="3"><li>降低特征的数量</li></ol><p>对于一些特征工程而言，可以降低特征的数量——<font color="#006400">删除冗余特征</font>，人工选择保留哪些特征。这种方法也可以解决过拟合问题。</p><ol start="4"><li>L1 / L2 正则化</li></ol><p><a href="https://www.cnblogs.com/zingp/p/10375691.html#_label0">深入理解L1、L2正则化 - ZingpLiu - 博客园</a></p><ul><li>L1正则化</li></ul><p>L1正则化可以使得参数稀疏化，即得到的参数是一个稀疏矩阵，可以用于特征选择。</p><pre><code>    稀疏性，说白了就是模型的很多参数是0。通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，很多参数是0，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，即使去掉对模型也没有什么影响，此时我们就可以只</code></pre><p>在原始的损失函数后面加上一个L1正则化项，即<strong>全部权重 $w$ 的绝对值的和，再乘以λ/n</strong>。则损失函数变为：</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi><mo>=</mo><msub><mi>C</mi><mn>0</mn></msub><mo>+</mo><mfrac><mi>&#x3BB;</mi><mi>n</mi></mfrac><munder><mo>&#x2211;</mo><mi>i</mi></munder><mfenced close="|" open="|"><msub><mi>w</mi><mi>i</mi></msub></mfenced></math></p><p>对应的梯度（导数）：</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mo>&#x2202;</mo><mi>C</mi></mrow><mrow><mo>&#x2202;</mo><mi>w</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mo>&#x2202;</mo><msub><mi>C</mi><mn>0</mn></msub></mrow><mrow><mo>&#x2202;</mo><mi>w</mi></mrow></mfrac><mo>+</mo><mfrac><mi>&#x3BB;</mi><mi>n</mi></mfrac><mo>sgn</mo><mo>(</mo><mi>w</mi><mo>)</mo></math></p><p>其中 <math xmlns="http://www.w3.org/1998/Math/MathML"><mo>sgn</mo><mo>(</mo><mi>w</mi><mo>)</mo></math> 只是简单地取 $w1$ 各个元素地正负号。</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>sgn</mo><mo>(</mo><mi>w</mi><mo>)</mo><mo>=</mo><mfenced close="" open="{"><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>,</mo><mi>w</mi><mo>&gt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn><mo>,</mo><mi>w</mi><mo>=</mo><mn>0</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>1</mn><mo>,</mo><mi>w</mi><mo>&lt;</mo><mn>0</mn></mtd></mtr></mtable></mfenced></math></p><p>梯度下降时权重 $w$ 更新变为：</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>w</mi><mo>&#x2192;</mo><msup><mi>w</mi><mo>‘</mo></msup><mo>=</mo><mi>w</mi><mo>-</mo><mfrac><mrow><mi>&#x3B7;</mi><mi>&#x3BB;</mi></mrow><mi>n</mi></mfrac><mo>sgn</mo><mo>(</mo><mi>w</mi><mo>)</mo><mo>-</mo><mi>&#x3B7;</mi><mfrac><mrow><mo>&#x2202;</mo><msub><mi>C</mi><mn>0</mn></msub></mrow><mrow><mo>&#x2202;</mo><mi>w</mi></mrow></mfrac></math></p><p>当 $w=0$ 时，|w|是不可导的。所以我们仅仅能依照原始的未经正则化的方法去更新 $w$  。<br>当 $w&gt;0$  时，sgn( $w$  )&gt;0, 则梯度下降时更新后的 $w$  变小。<br>当 $w&lt;0$  时，sgn( $w$  )&gt;0, 则梯度下降时更新后的 $w$  变大。换句换说，L1正则化使得权重 $w$ 往0靠，使网络中的权重尽可能为0，也就相当于减小了网络复杂度，防止过拟合。</p><p>这也就是<font color="#6495ED">L1正则化会产生更稀疏（sparse）的解</font>的原因。此处稀疏性指的是最优值中的一些参数为0。<font color="#1E90FF">L1正则化的稀疏性质已经被广泛地应用于特征选择</font>机制，从可用的特征子集中选择出有意义的特征。</p><ul><li>L2 正则化</li></ul><p>L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合。</p><p>拟合过程中通常都倾向于让权值尽可能小，最后构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。可以设想一下对于一个线性回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，专业一点的说法是抗扰动能力强。</p><p>L2正则化通常被称为<strong>权重衰减</strong>（weight decay），就是在原始的损失函数后面再加上一个L2正则化项，即<strong>全部权重</strong> $w$  的平方和，再乘以λ/2n。则损失函数变为：</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi><mo>=</mo><msub><mi>C</mi><mn>0</mn></msub><mo>+</mo><mfrac><mi>&#x3BB;</mi><mrow><mn>2</mn><mi>n</mi></mrow></mfrac><mo>&#xB7;</mo><mo>&#x2211;</mo><msubsup><mi>w</mi><mi>i</mi><mn>2</mn></msubsup></math></p><p>对应的梯度（导数）：</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mo>&#x2202;</mo><mi>C</mi></mrow><mrow><mo>&#x2202;</mo><mi>w</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mo>&#x2202;</mo><msub><mi>C</mi><mn>0</mn></msub></mrow><mrow><mo>&#x2202;</mo><mi>w</mi></mrow></mfrac><mo>+</mo><mfrac><mi>&#x3BB;</mi><mi>n</mi></mfrac><mi>w</mi></math></p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mo>&#x2202;</mo><mi>C</mi></mrow><mrow><mo>&#x2202;</mo><mi>b</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mo>&#x2202;</mo><msub><mi>C</mi><mn>0</mn></msub></mrow><mrow><mo>&#x2202;</mo><mi>b</mi></mrow></mfrac></math></p><p>能够发现L2正则化项对偏置 b 的更新没有影响，可是对于权重 $w$  的更新有影响：</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>w</mi><mo>&#x2192;</mo><mi>w</mi><mo>-</mo><mi>&#x3B7;</mi><mfrac><mrow><mo>&#x2202;</mo><msub><mi>C</mi><mn>0</mn></msub></mrow><mrow><mo>&#x2202;</mo><mi>w</mi></mrow></mfrac><mo>-</mo><mfrac><mrow><mi>&#x3B7;</mi><mi>&#x3BB;</mi></mrow><mi>n</mi></mfrac><mi>w</mi></math><br><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>=</mo><mfenced><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mi>&#x3B7;</mi><mi>&#x3BB;</mi></mrow><mi>n</mi></mfrac></mrow></mfenced><mi>w</mi><mo>-</mo><mi>&#x3B7;</mi><mfrac><mrow><mo>&#x2202;</mo><msub><mi>C</mi><mn>0</mn></msub></mrow><mrow><mo>&#x2202;</mo><mi>w</mi></mrow></mfrac></math><br>这里的<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3B7;</mi></math>、 $n$ 、<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3BB;</mi></math>都是大于0的， 所以 <math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mo>-</mo><mfrac><mrow><mi>&#x3B7;</mi><mi>&#x3BB;</mi></mrow><mi>n</mi></mfrac></math>小于1。因此在梯度下降过程中，权重 $w$ 将逐渐减小，趋向于0但不等于0。这也就是<strong>权重衰减</strong>（weight decay）的由来。</p><p>L2正则化起到使得权重参数 $w$ 变小的效果，为什么能防止过拟合呢？因为更小的权重参数  意味着模型的复杂度更低，对训练数据的拟合刚刚好，不会过分拟合训练数据，从而提高模型的泛化能力。</p><ol start="5"><li>Dropout</li></ol><p>  Dropout是在训练网络时用的一种技巧（trike），相当于在隐藏单元增加了噪声。<strong>Dropout 指的是在训练过程中每次按一定的概率（比如50%）随机地“删除”一部分隐藏单元（神经元）</strong>。所谓的“删除”不是真正意义上的删除，其实就是将该部分神经元的激活函数设为0（激活函数的输出为0），让这些神经元不计算而已。</p><p>  <img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622466578527.png" alt="Dropout"></p><p><font color="#006400">  <strong>Dropout为什么有助于防止过拟合呢？</strong></font></p><p>（a）在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果。随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。<br>（b）它消除或者减弱了神经元节点间的联合，降低了网络对单个神经元的依赖，从而增强了泛化能力。</p><blockquote><p><font color="#00008B">理解</font><br>通过加入噪声，在训练模型时，扩展模型的接受范围，避免过拟合</p></blockquote><ol start="6"><li>Early stopping（提前终止）</li></ol><p>对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如梯度下降（Gradient descent）。Early stopping是一种迭代次数截断的方法来防止过拟合的方法，<font color="#7FFF00">即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合</font>。</p><p>为了获得性能良好的神经网络，训练过程中可能会经过很多次epoch（遍历整个数据集的次数，一次为一个epoch）。如果epoch数量太少，网络有可能发生欠拟合；如果epoch数量太多，则有可能发生过拟合。Early stopping旨在解决epoch数量需要手动设置的问题。具体做法：每个epoch（或每N个epoch）结束后，在验证集上获取测试结果，随着epoch的增加，如果在验证集上发现测试误差上升，则停止训练，将停止之后的权重作为网络的最终参数。</p><p><font color="#E9967A">为什么能防止过拟合？</font></p><p>当还未在神经网络运行太多迭代过程的时候，w参数[误差]接近于0，因为随机初始化w值的时候，它的值是较小的随机值。当你开始迭代过程，w的值会变得越来越大。到后面时，w的值已经变得十分大了。所以early stopping要做的就是在中间点停止迭代过程。我们将会得到一个中等大小的w参数，会得到与L2正则化相似的结果，选择了w参数较小的神经网络。</p><p><font color="#A52A2A">Early Stopping缺点</font><br><strong>没有采取不同的方式来解决优化损失函数和过拟合这两个问题</strong>，而是用一种方法同时解决两个问题 ，结果就是要考虑的东西变得更复杂。之所以不能独立地处理，因为如果你停止了优化损失函数，你可能会发现损失函数的值不够小，同时你又不希望过拟合。</p>]]></content>
      
      
      <categories>
          
          <category> machine learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> machine learning </tag>
            
            <tag> data mining </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法的性能指标</title>
      <link href="/2021/05/31/%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/"/>
      <url>/2021/05/31/%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kernal</title>
      <link href="/2021/05/30/kernal/"/>
      <url>/2021/05/30/kernal/</url>
      
        <content type="html"><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p><font color="#6495ED">核方法</font>是一类把低维空间的非线性可分问题，转化为高维空间的线性可分问题的方法。</p><blockquote><p><font color="#A9A9A9">理论基础:</font>核方法的理论基础是Cover’s theorem，指的是<font color="#FF8C00">对于非线性可分的训练集，可以大概率通过将其非线性映射到一个高维空间来转化成线性可分的训练集。</font></p></blockquote><p><font color="#9400D3">核函数</font>是映射关系 的内积，映射函数本身仅仅是一种映射关系，并没有增加维度的特性，不过可以利用核函数的特性，构造可以增加维度的核函数。</p><p>设 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="script">X</mi></math>是输入空间（即 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>i</mi></msub><mo>&#x2208;</mo><mi mathvariant="script">X</mi></math> ， <math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="script">X</mi></math>  是 <math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi mathvariant="normal">&#x211D;</mi><mi>n</mi></msup></math> 的子集或离散集合 ），又设<math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="script">H</mi></math>  为特征空间（<math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="script">H</mi></math> 是希尔伯特空间），如果存在一个从 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="script">X</mi></math> 到 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="script">H</mi></math> 的映射</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3D5;</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>:</mo><mi mathvariant="script">X</mi><mo>&#x2192;</mo><mi mathvariant="script">H</mi></math></p><p>使得对所有 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi><mo>,</mo><mi>z</mi><mo>&#x2208;</mo><mi mathvariant="script">X</mi></math>,函数<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mo>(</mo><mi>x</mi><mo>,</mo><mi>z</mi><mo>)</mo></math>满足条件</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mo>(</mo><mi>x</mi><mo>,</mo><mi>z</mi><mo>)</mo><mo>=</mo><mo>&#x27E8;</mo><mi>&#x3D5;</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>,</mo><mi>&#x3D5;</mi><mo>(</mo><mi>z</mi><mo>)</mo><mo>&#x27E9;</mo></math></p><p>则称 $K$ 为核函数。其中 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3D5;</mi><mo>(</mo><mi>x</mi><mo>)</mo></math> 为映射函数， <math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&#x27E8;</mo><mo>&#xB7;</mo><mo>,</mo><mo>&#xB7;</mo><mo>&#x27E9;</mo></math>为内积。</p><p>即核函数输入两个向量，它返回的值<font color="#FF1493">等于</font>这两个向量分别作 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3D5;</mi></math> 映射然后点积【内积】的结果。</p><p><font color="#008B8B">核技巧</font>是一种利用核函数直接计算 <math xmlns="http://www.w3.org/1998/Math/MathML"><mo>&#x27E8;</mo><mi>&#x3D5;</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>,</mo><mi>&#x3D5;</mi><mo>(</mo><mi>z</mi><mo>)</mo><mo>&#x27E9;</mo></math> ，以避开分别计算<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3D5;</mi><mo>(</mo><mi>x</mi><mo>)</mo></math>  和<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3D5;</mi><mo>(</mo><mi>z</mi><mo>)</mo></math>  ，从而加速核方法计算的技巧。</p><blockquote><p><font color="#FF1493">注意</font><br>得益于<font color="#FF8C00">SVM对偶问题</font>的表现形式，核技巧可以应用于SVM。<br><font color="#7FFF00">TODO  </font>没有了解<br>核函数的选择是SVM的<font color="#B8860B">最大变数</font>，如果核函数选择不适，那么  将不能将输入空间映射到线性可分的特征空间。</p></blockquote><h2 id="判断核函数"><a href="#判断核函数" class="headerlink" title="判断核函数"></a>判断核函数</h2><p><font color="#bf242a">不知道 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3D5;</mi></math> 的情况下，如何判断某个 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math> 是不是核函数？</font></p><p><strong>答案:</strong> 是 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math> 是核函数当且仅当对任意数据 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>D</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>&#x2026;</mo><mo>,</mo><msub><mi>x</mi><mi>m</mi></msub></math> ，核矩阵(kernal matrix,gram matrix)总是半正定的</p><blockquote><p><font color="#368AF8">知识补充：</font><strong>实对称矩阵</strong><br>如果有n阶矩阵A，其矩阵的元素都为实数，且矩阵A的转置等于其本身（aij=aji），(i,j为元素的脚标），则称A为实对称矩阵。</p></blockquote><blockquote><p><font color="#6495ED"><a href="https://zhuanlan.zhihu.com/p/44860862">知识补充</a>：</font><font color="#8B0000">「正定矩阵」(positive definite)</font>和<font color="#8B0000">「半正定矩阵」(positive semi-definite)</font><br><strong>正定矩阵：</strong> 给定一个大小为 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>&#xD7;</mo><mi>n</mi></math> 的实对称矩阵<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi></math>  ，若对于任意长度为 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math> 的<font color="#A66766">非零向量</font> <math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="bold-italic">x</mi></math>，有 <math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi mathvariant="bold-italic">x</mi><mi>T</mi></msup><mi>A</mi><mi mathvariant="bold-italic">x</mi><mo>&gt;</mo><mn>0</mn></math> 恒成立，则矩阵 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi></math>  是一个正定矩阵。<br><strong>半正定矩阵：</strong> 给定一个大小为 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>&#xD7;</mo><mi>n</mi></math> 的实对称矩阵<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi></math>  ，若对于任意长度为 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math> 的<font color="#A66766">向量</font> <math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="bold-italic">x</mi></math>，有 <math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi mathvariant="bold-italic">x</mi><mi>T</mi></msup><mi>A</mi><mi mathvariant="bold-italic">x</mi><mo>&gt;</mo><mn>0</mn></math> 恒成立，则矩阵 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi></math>  是一个正定矩阵。<br><font color="#FF00FF">半正定矩阵包括了正定矩阵，核矩阵与协方差矩阵都要半正定</font></p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021530/1622369097125.png" alt="核矩阵"></p><h2 id="常用核函数"><a href="#常用核函数" class="headerlink" title="常用核函数"></a>常用核函数</h2><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021530/1622366953315.png" alt="常用核函数"></p><h2 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h2><p>举一个<a href="https://zhuanlan.zhihu.com/p/95362628">栗子</a><br>下面这张图位于第一、二象限内。我们关注红色的门，以及“北京四合院”这几个字下面的紫色的字母。我们把红色的门上的点看成是“+”数据，紫色字母上的点看成是“-”数据，它们的横、纵坐标是两个特征。显然，在这个二维空间内，“+”“-”两类数据不是线性可分的。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021530/1622369536767.png" alt="二维"></p><p>我们现在考虑核函数<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mfenced><mrow><msub><mi>v</mi><mn>1</mn></msub><mo>,</mo><msub><mi>v</mi><mn>2</mn></msub></mrow></mfenced><mo>=</mo><mo>&lt;</mo><msub><mi>v</mi><mn>1</mn></msub><mo>,</mo><msub><mi>v</mi><mn>2</mn></msub><msup><mo>&gt;</mo><mn>2</mn></msup></math>，即“内积平方”。<br>这里面<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>v</mi><mn>1</mn></msub><mo>=</mo><mfenced><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>1</mn></msub></mrow></mfenced><mo>,</mo><msub><mi>v</mi><mn>2</mn></msub><mo>=</mo><mfenced><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub></mrow></mfenced></math>是二维空间中的两个点。</p><p>这个核函数对应着一个二维空间到三维空间的映射，它的表达式是：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo><mo>=</mo><mfenced><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>,</mo><msqrt><mn>2</mn></msqrt><mi>x</mi><mi>y</mi><mo>,</mo><msup><mi>y</mi><mn>2</mn></msup></mrow></mfenced></math><br>可以验证，<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021530/1622369667776.png" alt="核函数"></p><p>在P这个映射下，原来二维空间中的图在三维空间中的像是这个样子：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021530/1622369693244.png" alt="三维"></p><p><font color="#D2691E">注意</font>到绿色的平面可以完美地分割红色和紫色，也就是说，两类数据在三维空间中变成线性可分的了。</p><p>而三维中的这个判决边界，再映射回二维空间中是这样的：</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021530/1622369730773.png" alt="再二维"></p><p>这是一条双曲线，它不是线性的。</p><p><font color="#A52A2A">通过高维映射使得特征线性可分，换种思路就是当两个特征值无法将数据分开时，就将两个特征值进行点交，形成第三个特征，这个时候就有三个特征值，然后构成三位空间，进行分类</font></p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> data mining </tag>
            
            <tag> kernal method </tag>
            
            <tag> kernal trick </tag>
            
            <tag> kernal function </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>协方差矩阵</title>
      <link href="/2021/05/26/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/"/>
      <url>/2021/05/26/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="方差和协方差的定义"><a href="#方差和协方差的定义" class="headerlink" title="方差和协方差的定义"></a>方差和协方差的定义</h2><p><font color="#184471"><strong>方差</strong>：</font>用来度量单个随机变量的离散程度</p><p>$$\sigma_{x}^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}$$</p><p><font color="#D3B2F7">为什么样本方差的分母是n-1？</font></p><pre><code>最简单的原因，是因为因为均值已经用了n个数的平均来做估计在求方差时，只有(n-1)个数和均值信息是不相关的。而你的第ｎ个数已经可以由前(n-1)个数和均值　来唯一确定，实际上没有信息量。所以在计算方差时，只除以(n-1)。</code></pre><p><font color="#0C5F6C"><strong>协方差</strong>：</font>一般用来刻画两个随机变量的相似程度</p><p>$$\sigma(x, y)=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)$$</p><p>在公式中，符号 $\bar{x}, \bar{y}$ 分别表示两个随机变量所对应的观测样本均值，据此，我们发现：方差 $\sigma_{x}^{2}$ 可视作随机变量 x 关于其自身的协方差 $\sigma(x, x)$ .</p><h2 id="从方差-协方差到协方差矩阵"><a href="#从方差-协方差到协方差矩阵" class="headerlink" title="从方差/协方差到协方差矩阵"></a>从方差/协方差到协方差矩阵</h2><p>根据方差的定义，给定 $d$ 个随机变量 $x_{k},k=1,2,\ldots,d$ ，则这些随机变量的方差为<br>$$\sigma\left(x_{k},x_{k}\right)=\frac{1}{n-1}\sum_{i=1}^{n}\left(x_{k i}-\bar{x}_{k}\right)^{2},k=1,2,\ldots,d$$</p><p> $x_{k i}$ 表示随机变量 $x_{k}$ 中的第 $i$ 个观测样本，$n$  表示样本量，每个随机变量所对应的观测样本数量均为 $n$ 。<br> 对于这些随机变量，我们还可以根据协方差的定义，求出<strong>两两之间的协方差</strong>，即<br> <img src="https://gitee.com/merlynr/img-store/raw/master/2021527/1622097407978.png"></p><p> 因此，协方差矩阵为 $$\Sigma=\left[\begin{array}{ccc}\sigma\left(x_{1}, x_{1}\right)&amp;\cdots&amp;\sigma\left(x_{1},x_{d}\right)\\vdots&amp;\ddots&amp;\vdots\\sigma\left(x_{d},x_{1}\right)&amp;\cdots&amp;\sigma\left(x_{d},x_{d}\right)\end{array}\right]\in\mathbb{R}^{d\times d}$$<br>其中，对角线上的元素为各个随机变量的方差，非对角线上的元素为两两随机变量之间的协方差，根据协方差的定义，我们可以认定：矩阵 $\Sigma$ 为<font color="#AB8E35">对称矩阵</font>(symmetric matrix)，其大小为 $d$ x $d$ 。</p><h2 id="多元正态分布与线性变换"><a href="#多元正态分布与线性变换" class="headerlink" title="多元正态分布与线性变换"></a>多元正态分布与线性变换</h2><blockquote><p><font color="#EFED2E">多元正态分布</font>—n维的多元正态分布，也称为多元高斯分布</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021526/1622033779880.png" alt="多元正态分布图"></p><p>假设一个向量 $x$ 服从均值向量为 $\boldsymbol{\mu}$ 、协方差矩阵为 $\Sigma$ 的多元正态分布(multi-variate Gaussian distribution)【第二章】，则 $$p(\boldsymbol{x})=|2 \pi \Sigma|^{-1 / 2} \exp \left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{T} \Sigma^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\right)$$</p><blockquote><p><font color="#DE8937">联立理解：</font>多元正态分布<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021526/1622035698486.png" alt="多元正态分布"></p></blockquote><p>令该分布的均值向量为 $\boldsymbol{\mu}=\mathbf{0}$ ，由于指数项外面的系数 $|2 \pi \Sigma|^{-1 / 2}$ 通常作为常数，故可将多元正态分布简化为 $$p(\boldsymbol{x}) \propto \exp \left(-\frac{1}{2} \boldsymbol{x}^{T} \Sigma^{-1} \boldsymbol{x}\right)$$<br>再令 $\boldsymbol{x}=(y, z)^{T}$ ，包含两个随机变量 $y$ 和 $z$ ，则协方差矩阵可写成如下形式： $$ \Sigma=\left[\begin{array}{ll}\sigma(y, y) &amp; \sigma(y, z) \ \sigma(z, y) &amp; \sigma(z, z)\end{array}\right] \in \mathbb{R}^{2 \times 2} $$<br>用<font color="#006EFF">单位矩阵</font>(identity matrix) $I$ 作为<font color="#183D66">协方差矩阵</font>，随机变量 $y$ 和 $z$ 的方差均为1，则生成如干个随机数如图所示。 </p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021526/1622038800402.png" alt="图1二元正态分布"></p><blockquote><p><font color="#DE8937">知识补充：</font>单位矩阵<br> 单位矩阵是个方阵，从左上角到右下角的对角线（称为主对角线）上的元素均为1。除此以外全都为0。<strong>任何矩阵与单位矩阵相乘都等于本身</strong><br><img src="https://gitee.com/merlynr/img-store/raw/master/2021526/1622039427482.png" alt="单位矩阵"></p></blockquote><p>在生成的若干个随机数中，每个点的似然为 $$ \mathcal{L}(\boldsymbol{x}) \propto \exp \left(-\frac{1}{2} \boldsymbol{x}^{T} \boldsymbol{x}\right) $$</p><blockquote><p><font color="">知识补充：</font>线性变换<br><a href="https://www.bilibili.com/video/av6043439">视频教学</a><br>线性性质一：直线在变换后仍然保持为直线，不能弯曲；线性性质二：原点是固定不变的</p></blockquote><p>对图[二元正态分布]中的所有点考虑一个线性变换(linear transformation)：$\boldsymbol{t}=A \boldsymbol{x}$  ，我们能够得到图</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021526/1622039676816.png" alt="图2 经过线性变换的二元正态分布，先将图1的纵坐标压缩0.5倍，再将所有点逆时针旋转30°得到"></p><p>在线性变换中，矩阵 $A$ 被称为<strong>变换矩阵</strong>(transformation matrix)，为了将图1中的点经过线性变换得到我们想要的图2，其实我们需要构造两个矩阵：</p><ul><li><strong>尺度矩阵</strong>(scaling matrix)： $$S=\left[\begin{array}{cc}s_{y}&amp;0\0&amp;s_{z}\end{array}\right]$$</li><li><strong>旋转矩阵</strong>(rotation matrix)： $$R=\left[\begin{array}{cc}\cos(\theta)&amp;-\sin(\theta)\\sin(\theta)&amp;\cos(\theta)\end{array}\right]$$<br>其中， $\theta$ 为顺时针旋转的度数。</li></ul><blockquote><p><font color="#8591A6">补充知识：</font>变换矩阵、尺度矩阵和旋转矩阵三者的关系式<br>$A=R S$</p></blockquote><p>在这个例子中，尺度矩阵为 $S=\left[\begin{array}{l l}1&amp;0\0&amp;\frac{1}{2}\end{array}\right]$ ，旋转矩阵为 $R=\left[\begin{array}{c c}\cos\left(-\frac{\pi}{6}\right)&amp;-\sin\left(-\frac{\pi}{6}\right)\\sin\left(-\frac{\pi}{6}\right)&amp;\cos\left(-\frac{\pi}{6}\right)\end{array}\right]=\left[\begin{array}{c c}\frac{\sqrt{3}}{2}&amp;\frac{1}{2}\-\frac{1}{2}&amp;\frac{\sqrt{3}}{2}\end{array}\right]$ ，故变换矩阵为 $A=R S=\left[\begin{array}{cc}\frac{\sqrt{3}}{2}&amp;\frac{1}{4}\-\frac{1}{2}&amp;\frac{\sqrt{3}}{4}\end{array}\right]$</p><p>另外，需要考虑的是，经过了线性变换，$t$  的分布是什么样子呢？</p><p>将 $\boldsymbol{x}=A^{-1} \boldsymbol{t}$ 带入前面给出的似然 $\mathcal{L}(\boldsymbol{x})$ ，有 $\mathcal{L}(\boldsymbol{t}) \propto \exp \left(-\frac{1}{2}\left(A^{-1} \boldsymbol{t}\right)^{T}\left(A^{-1} \boldsymbol{t}\right)\right)$<br>$=\exp \left(-\frac{1}{2} \boldsymbol{t}^{T}\left(A A^{T}\right)^{-1} \boldsymbol{t}\right)$</p><p>由此可以得到，多元正态分布的协方差矩阵为 $$\Sigma=A A^{T}=\left[\begin{array}{cc}\frac{\sqrt{3}}{2} &amp; \frac{1}{4} \ -\frac{1}{2} &amp; \frac{\sqrt{3}}{4}\end{array}\right]\left[\begin{array}{cc}\frac{\sqrt{3}}{2} &amp; -\frac{1}{2} \ \frac{1}{4} &amp; \frac{\sqrt{3}}{4}\end{array}\right]=\left[\begin{array}{cc}\frac{13}{16} &amp; -\frac{3 \sqrt{3}}{16} \ -\frac{3 \sqrt{3}}{16} &amp; \frac{7}{16}\end{array}\right]$$</p><h2 id="协方差矩阵的特征值分解"><a href="#协方差矩阵的特征值分解" class="headerlink" title="协方差矩阵的特征值分解"></a>协方差矩阵的特征值分解</h2><blockquote><p>回到我们已经学过的线性代数内容，对于任意对称矩阵 $\Sigma$ ，存在一个特征值分解(eigenvalue decomposition, EVD)： $$\Sigma=U \Lambda U^{T}$$ 其中, $U$ 的每一列都是相互正交的特征向量，且是单位向量，满足 $U^{T}U=I$ ， $\Lambda$ 对角线上的元素是从大到小排列的特征值，非对角线上的元素均为0。</p></blockquote><p>当然，这条公式在这里也可以很容易地写成如下形式： $$\Sigma=\left(U \Lambda^{1 / 2}\right)\left(U \Lambda^{1 / 2}\right)^{T}=A A^{T}$$<br>其中，$A=U \Lambda^{1 / 2}$  ，因此，通俗地说，<font color="#226771">任意一个协方差矩阵都可以视为线性变换的结果。</font><br>在上面的例子中，<strong>特征向量构成的矩阵</strong>为 $$U=R=\left[\begin{array}{cc}\cos (\theta) &amp; -\sin (\theta) \ \sin (\theta) &amp; \cos (\theta)\end{array}\right]=\left[\begin{array}{cc}\frac{\sqrt{3}}{2} &amp; \frac{1}{2} \ -\frac{1}{2} &amp; \frac{\sqrt{3}}{2}\end{array}\right]$$<br><strong>特征值构成的矩阵</strong>为<br>$$\Lambda=S S^{T}=\left[\begin{array}{cc}s_{y}^{2} &amp; 0 \ 0 &amp; s_{z}^{2}\end{array}\right]=\left[\begin{array}{ll}1 &amp; 0 \ 0 &amp; \frac{1}{4}\end{array}\right]$$<br>到这里，我们发现：多元正态分布的概率密度是由<font color="#BD5A5D">协方差矩阵的特征向量控制旋转(rotation)</font>，<font color="">特征值控制尺度(scale)</font>，除了协方差矩阵，<font color="#810006">均值向量会控制概率密度的位置</font>，在图1和图2中，均值向量为 $0$ ，因此，概率密度的中心位于坐标原点。</p>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>挖掘业务流程，结合机器学习进行业务预测分析</title>
      <link href="/2021/05/25/%E6%8C%96%E6%8E%98%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%EF%BC%8C%E7%BB%93%E5%90%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E4%B8%9A%E5%8A%A1%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/25/%E6%8C%96%E6%8E%98%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%EF%BC%8C%E7%BB%93%E5%90%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E4%B8%9A%E5%8A%A1%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="基于机器学习的流程异常预测行为"><a href="#基于机器学习的流程异常预测行为" class="headerlink" title="基于机器学习的流程异常预测行为"></a>基于机器学习的流程异常预测行为</h2><p><img src="./attachments/%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%81%E7%A8%8B%E5%BC%82%E5%B8%B8%E9%A2%84%E6%B5%8B%E6%96%B9%E6%B3%95_%E9%AD%8F%E6%87%BF.pdf" alt="基于机器学习的流程异常预测方法_魏懿"></p><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><blockquote><p>通过挖掘流程执行的<font color="#D2691E">日志记录</font> 和<font color="#6495ED">活动执行时间信息 </font>，基于机器学习方法的异常检测方法，实现实时预测业务流程中的超 期 异 常 和 流 程 行 为 异 常。</p></blockquote><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><blockquote><p>异常(预期的，完全意外的)</p></blockquote><ol><li>流程超期、资源不可用、活动执行失败等和完全意外的异常</li></ol><blockquote><p>现有的流程异常检测方法</p></blockquote><ul><li>主动 的 设 置 时 间 检 查点、动态检查，或 被动地基于异常发生后捕捉异常、处理异常的机制<ol><li>主动设置时间检查点的方法有两个弊端，第一个设置点的位置无法精确判断，第二个是系统状态是动态的，受生产环境等诸多条件影响，所以主动i设置会造成很多新的问题</li><li>被动处理超期异常的方法，失去了对业务流程管理的主动性，从而将导致工作流期望的目标延迟或付出更大的开销。【即失去对于流程预测的主动性】</li></ol></li></ul><h3 id="目前国内外研究动态"><a href="#目前国内外研究动态" class="headerlink" title="目前国内外研究动态"></a>目前国内外研究动态</h3><h4 id="基于时间边界的时间异常检测"><a href="#基于时间边界的时间异常检测" class="headerlink" title="基于时间边界的时间异常检测"></a>基于时间边界的时间异常检测</h4><ol><li>基于时间边界的时间异常检测–Eder</li></ol><p><font size=1>the fifth and sixth document of this paper </font></p><pre><code>首先要明确每个任务节点执行时间的上下边界， 基于这两个时限， 计算起始节点到当前节点的最佳（ 最短） 执行时间和最坏（ 最长） 执行时间。当流程执行时， 如果当前时间在区间内， 则判断为没有时间异常</code></pre><ol start="2"><li>基于关键路径</li></ol><p><font size=1>the seventh document of this paper </font></p><pre><code>在工作流执行前，会根据模型先找出关键路径， 并在流程执行时检查最佳完成时间与最终时限， 如果最佳完成时间大于最终时限， 则预测为异常</code></pre><h4 id="时间统计模型建立"><a href="#时间统计模型建立" class="headerlink" title="时间统计模型建立"></a>时间统计模型建立</h4><ol><li>执行时间建模方法</li></ol><p><font size=1>the eighth document of this paper </font></p><pre><code>该方法利用历史日志生成涵盖所有活动持续时间直方图来表示当前节点和末端节点之间的剩余执行时间的概率，用于捕获有关工作流执行的时间信息，定义计算工作流执行时间的必要操作</code></pre><ol start="2"><li>综合时间模型和流程步骤分析</li></ol><p><font size=1>the ninth document of this paper </font></p><pre><code>综合运用时间统计模型和通过多个步骤分析方法生成运行时间概率分布、计算异常概率、与阈值比较的方法，提出一种基于运行的异常预测算法来预测工作流中的时间异常，该算法分为即设计时段和运行时段两个阶段，在设计时段，生成该模型所有可能产生的运行轨迹，并计算它们的预计执行时间的概率分布；在运行时段，通过分析计算流程超时的可能性与预设的阈值做比较来判断是否预测为异常    </code></pre><ol start="3"><li>结合积极语义模型</li></ol><p><font size=1>the tenth document of this paper </font></p><pre><code>采用积极语义模型来捕捉各种工作流情形下的 语 义 特 征，并 且 检 测 和 处 理 异 常    </code></pre><ol start="4"><li>提出受启发与传染病模型的时间延迟传播模型</li></ol><p><font size=1>the eleventh document of this paper </font></p><pre><code>着眼于并行云工作流中的时间延迟，提出受启发与传染病模型的时间延迟传播模型，预测使云工作流中达到一定完成率的最大时间异常数目</code></pre><h3 id="离群点检测的算法"><a href="#离群点检测的算法" class="headerlink" title="离群点检测的算法"></a>离群点检测的算法</h3><p><a href="https://blog.zuishuailcq.xyz/2021/05/25/%E7%A6%BB%E7%BE%A4%E7%82%B9%E6%A3%80%E6%B5%8B/">离群点检测 | 吾辈之人，自当自强不息！</a></p><p><a href="https://blog.zuishuailcq.xyz/2021/05/31/%E5%AD%A4%E7%AB%8B%E6%A3%AE%E6%9E%97%EF%BC%88Isolation%20Forest%EF%BC%89/">孤立森林（Isolation Forest） | 吾辈之人，自当自强不息！</a></p><h2 id="本文"><a href="#本文" class="headerlink" title="本文"></a>本文</h2><h3 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h3><blockquote><p>提出一种基于活动执行时间和比例关系的方法，通过学习历史流程执行日志中活动时间信息，根据正在执行的待预测流程的日志及状态，预测其是否为异常流程以及异常的类型。并且，本文提出通过计算活动执行时间之间的比例关系作为流程特征加入机器学习算法，运用机器学习中监督学习的分类器以预测流程是否会发生超期异常（流程执行总时间超过预设最终期限），同时使用非监督学习的离群点检测算法根据历史数据中活动执行时间比例关系判定流程行为异常。结合两种算法的结果对流程异常预测做出进一步的分类和分析。</p></blockquote><h3 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h3><ol><li>预处理历史和正在执行的流程数据，获得流程中活动执行时间序列以及计算活动执行时间<font color="#8B0000">比例关系</font></li><li>使用监督学习的分类器，预测并标记超期【流程执行<br>总时间超过预设最终期限】异常流程为<math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">I</mi></math>类异常流程</li><li> 用无监督学习检测离群点算法【 <font color="#9400D3">活动执行时间之间比例关系(单个活动占总体)</font>为特征值】，找出历史数据中的异常流程并标记为<math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">I</mi></math><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">I</mi></math>类异常流程</li><li> 通过集成业务流程异常预测方法将待预测流程分为正常流程或者不同种类的异常流程</li></ol><h3 id="结构概述"><a href="#结构概述" class="headerlink" title="结构概述"></a>结构概述</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622429405396.png" alt="集成业务流程异常预测方法结构图"></p><blockquote><p><font color="#8FBC8F">知识补充：</font>弱监督<br>不完全监督（Incomplete supervision）：训练数据中只有一部分数据被给了标签，有一些数据是没有标签的。<br>不确切监督（Inexact supervision）：训练数据只给出了粗粒度标签。可理解为只给了大类的标签，详细属性没有给标签<br>不精确监督（Inaccurate supervision）：给出的标签不总是正确的</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622441386940.png" alt="预测结果异常分类韦恩图"></p><ol><li>第一类通过弱监督学习方法可以标记出大部分的异常流程，但是系统的运行情况很容易受环境资源影响，很多时候由于等待时间过长，被误标为异常流程，但是依旧属于正常流程</li><li>在实际业务流程中， 活动的执行时间之间并非独立分布， 而是具有隐含的相关关系， 由于多种因素的影响， 造成了活动时间相应的变化。比如工作负荷加倍使得某些活动花费了较长时间， 导致流程总时间较长， 有超期异常的风险。但是从活动执行时间比例关系来看， 流程时间可能被近乎等比例放大， 完全是合情合理的， 并不应该被记为最终期限异常的流程。在活动时间比例上， 正常执行的流程活动时间比例关系是相似的， 而行为异常的流程活动时间比例关系容易出现离群点。因此计算流程中活动时间的比例关系， 并将其作为特征加入算法是有必要的。</li></ol><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h4><blockquote><p><font color="#1E90FF">数据集</font><br>将历史业务流程日志及正在执行流程中的活动执行时间信息作为初始的数据集</p></blockquote><p><font color="#7FFF00">TODO</font><br> 通过目前较为成熟的流程挖掘算法和软件， 如ProM Tools、Disco， 流程模型模拟业务流程获取数据可以简化结构、 缩减活动数量。</p><p><font color="#ff7500">数据初始化：</font><br>待预测流程的活动数量：n<br>多条与待预测执行流程路径一致的历史流程数量：q<br>待预测流程执行时间集：T<br>其中一条流程的活动执行时间序列：<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mi>k</mi></msub><mo>(</mo><mi>k</mi><mo>&#x2208;</mo><mo>[</mo><mn>1</mn><mo>,</mo><mi>q</mi><mo>]</mo><mo>)</mo></math><br>序列中单个活动的执行时间：<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>i</mi></msub><mo>(</mo><mi>i</mi><mo>&#x2208;</mo><mo>[</mo><mn>1</mn><mo>,</mo><mi>n</mi><mo>]</mo><mo>)</mo></math></p><p>待预测流程执行时间集：<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mo>=</mo><mfenced close="]" open="["><mrow><msub><mi>T</mi><mn>1</mn></msub><mo>,</mo><msub><mi>T</mi><mn>2</mn></msub><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msub><mi>T</mi><mi>k</mi></msub><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msub><mi>T</mi><mi>q</mi></msub></mrow></mfenced><mo>,</mo><mi>k</mi><mo>&#x2208;</mo><mo>[</mo><mn>1</mn><mo>,</mo><mi>q</mi><mo>]</mo></math><br>序列k的流程时间：<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mi>k</mi></msub><mo>=</mo><mfenced close="]" open="["><mrow><msub><mi>t</mi><mn>1</mn></msub><mo>,</mo><msub><mi>t</mi><mn>2</mn></msub><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msub><mi>t</mi><mi>i</mi></msub><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msub><mi>t</mi><mi>n</mi></msub></mrow></mfenced><mo>,</mo><mi>i</mi><mo>&#x2208;</mo><mo>[</mo><mn>1</mn><mo>,</mo><mi>n</mi><mo>]</mo></math></p><h4 id="获得时间比例"><a href="#获得时间比例" class="headerlink" title="获得时间比例"></a>获得时间比例</h4><p><font color="#1E90FF">对长度为 $n$ 的活动执行时间序列<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mi>k</mi></msub></math>，求出长度为 $n-1$ 的时间比例序<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>R</mi><mi>k</mi></msub></math>，记比例数据集为 $R$ </font></p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>R</mi><mo>=</mo><mfenced close="]" open="["><mrow><msub><mi>R</mi><mn>1</mn></msub><mo>,</mo><msub><mi>R</mi><mn>2</mn></msub><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msub><mi>R</mi><mi>k</mi></msub><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><msub><mi>R</mi><mi>q</mi></msub></mrow></mfenced><mo>,</mo><mi>k</mi><mo>&#x2208;</mo><mo>[</mo><mn>1</mn><mo>,</mo><mi>q</mi><mo>]</mo></math><br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>R</mi><mi>k</mi></msub><mo>=</mo><mfenced close="]" open="["><mrow><mfrac><msub><mi>t</mi><mn>1</mn></msub><msub><mi>t</mi><mn>2</mn></msub></mfrac><mo>,</mo><mfrac><msub><mi>t</mi><mn>2</mn></msub><msub><mi>t</mi><mn>3</mn></msub></mfrac><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><mfrac><msub><mi>t</mi><mi>i</mi></msub><msub><mi>t</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></mfrac><mo>,</mo><mo>&#x22EF;</mo><mo>,</mo><mfrac><msub><mi>t</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><msub><mi>t</mi><mi>n</mi></msub></mfrac></mrow></mfenced><mo>,</mo><mi>i</mi><mo>&#x2208;</mo><mo>[</mo><mn>1</mn><mo>,</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo>]</mo></math></p><h4 id="对异常流程进行标记"><a href="#对异常流程进行标记" class="headerlink" title="对异常流程进行标记"></a>对异常流程进行标记</h4><ul><li>通过历史流程计算出流程执行时间分布，可以给不同活动设定阈值，来标记超期异常流程</li><li>可以用执行时间拟合建立高斯分布，利用模型参数设立阈值以标记异常（如临界点 $threshold$ <math xmlns="http://www.w3.org/1998/Math/MathML"><mo>=</mo><mi>&#x3BC;</mi><mo>+</mo><mn>2</mn><mo>&#xB7;</mo><mi>&#x3C3;</mi></math>），标记出的异常数据集为<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mi>c</mi><mi>v</mi></math>【time constrain violation 违规时间约束】</li></ul><h4 id="集成业务流程异常预测方法（EnsBPAP）"><a href="#集成业务流程异常预测方法（EnsBPAP）" class="headerlink" title="集成业务流程异常预测方法（EnsBPAP）"></a>集成业务流程异常预测方法（EnsBPAP）</h4><blockquote><p><font color="#9932CC">前提</font><br>将待预测流程的活动执行时间序列记为ｔ，将其时间比例序列记为ｒ， 同数据预处理中得到的历史流程的执行时间,比例数据集和标记出的异常数据集 $T$ , $R$ , $tcv$</p></blockquote><ol><li>将活动执行时间和比例的训练数据集和测试用例数据传入监督学习的分类算法中， 得到超期异常预测结果</li><li>将活动时间比例的训练集和测试用例传入无监督学习异常检测算法， 得到行为异常预测结果</li><li>用两个预测结果访问EnsBPAP分类结果矩阵， 并返回最终的分类结果</li></ol><p><font color="#0000FF">EnsBPAP(t,r,T,R,balance_data)伪代码</font></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622448127881.png" alt="输入输出"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021531/1622448326369.png" alt="步骤函数"></p><ol><li>标记超期异常流程</li><li>标记行为异常【时间比例异常】</li><li>制定EnsBPAP模型【位运算】</li><li>将异常流程通过EnsBPAP模型，获得符合模型的综合分类结果</li></ol><blockquote><p>class： 预测测试过程的综合分类结果</p></blockquote><h4 id="超期异常预测"><a href="#超期异常预测" class="headerlink" title="超期异常预测"></a>超期异常预测</h4><p><font color="#7FFF00">分类器基本模型</font></p><ul><li>逻辑回归算法–监督学习</li></ul><p><font color="#DC143C">数据存在问题</font></p><ul><li>异常点在整个数据集中的数量远小于正常点的数量【样本不均衡问题】，会导致分类器倾向于把预测样本分为多数类。</li></ul><p><font color="#00FFFF">处理样本不平衡问题</font>—<a href="https://blog.zuishuailcq.xyz/2021/05/31/%E4%BA%8C%E5%88%86%E7%B1%BB%E4%B9%8B%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1/">二分类之类别不平衡 | 吾辈之人，自当自强不息！</a></p><ul><li>使用过采样和欠采样结合的方法<font color="#0000FF">SMOTE + TOMEK algorithm</font></li></ul><ol><li>第１步， 将执行时间和比例数据Ｔ，Ｒ 合并成训练集Ｘ， 训练目标为tcv，ｔ，ｒ合并成测试样本ｘ； </li><li>第２步， 根据balance_data参数选择是否执行SMOTE＋Tomek算法均衡训练样本【balance_data平衡训练数据以进行时间约束违规预测】</li><li>第3步，对每个特征做归一化消除数据量级的影响【<font color="#FF00FF">归一化的目的就是使得预处理的数据被限定在一定的范围内（比如[0,1]或者[-1,1]），从而消除奇异样本数据导致的不良影响</font>。】</li><li>第4步，初始化算法模型，超参数空间，最佳参数</li><li>第5步，通过若干次迭代随机生成超参数、参考交叉验证法评估当前超参数下的性能、更新最佳超参</li><li>最后一步，使用最佳超参数拟合算法模型，预测测试样本模型类型，并返回</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021611/1623397346285.png" alt="TimeConstraitsViolationPrediction(t,r,T,R,tcv,balance_data)"></p><h4 id="行为异常检测"><a href="#行为异常检测" class="headerlink" title="行为异常检测"></a>行为异常检测</h4><p><font color="#8B0000">目标</font></p><ul><li>通过活动执行时间比例找出离群点， 以鉴别待预测流程是否为行为异常的流程。</li></ul><p><font color="#8B008B">算法模型</font></p><ul><li>孤立森林</li></ul><ol><li>第１步， 初始化算法模型</li><li>第２步， 拟合历史数据得到孤立森林模型</li><li>第３步， 预测测试样本并返回</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021611/1623397471182.png" alt="BehaviorAnimalyDetection(r,R)"></p><blockquote><p><font color="#006400">补充知识</font><br><a href="https://blog.csdn.net/huangfei711/article/details/78456165">如何通俗易懂地理解皮尔逊相关系数？_黄飞的博客专栏-CSDN博客_皮尔逊相关系数怎么看</a></p></blockquote><h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><ol><li>流程的预设期限<font color="#5F9EA0">如何</font> <font color="#696969">在哪</font> 还有 <font color="#BDB76B">设置的标准</font>没有提到</li></ol>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> RPA </tag>
            
            <tag> paper </tag>
            
            <tag> algorithm </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离群点检测</title>
      <link href="/2021/05/25/%E7%A6%BB%E7%BE%A4%E7%82%B9%E6%A3%80%E6%B5%8B/"/>
      <url>/2021/05/25/%E7%A6%BB%E7%BE%A4%E7%82%B9%E6%A3%80%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><p><strong>离群点检测</strong>（<font color=" #009688">异常检测</font>）是找出其行为不同于预期对象的过程，这种对象称为离群点或异常。</p><blockquote><p>离群点和噪声有区别，噪声是观测变量的随机误差和方差，而离群点的产生机制和其他数据的产生机制就有根本的区别,同一批数据产生方式可能不一样。</p></blockquote><p><strong>全局离群点</strong>：通过找到某种合适的偏离度量方式，将离群点检测划为不同的类别；全局离群点是情景离群点的特例，因为考虑整个数据集为一个情境。</p><p><strong>情境离群点</strong>：又称为条件离群点，即在特定条件下它可能是离群点，但是在其他条件下可能又是合理的点。比如夏天的28℃和冬天的28℃等。</p><p><strong>集体离群点</strong>：个体数据可能不是离群点，但是这些对象作为整体显著偏移整个数据集就成为了集体离群点。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021525/1621947763766.png" alt="黑色对象形成集体离群点"></p><h3 id="补充学习"><a href="#补充学习" class="headerlink" title="补充学习"></a>补充学习</h3><blockquote><p>有些模型的表现一直不错，建议优先考虑。对于大数据量和高纬度的数据集，Isolation Forest算法的表现比较好。小数据集上，简单算法KNN和MCD的表现不错。</p></blockquote><p> <font color="#F6C75A">聚类：</font>将物理或抽象对象的集合分成由类似的对象组成的多个类的过程被称为聚类。</p><p><font color="#D87E8D">簇：</font>把数据划分为不同类别，机器学习给这个类别定义一个新的名字—簇。</p><h2 id="离群点检测目前遇到的挑战"><a href="#离群点检测目前遇到的挑战" class="headerlink" title="离群点检测目前遇到的挑战"></a>离群点检测目前遇到的挑战</h2><ul><li>正常数据和离群点的有效建模本身就是个挑战,数据没有标签，无法分清正常数据还是异常数据；或者缺乏异常数据；</li><li>离群点检测高度依赖于应用类型使得不可能开发出通用的离群点检测方法，比如针对性的相似性、距离度量机制等；</li><li>数据质量实际上往往很差，噪声充斥在数据中，影响离群点和正常点之间的差别，缺失的数据也可能“掩盖”住离群点，影响检测到有效性；</li><li>检测离群点的方法需要可解释性；</li></ul><h2 id="离群点检测方法"><a href="#离群点检测方法" class="headerlink" title="离群点检测方法"></a>离群点检测方法</h2><h3 id="监督方法"><a href="#监督方法" class="headerlink" title="监督方法"></a>监督方法</h3><p> <strong>➀训练可识别离群点的分类器</strong></p><p><font color="#009688">困难：</font> 1 .两个类别（正常和离群）的数据量很不平衡，缺乏足够的离群点样本可能会限制所构建分类器的能力；<br>2. 许多应用中，捕获尽可能多的离群点（灵敏度和召回率）比把正常对象误当做离群点更重要。</p><blockquote><p>由于与其他样本相比离群点很稀少，所以离群点检测的监督方法必须注意如何训练和如何解释分类率。</p></blockquote><p><strong>➁One-class model，一分类模型</strong></p><pre><code>考虑到数据集严重不平衡的问题，构建一个仅描述正常类的分类器，不属于正常类的任何样本都被视为离群点。比如SVM决策边界以外的都可以视为离群点。</code></pre><h3 id="无监督方法"><a href="#无监督方法" class="headerlink" title="无监督方法"></a>无监督方法</h3><blockquote><p>正常对象在某种程度上是“聚类”的，正常对象之间具有高度的相似性，但是离群点将远离正常对象的组群。<font color="#72A1C3">但是遇到前文所述的集体离群点时，正常数据是发散的，而离群点反而是聚类的</font>,这种情形下更适合<font color="#A98A2F">监督方法</font>进行检测。无监督方法很容易误标记离群点导致许多真实的离群点逃脱检测。</p></blockquote><p><strong>对于传统的聚类方法，有以下几个问题：</strong></p><ul><li>不属于任何簇的对象可能是噪声，而不是离群点；</li><li>先找出簇再找出离群点的开销很大（离群点数量远少于正常对象）；</li></ul><h3 id="半监督方法"><a href="#半监督方法" class="headerlink" title="半监督方法"></a>半监督方法</h3><p>当有一些被标记的正常对象时，可以先使用它们，与邻近的无标记对象一起训练一个正常的对象模型，使用这个模型检测离群点；但是由于具有标记的数据只有少部分，意味着仅仅基于少量被标记的离群点而构建的离群点模型不大可能是有效的。</p><h3 id="统计方法"><a href="#统计方法" class="headerlink" title="统计方法"></a>统计方法</h3><blockquote><p>假定正常的数据对象由一个统计模型产生，不遵守该模型的数据是离群点。即正常对象出现在该随机模型的高概率区域中，而低概率区域中的对象是离群点</p></blockquote><h4 id="参数方法—壹"><a href="#参数方法—壹" class="headerlink" title="参数方法—壹"></a>参数方法—壹</h4><blockquote><p>基于正态分布的一元离群点检测（仅涉及一个属性或变量的数据）</p></blockquote><ol><li>假定数据由某个正态分布产生，由输入来学习正态分布的参数（μ ，σ）（最大似然估计），通过假设检验的方法，一般认定如果某点距离估计的分布均值超过3σ  ，就被认为是离群点。下面的文章中提到过利用盒图和四分位数据来划分离群点，其原理类似。</li><li>另一种离群点检测方法是Grubb检验（最大标准残差检验），对于数据集中的每个对象x，定义z分数(z-score)为：$z=\frac{|x-\bar{x}|}{s}$ , $\bar{x}$是输入数据的均值，s是标准差。<br>若 $z\geq\frac{N-1}{\sqrt{n}}\sqrt{\frac{t_{a/(2N),N-2}^{2}}{N-2+t_{a/(2N),N-2}^{2}}}$ ,x视为离群点。<br>其中 $t^{2}\alpha/(2N),N-2$ 是显著水平 $\alpha /(2N)$ 下的 $t-$ 分布的值，N是数据集中的对象数。</li></ol><h4 id="参数方法—贰"><a href="#参数方法—贰" class="headerlink" title="参数方法—贰"></a>参数方法—贰</h4><blockquote><p>多元离群点检测<br><font size=1>涉及两个或多个属性或变量的数据称为多元数据。核心思想是把多元离群点检测任务转换成一元离群点检测问题。</font></p></blockquote><ol><li><font color="#032953"><strong>马哈拉诺比斯距离检测多元离群点</strong></font></li></ol><p> 对一个多元数据集，设 $\bar{o}$ 为均值向量，对数据集中的对象 $O$ ，从  $O$ 到 $\bar{o}$ 的马哈拉诺比斯距离为： $$M D i s t(o, \bar{o})=(o-\bar{o})^{T} S^{-1}(o-\bar{o})$$ ,S是协方差矩阵。 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mi>D</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo>(</mo><mi>o</mi><mo>,</mo><mover><mi>O</mi><mo>&#xAF;</mo></mover><mo>)</mo></math>是一元变量，于是可以对它进行Grubb检验，如果<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>M</mi><mi>D</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo>(</mo><mi>o</mi><mo>,</mo><mover><mi>O</mi><mo>&#xAF;</mo></mover><mo>)</mo></math>设定为离群点的阈值，则 $o$ 是为离群点。</p><blockquote><p><font color="#DD7ADF">补充知识：</font><a href="https://blog.zuishuailcq.xyz/2021/05/26/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/">协方差矩阵 | 吾辈之人，自当自强不息！</a><br><font color="#2C7D82">协方差矩阵：</font>计算样本不同维度之间的协方差<br><font color="#348A8A">协方差：</font>一般用来刻画两个随机变量的相似程度</p></blockquote><blockquote><p><font color="#F27611">补充知识：</font><strong>欧氏距离</strong>—–又称欧几里得距离<br>m维空间中两个点之间的真实距离<br>例如二维空间的公式：<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3C1;</mi><mo>=</mo><msqrt><msup><mfenced><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>-</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></mfenced><mn>2</mn></msup><mo>+</mo><msup><mfenced><mrow><msub><mi>y</mi><mn>2</mn></msub><mo>-</mo><msub><mi>y</mi><mn>1</mn></msub></mrow></mfenced><mn>2</mn></msup></msqrt></math>，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3C1;</mi></math> 为点 <math xmlns="http://www.w3.org/1998/Math/MathML"><mfenced><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub></mrow></mfenced></math>与点 <math xmlns="http://www.w3.org/1998/Math/MathML"><mfenced><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>1</mn></msub></mrow></mfenced></math>之间的欧氏距离</p></blockquote><blockquote><p><font color="#4D74F2">补充知识：</font><strong>马哈拉诺比斯距离</strong><br>表示数据的协方差距离，它是一种有效的计算两个未知样本集的相似度的方法。<br><strong>思路</strong>：</p><ul><li>将变量按照主成分进行旋转，消除维度间的相关性</li><li>对向量和分布进行标准化，让各个维度同为标准正态分布</li></ul></blockquote><ol start="2"><li><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>&#x3C7;</mi><mn>2</mn></msup></math><strong>统计量</strong>的多元离群点检测</li></ol><p>  正态分布的假定下，<math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>&#x3C7;</mi><mn>2</mn></msup></math>  统计量也可以用来捕获多元离群点，对象 $o$ ，<math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>&#x3C7;</mi><mn>2</mn></msup></math>  统计量是：<br>  <math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>&#x3C7;</mi><mn>2</mn></msup><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><msup><mfenced><mrow><msub><mi>o</mi><mi>i</mi></msub><mo>-</mo><msub><mi>E</mi><mi>i</mi></msub></mrow></mfenced><mn>2</mn></msup><msub><mi>E</mi><mi>i</mi></msub></mfrac></math></p><blockquote><p><font color="#6B6B6B">统计量：</font><br>是样本测量的一种<em>属性</em>。类似计算样本的平均值。</p></blockquote><p><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>O</mi><mi>i</mi></msub></math>是$o$在第 $i$ 维上的值，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>E</mi><mi>i</mi></msub></math>是所有对象在第 $i$ 维上的均值，而n是是维度。如果对象的 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3C7;</mi><mn>2</mn></math>统计量很大，则对象是离群点。</p><ol start="3"><li>混合参数分布检测离群</li></ol><p>  当实际数据很复杂时，假定服从正态分布的话会不太合适，这种情况下假定数据是被混合参数分布产生的。</p><blockquote><p><font color="#1076FF">补充知识：</font><strong>混合分布</strong><br>在概率与统计中，如果我们有一个包含多个随机变量的随机变量集合，再基于该集合生成一个新的随机变量，则该随机变量的分布称为混合分布(mixture distribution)。<br><font color="red">TODO:</font>查阅了<a href="https://blog.csdn.net/tanghonghanhaoli/article/details/90543917">混合分布</a>的三个性质没有理解如何判定离群 </p></blockquote><h4 id="非参数方法—壹"><a href="#非参数方法—壹" class="headerlink" title="非参数方法—壹"></a>非参数方法—壹</h4><p><font color="#DD7ADF">构造直方图</font></p><p>为了构造一个好的直方图，用户必须指定直方图的类型和其他参数（箱数、等宽or等深）。最简单的方法是，如果该对象落入直方图的一个箱中，则该对象被看做正常的，否则被认为是离群点。也可以使用直方图赋予每个对象一个离群点得分，比如对象的离群点得分为该对象落入的箱的容积的倒数。</p><h4 id="非参数方法—贰"><a href="#非参数方法—贰" class="headerlink" title="非参数方法—贰"></a>非参数方法—贰</h4><p><font color="#DD7ADF"><a href="https://blog.csdn.net/pipisorry/article/details/53635895">核密度估计</a></font></p><blockquote><p> <font color="#B22222">补充知识：</font><br> <strong>向量的内积与外积</strong><br> 对于向量a和向量b：<br> <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>a</mi><mo>=</mo><mfenced close="]" open="["><mrow><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>,</mo><mo>&#x2026;</mo><mo>&#xB7;</mo><msub><mi>a</mi><mi>n</mi></msub></mrow></mfenced></math><br> <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi><mo>=</mo><mfenced close="]" open="["><mrow><msub><mi>b</mi><mn>1</mn></msub><mo>,</mo><msub><mi>b</mi><mn>2</mn></msub><mo>,</mo><mo>&#x2026;</mo><mo>,</mo><msub><mi>b</mi><mi>n</mi></msub></mrow></mfenced></math><br> <font color="#00FFFF">内积</font><br> <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>a</mi><mo>&#x2219;</mo><mi>b</mi><mo>=</mo><msub><mi>a</mi><mn>1</mn></msub><msub><mi>b</mi><mn>1</mn></msub><mo>+</mo><msub><mi>a</mi><mn>2</mn></msub><msub><mi>b</mi><mn>2</mn></msub><mo>+</mo><mo>&#x2026;</mo><mo>+</mo><msub><mi>a</mi><mi mathvariant="normal">n</mi></msub><msub><mi>b</mi><mi>n</mi></msub></math>，内积的几何意义是可以用来表征【信息在头脑中的呈现方式】或计算两个向量之间的夹角，以及在b向量在a向量方向上的投影。<br><font color="#FF8C00">外积</font><br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>a</mi><mo>&#xD7;</mo><mi>b</mi><mo>=</mo><mfenced close="|" open="|"><mtable columnalign="left"><mtr><mtd><mi>i</mi></mtd><mtd><mi>j</mi></mtd><mtd><mi>k</mi></mtd></mtr><mtr><mtd><msub><mi>x</mi><mn>1</mn></msub></mtd><mtd><msub><mi>y</mi><mn>1</mn></msub></mtd><mtd><msub><mi>z</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd><msub><mi>x</mi><mn>2</mn></msub></mtd><mtd><msub><mi>y</mi><mn>2</mn></msub></mtd><mtd><msub><mi>z</mi><mn>2</mn></msub></mtd></mtr></mtable></mfenced><mo>=</mo><mfenced><mrow><msub><mi>y</mi><mn>1</mn></msub><msub><mi>z</mi><mn>2</mn></msub><mo>-</mo><msub><mi>y</mi><mn>2</mn></msub><msub><mi>z</mi><mn>1</mn></msub></mrow></mfenced><mi>i</mi><mo>-</mo><mfenced><mrow><msub><mi>x</mi><mn>1</mn></msub><msub><mi>z</mi><mn>2</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub><msub><mi>z</mi><mn>1</mn></msub></mrow></mfenced><mi>j</mi><mo>+</mo><mfenced><mrow><msub><mi>x</mi><mn>1</mn></msub><msub><mi>y</mi><mn>2</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub><msub><mi>y</mi><mn>1</mn></msub></mrow></mfenced><mi>k</mi></math>，外积的结果是一个向量，更为熟知的叫法是法向量，该向量垂直于a和b向量构成的平面。</p></blockquote><p>把每个观测对象看作一个周围区域中的高概率密度指示子，一个点上的概率密度依赖于该点到观测对象的距离，使用核函数对样本点对其邻域的影响建模。核函数K()满足以下两个条件：</p><ol><li><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mo>&#x222B;</mo><mrow><mo>-</mo><mo>&#x221E;</mo></mrow><mo>&#x221E;</mo></msubsup><mi>K</mi><mo>(</mo><mi>u</mi><mo>)</mo><mi>d</mi><mi>u</mi><mo>=</mo><mn>1</mn></math></li><li>对于所有的 $u$ 值，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mo>(</mo><mo>-</mo><mi>u</mi><mo>)</mo><mo>=</mo><mi>K</mi><mo>(</mo><mi>u</mi><mo>)</mo></math></li></ol><p> 一个频繁使用的核函数是标准高斯函数：<br> <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mfenced><mfrac><mrow><mi>x</mi><mo>-</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mi>h</mi></mfrac></mfenced><mo>=</mo><mfrac><mn>1</mn><msqrt><mn>2</mn><mi>&#x3C0;</mi></msqrt></mfrac><msup><mi>e</mi><mrow><mo>-</mo><mfrac><msup><mfenced><mrow><mi>x</mi><mo>-</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mfenced><mn>2</mn></msup><mrow><mn>2</mn><msup><mi>h</mi><mn>2</mn></msup></mrow></mfrac></mrow></msup></math></p><blockquote><p><font color="#3B4B6E">补充知识：</font>高斯函数<br>一维形式<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><msup><mi>e</mi><mrow><mo>-</mo><mfrac><mrow><mo>(</mo><mi>x</mi><mo>-</mo><mi>b</mi><msup><mo>)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msup><mi>c</mi><mn>2</mn></msup></mrow></mfrac></mrow></msup></math><br>a是曲线尖峰的高度，b是尖峰中心的坐标，c称为标准方差<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021530/1622339515069.png" alt="高斯函数"></p><p><font color="#DD7ADF">二维高斯核函数</font>常用于高斯模糊Gaussian Blur，在数学领域，主要是用于解决热力方程和扩散方程，以及定义Weiertrass Transform<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo><mo>=</mo><mi>A</mi><mi>exp</mi><mfenced><mrow><mo>-</mo><mfenced><mrow><mfrac><msup><mfenced><mrow><mi>x</mi><mo>-</mo><msub><mi>x</mi><mi>o</mi></msub></mrow></mfenced><mn>2</mn></msup><mrow><mn>2</mn><msubsup><mi>&#x3C3;</mi><mi>x</mi><mn>2</mn></msubsup></mrow></mfrac><mo>+</mo><mfrac><msup><mfenced><mrow><mi>y</mi><mo>-</mo><msub><mi>y</mi><mi>o</mi></msub></mrow></mfenced><mn>2</mn></msup><mrow><mn>2</mn><msubsup><mi>&#x3C3;</mi><mi>y</mi><mn>2</mn></msubsup></mrow></mfrac></mrow></mfenced></mrow></mfenced></math><br>A是幅值，x。y。是中心点坐标，σx σy是方差，图示如下，A = 1, xo = 0, yo = 0, σx = σy = 1<br><img src="https://gitee.com/merlynr/img-store/raw/master/2021530/1622340032183.png" alt="二维高斯函数"></p></blockquote><p>设 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mo>&#x2026;</mo><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></math> 是随机变量 $f$ 的独立同分布样本，那么概率密度函数的核函数近似为：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mover><mi>f</mi><mo>^</mo></mover><mi>h</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><mi>h</mi></mrow></mfrac><munderover><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>K</mi><mfenced><mfrac><mrow><mi>x</mi><mo>-</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mi>h</mi></mfrac></mfenced></math>,K()是核函数，h是带宽,充当光滑参数</p><p>对于对象 $o$ ， <math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi>f</mi><mo>^</mo></mover><mo>(</mo><mi>o</mi><mo>)</mo></math> 给出该对象被随机过程中产生的估计概率。如果 <math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi>f</mi><mo>^</mo></mover><mo>(</mo><mi>o</mi><mo>)</mo></math> 过小，$o$  可能是离群点。</p><h3 id="基于邻近性的方法"><a href="#基于邻近性的方法" class="headerlink" title="基于邻近性的方法"></a>基于邻近性的方法</h3><p>假定一个对象是离群点，如果在特征空间中的最近邻也远离它，即该对象与它的最近邻之间的邻近性显著地偏离数据集中其他对象与它们的近邻之间的邻近性。</p><p>基于邻近性的方法的有效性高度依赖与所使用的邻近性度量，主要有<strong>基于距离</strong>和<strong>基于密度</strong>的离群点检测方法。</p><p><font color="#7FFF00">通俗理解，</font>离群点与近邻点的近邻距离明显大于其它对象与其的近邻的距离。即离群点周边环境明显和其它对象不一样。</p><h4 id="基于距离的离群点检测"><a href="#基于距离的离群点检测" class="headerlink" title="基于距离的离群点检测"></a>基于距离的离群点检测</h4><p>对象给定半径的邻域，如果它的邻域内没有足够多的其他点，则该点被认为是离群点。</p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mfenced close="||" open="||"><mfenced close="}" open="{"><mrow><msup><mi>o</mi><mo>‘</mo></msup><mo>&#x2223;</mo><mo>dist</mo><mfenced><mrow><mi>o</mi><mo>,</mo><msup><mi>o</mi><mo>‘</mo></msup></mrow></mfenced><mo>&#x2264;</mo><mi>r</mi></mrow></mfenced></mfenced></mrow><mrow><mo>&#x2016;</mo><mi>D</mi><mo>&#x2016;</mo></mrow></mfrac><mo>&#x2264;</mo><mi>&#x3C0;</mi></math></p><p><font color="#228B22">r是距离阈值</font>，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3C0;</mi></math>  是分数阈值，对象 $o$ 如果满足上面的式子则是一个  离群点。</p><h4 id="基于密度的离群点检测"><a href="#基于密度的离群点检测" class="headerlink" title="基于密度的离群点检测"></a>基于密度的离群点检测</h4><p>基于距离的检测方法从全局考虑数据集，所找到的离群点都是<strong>全局离群点</strong>，但实际上数据结构更复杂，对象<font color="#8FBC8F">可能</font>关于其局部邻域，而<font color="#8FBC8F">不是</font>整个数据分布而视为离群点。</p><p>基于密度的离群点检测方法基本假定为：<strong>非离群点对象周围的密度与其邻域周围的密度类似，而离群点对象周围的密度显著不同于其邻域周围的密度。</strong></p><p><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo><mo>=</mo><mfenced close="}" open="{"><mrow><msup><mi>o</mi><mo>‘</mo></msup><mo>&#x2223;</mo><msup><mi>o</mi><mo>‘</mo></msup><mo>&#x2208;</mo><mi>D</mi><mo>,</mo><mo>dist</mo><mfenced><mrow><mi>o</mi><mo>,</mo><msup><mi>o</mi><mo>‘</mo></msup></mrow></mfenced><mo>&#x2264;</mo><msub><mo>dist</mo><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></mrow></mfenced></math></p><p>D为数据集，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mo>dist</mo><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></math>  是对象o第k个近邻的对象之间的距离，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></math>  是所有在<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mo>dist</mo><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></math> 之内的对象集。可以使用 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></math> 中的对象到o的平均距离作为局部密度的度量，但是为了避免比如有非常近的近邻使得距离度量统计产生波动，需要加上光滑效果：<br>$reachdist$<math xmlns="http://www.w3.org/1998/Math/MathML"><mmultiscripts><mfenced><mrow><mi>o</mi><mo>&#x2190;</mo><msup><mi>o</mi><mo>‘</mo></msup></mrow></mfenced><mprescripts/><mi>k</mi><none/></mmultiscripts><mo>=</mo><mi>max</mi><mfenced close="}" open="{"><mrow><msub><mo>dist</mo><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo><mo>,</mo><mo>dist</mo><mfenced><mrow><mi>o</mi><mo>,</mo><msup><mi>o</mi><mo>‘</mo></msup></mrow></mfenced></mrow></mfenced></math><br>k是用户指定参数，控制光滑效果。对象o的局部密度为：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>l</mi><mi>r</mi><msub><mi>d</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo><mo>=</mo><mfrac><mfenced close="||" open="||"><mrow><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></mrow></mfenced><mrow><msub><mo>&#x2211;</mo><mrow><msup><mi>o</mi><mo>‘</mo></msup><mo>&#x2208;</mo><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></mrow></msub><msub><mtext>&#xA0;reachdist&#xA0;</mtext><mi>k</mi></msub><mfenced><mrow><msup><mi>o</mi><mo>‘</mo></msup><mo>&#x2190;</mo><mi>o</mi></mrow></mfenced></mrow></mfrac></math><br>o的局部离群点因子为：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi><mi>O</mi><msub><mi>F</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo><mo>=</mo><mfrac><mrow><msub><mo>&#x2211;</mo><mrow><msup><mi>o</mi><mo>‘</mo></msup><mo>&#x2208;</mo><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></mrow></msub><mfrac><mrow><msub><mo>lrd</mo><mi>k</mi></msub><mfenced><msup><mi>o</mi><mo>‘</mo></msup></mfenced></mrow><mrow><msub><mo>lrd</mo><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></mrow></mfrac></mrow><mfenced close="||" open="||"><mrow><msub><mi>N</mi><mi>k</mi></msub><mo>(</mo><mi>o</mi><mo>)</mo></mrow></mfenced></mfrac></math><br>局部离群点因子是o的可达密度与o的k-最近邻可达密度之比的平均值。对象o的局部可达密度越低，并且o的k-最近邻局部可达密度越高，LOF值越高。</p><p><font color="#B8860B">LOF 的思想：</font><br>通过比较每个点 p 和其邻域点的密度来判断该点是否为异常点，如果点 p 的密度越低，越可能被认定是异常点。至于这个密度，是通过点之间的距离来计算的，点之间距离越远，密度越低，距离越近，密度越高，而且这里的密度不是基于全局数据，而是基于局部数据。</p><h3 id="基于聚类的方法"><a href="#基于聚类的方法" class="headerlink" title="基于聚类的方法"></a>基于聚类的方法</h3><p>假定<font color="#556B2F">正常数据</font>对象属于大的、稠密的簇、而<font color="#556B2F">离群点</font>属于小或稀疏的簇，或者不属于任何簇。直截了当的采用聚类方法用于离群点检测开销会很大，不能很好地扩展到大数据集上。</p><ol><li>将离群点检测为不属于任何簇的对象</li><li>最近簇距离的离群点检测</li></ol><blockquote><p>假设o到最近的簇中心为 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>c</mi><mi>o</mi></msub></math> ,则o与 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>c</mi><mi>o</mi></msub></math> 之间的距离为 <math xmlns="http://www.w3.org/1998/Math/MathML"><mo>dist</mo><mfenced><mrow><mi>o</mi><mo>,</mo><msub><mi>c</mi><mi>o</mi></msub></mrow></mfenced></math> ， <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>c</mi><mi>o</mi></msub></math> 与指派到 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>c</mi><mi>o</mi></msub></math> 这个簇中的对象之间的平均距离为 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>l</mi><msub><mi>c</mi><mi>o</mi></msub></msub></math> ，比率 <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mo>dist</mo><mfenced><mrow><mi>o</mi><mo>,</mo><msub><mi>c</mi><mi>o</mi></msub></mrow></mfenced></mrow><msub><mi>l</mi><msub><mi>c</mi><mi>o</mi></msub></msub></mfrac></math> 度量 <math xmlns="http://www.w3.org/1998/Math/MathML"><mo>dist</mo><mfenced><mrow><mi>o</mi><mo>,</mo><msub><mi>c</mi><mi>o</mi></msub></mrow></mfenced></math> 与平均值的差异程度。</p></blockquote><ol start="3"><li>识别小簇或稀疏簇</li></ol><blockquote><p>先是找出数据集中的簇，并把它们按照大小降序排列，假定大部分数据点都不是离群点。它使用一个参数<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3B1;</mi><mo>(</mo><mn>0</mn><mo>&#x2264;</mo><mi>&#x3B1;</mi><mo>&#x2264;</mo><mn>1</mn><mo>)</mo></math>  区别大小簇。任何至少包含数据集中 <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>&#x3B1;</mi><mo>%</mo></math> 数据点的簇都被视为大簇，其余为小簇。然后对每个数据点赋予基于簇的局部离群点因子(CBLOF)。对于属于大簇的点，它的CBLOF是簇的大小与该点与簇的相似性的乘积。对于小簇的点，其CBLOF用小簇的大小和该点与最近的大簇的相似性乘积计算。<br>CBLOF代表点属于簇的概率，值越大，点与簇越相似。远离任何大簇的小簇被看作离群点组成，并且具有最低CBLOF值的点怀疑为离群点。</p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>LOF类的算法适用于局部区域空间问题，对于完整区域空间，KNN和Iforest更好。</li><li>KNN每次运行需要遍历所有数据，所以效率比较低，如果效率要求比较高，用聚类方法更好。</li><li>传统机器学习算法中Iforest、KNN和OCSVM表现较好，基于深度学习的算法准确率在论文中更好！</li><li>对于不同种类的数据，没有哪一种算法是最好的，HBOS算法在某些数据集上的表现非常好，且运算速度很快。</li><li>当数据特征数很多时，如400个特征，只有KNN表现还不错，Iforest表现也不好，因为特征选取的随机性，可能无法覆盖足够多的特征（不绝对）。</li><li>ABOD综合效果最差，尽量不要用。</li></ol>]]></content>
      
      
      <categories>
          
          <category> algorithm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> study </tag>
            
            <tag> algorithm </tag>
            
            <tag> machine learning </tag>
            
            <tag> data mining </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-05-15【Week】</title>
      <link href="/2021/05/19/2021-05-15%E3%80%90Week%E3%80%91/"/>
      <url>/2021/05/19/2021-05-15%E3%80%90Week%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h3 id="本周安排"><a href="#本周安排" class="headerlink" title="本周安排"></a>本周安排</h3><ul><li><input disabled="" type="checkbox"> 源码分析</li><li><input disabled="" type="checkbox"> 预开题准备</li><li><input disabled="" type="checkbox"> 重新整理并寻找合适的研究点</li></ul><h3 id="任务完成情况"><a href="#任务完成情况" class="headerlink" title="任务完成情况"></a>任务完成情况</h3><ol><li>源码分析已经完成，tagui的源码的难点主要是语言多，但是其中逻辑不是很难</li><li>这次预开题，我是比较认真准备的，当时讲的时候人比较多，可能比较着急哇，我主要为了解决RPA中可并发执行任务的功能，这块的难点就是资源分配的问题，所以涉及了大量资源分配的研究，目前国内外RPA这方面都比较淡化，没有很好的解决方式，所以我感觉还是可以的：）</li><li>现在在看老师给发的文档，大部分我也看过了，里面的点太笼统，面太大，当时和老师交流后，重新理解了一下，是研究机器学习在业务流程中处理文档，表格，但是目前就RPA里面来说，自动获取文件中信息处理的比较好，各个公司都没有在这块上投入更多资源</li></ol><h3 id="汇总文件补充"><a href="#汇总文件补充" class="headerlink" title="汇总文件补充"></a>汇总文件补充</h3><blockquote><p>平时学习时，总结都是单独的，所以这块就引用上周写的汇总了</p></blockquote><ol><li>tagui源码分析</li></ol><p><img src="./attachments/TagUI%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E5%8F%8A%E5%88%86%E6%9E%90.pdf" alt="TagUI源码阅读及分析"></p><ol start="2"><li>预开题PPT</li></ol><p><img src="./attachments/RPA%E5%8A%A8%E6%80%81%E6%84%9F%E7%9F%A5%E5%88%86%E9%85%8D%E4%B8%9A%E5%8A%A1%E8%B5%84%E6%BA%90%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%BA%94%E7%94%A8.pptx" alt="RPA动态感知分配业务资源的研究与应用"></p><ol start="3"><li>重新整理—未完成</li></ol><p><img src="./attachments/RPA+AI.pdf" alt="RPA+AI"></p>]]></content>
      
      
      <categories>
          
          <category> weekly report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RPA+AI</title>
      <link href="/2021/05/17/RPA+AI/"/>
      <url>/2021/05/17/RPA+AI/</url>
      
        <content type="html"><![CDATA[<h2 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h2><p><a href="https://developer.aliyun.com/group/rpa?spm=a2c6h.12873639.0.0.65b05d65mS6OlC#/?_k=agnoe0">阿里云RPA社区</a></p><p><a href="https://zhuanlan.zhihu.com/p/59034887?utm_oi=786717341600858112">阿里云RPA（机器人流程自动化）系列</a></p><p><a href="https://www.yuque.com/aliyun_rpa">阿里云RPA文档</a></p><p><a href="https://github.com/rpabotsworld/awesome-rpa">资源</a></p><h2 id="阅读记录"><a href="#阅读记录" class="headerlink" title="阅读记录"></a>阅读记录</h2><h3 id="记录"><a href="#记录" class="headerlink" title="记录"></a>记录</h3><h4 id="阿里云RPA系列"><a href="#阿里云RPA系列" class="headerlink" title="阿里云RPA系列"></a>阿里云RPA系列</h4><ol><li>文件信息的处理–提取和处理结构和半结构化数据</li><li>异常处理–宕机、流程回滚、中断后的流程接续等问题</li><li>业务流程从明确化变为高适配的—智能处理【制定与运行过程中】</li><li>各类场景–大量重复【基本配置通用性高】、可贴合各类场景【规则灵活，外附组件可灵活配置】</li></ol><h4 id="S公司智能财务机器人共享中心建设与实践"><a href="#S公司智能财务机器人共享中心建设与实践" class="headerlink" title="S公司智能财务机器人共享中心建设与实践"></a>S公司智能财务机器人共享中心建设与实践</h4><p><a href="https://m.hanspub.org/journal/paper/34237">URL</a></p><ol><li>分布式部署时，对于资源无法实时有效判断其是否有效可用</li><li>将robot集中到资源池中，供全公司使用，打破单元机器人的壁垒—无法有效的共享数据，但是安全受到了极大威胁</li></ol><h4 id="一种基于RPA机器人共享中心的自动审批的方法【专利】"><a href="#一种基于RPA机器人共享中心的自动审批的方法【专利】" class="headerlink" title="一种基于RPA机器人共享中心的自动审批的方法【专利】"></a>一种基于RPA机器人共享中心的自动审批的方法【专利】</h4><p><a href="http://www10.drugfuture.com/pdfview/generic/web/viewer.html?file=/cnpat/package/%E5%8F%91%E6%98%8E%E4%B8%93%E5%88%A9%E7%94%B3%E8%AF%B7%E8%AF%B4%E6%98%8E%E4%B9%A6CN201911335237.4.pdf">PDF</a></p><ol><li>没有实际创新点，就是为用户提供了访问权限，根据用户自己提交的内容，进行过滤分类，然后由robot进行访问对应的资源进行处理，专利只是讲了研究内容，具体算法和实践没有提到，所以它所涉及到的对机器人共享中心进行分级调度没有表现出来。</li></ol><h3 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h3><blockquote><p>阿里云版本迭代</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021517/1621238642819.png" alt="阿里云版本迭代方案"></p><h3 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h3><ol><li>流程处理未知问题的智能化</li><li>中间通信安全</li><li>重新定义RPA，目前RPA，只是一个外接的控制工具，而不能替代人工</li><li>==* #F44336==挖掘业务流程，结合机器学习进行业务预测</li><li></li></ol><h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><ol><li>无数据比对，无证明方式，用数据证明有效改进</li></ol><p><a href="https://wap.cnki.net/touch/web/Dissertation/Article/10013-1019047248.nh.html">https://wap.cnki.net/touch/web/Dissertation/Article/10013-1019047248.nh.html</a></p><p><a href="https://www.touqikan.com/jsjj/660421.html">https://www.touqikan.com/jsjj/660421.html</a></p>]]></content>
      
      
      <categories>
          
          <category> RPA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> RPA </tag>
            
            <tag> machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nicholas Burns</title>
      <link href="/2021/05/06/Nicholas%20Burns/"/>
      <url>/2021/05/06/Nicholas%20Burns/</url>
      
        <content type="html"><![CDATA[<p><strong>身份：</strong><br>•    罗伊和芭芭拉·古德曼（Roy and Barbara Goodman）哈佛大学肯尼迪学校外交与国际关系实践家庭教授<br>•    Belfer Center董事会成员<br>•    外交项目的未来教席<br>•    欧洲与跨大西洋关系项目教席<br>•    中东倡议联盟会员<br>•    美国国务秘书项目主任</p><p><strong>个人履历见附件</strong></p><p><img src="./attachments/RNB_Bio_Full_1.pdf" alt="RNB_Bio_Full_1"></p><p><strong>联系方式：</strong></p><ul><li>twitter： @rnicholasburns</li><li>phone： 617-495-2495</li><li>邮箱：<a href="mailto:&#110;&#105;&#x63;&#x68;&#x6f;&#108;&#97;&#x73;&#95;&#x62;&#117;&#x72;&#110;&#115;&#x40;&#x68;&#107;&#x73;&#x2e;&#104;&#97;&#x72;&#118;&#x61;&#114;&#100;&#46;&#x65;&#x64;&#117;">&#110;&#105;&#x63;&#x68;&#x6f;&#108;&#97;&#x73;&#95;&#x62;&#117;&#x72;&#110;&#115;&#x40;&#x68;&#107;&#x73;&#x2e;&#104;&#97;&#x72;&#118;&#x61;&#114;&#100;&#46;&#x65;&#x64;&#117;</a></li></ul><p><strong>助理信息：</strong></p><ul><li>艾莉森·希格斯（Alison Hillegeist）</li><li>电邮：<a href="mailto:&#x61;&#x6c;&#105;&#115;&#111;&#110;&#95;&#104;&#x69;&#108;&#x6c;&#x65;&#103;&#101;&#105;&#x73;&#116;&#x40;&#x68;&#x6b;&#x73;&#46;&#x68;&#x61;&#x72;&#118;&#97;&#x72;&#x64;&#46;&#x65;&#100;&#117;">&#x61;&#x6c;&#105;&#115;&#111;&#110;&#95;&#104;&#x69;&#108;&#x6c;&#x65;&#103;&#101;&#105;&#x73;&#116;&#x40;&#x68;&#x6b;&#x73;&#46;&#x68;&#x61;&#x72;&#118;&#97;&#x72;&#x64;&#46;&#x65;&#100;&#117;</a></li><li>电话：617-495-2495</li><li>Mailing Address: John F. Kennedy School of Government、79 JFK St.、Cambridge, Massachusetts</li></ul><p><strong>家庭：</strong><br>妻子伊丽莎白·贝利（Elizabeth A. Baylies）育有三个女儿：莎拉（Sarah），伊丽莎白（Elizabeth）和卡罗琳（Caroline）</p><p><a href="https://www.youtube.com/watch?v=BloYsnYLxhM&t=42s">信息来源-1</a></p><ul><li>Nicholas Burns与妻子贝利在巴黎美国大学（American University of Paris）在1982年相识并相爱 </li><li>莎拉（Sarah）: 2017.05 毕业于巴黎美国大学（AUP）</li></ul><p><strong>官方个人网站：</strong> <a href="https://www.belfercenter.org/person/nicholas-burns">https://www.belfercenter.org/person/nicholas-burns</a></p><blockquote><p>亲属</p></blockquote><p>侄子：  Ben Hutchins【 command of Marine Air Group 13 in Yuma,2019.08】（侄子本·哈钦斯上校（Ben Hutchins上校）为亚利桑那州尤马市的第13航空集团负责，现在指挥F-35和“ rier”式战斗机）</p><p>堂兄： 鲍勃·肯尼迪【Bob Kennedy  led the historic Mechanics Hall in Worcester for 12 years,2006-2018】<br><img src="https://gitee.com/merlynr/img-store/raw/master/202156/Dn-k1W_XoAEdMqu.jfif" alt="Dn-k1W_XoAEdMqu"></p><blockquote><p>哈佛</p></blockquote><p>助教： Philip Balson【哈佛大学，2019毕业】<br>菲利普·巴尔森</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202156/D1vTtnUWsAYtUFT.jfif" alt="菲利普·巴尔森"></p><p>Vince Lowney【研究助理文斯·洛尼2018.05毕业于哈佛，并于<strong>7月就任美国外交部</strong>】</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202156/Dd_uNA6W4AAsCyp.jfif" alt="Dd_uNA6W4AAsCyp"></p><p>Aditi Kumar 和 Chris Mirasola 2018.05毕业于哈佛</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202156/Dd-jdveXkAAu3TU.jfif" alt="Dd-jdveXkAAu3TU"></p><p>泰莎·亨利（Tessa Henry）和但丁·托波（Dante Toppo）2017.05毕业于哈佛</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202156/DAsbrBBXUAQoJcb.jfif" alt="DAsbrBBXUAQoJcb"></p><blockquote><p>组织@RedSox  –棒球俱乐部，没找到与之有关的报道</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> people </category>
          
      </categories>
      
      
        <tags>
            
            <tag> security </tag>
            
            <tag> people </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TagUI源码阅读及分析</title>
      <link href="/2021/05/06/TagUI%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E5%8F%8A%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/06/TagUI%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E5%8F%8A%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>idea：</p><ol><li>RPA进程与AI的融合，非BPA那种与业务进行结合</li></ol><h3 id="tagui运行背后的技术支持"><a href="#tagui运行背后的技术支持" class="headerlink" title="tagui运行背后的技术支持"></a>tagui运行背后的技术支持</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/202156/1620314243708.png" alt="技术支持"></p><ol><li>Automation Flow:作为一种flow 编辑工具，集成在tagui中，允许TagUi可以通过本地文件，在线文件甚至url获取业务流程；</li></ol><ul><li>同时可以通过命令，图表，url，API，email等方式传入参数</li></ul><ol start="3"><li>Chrome Extension 可以通过类似录视频的方式记录用户行为并创建业务流程</li><li>R&amp;Python 提供机器学习模块</li><li>Sikuli 图像识别处理</li><li>CasperJS测试集成工具</li></ol><h3 id="关键技术组成"><a href="#关键技术组成" class="headerlink" title="关键技术组成"></a>关键技术组成</h3><ul><li>SikuliX 用于图像标记、追踪功能</li><li>phantomJs 是一种轻量级脚本语言（环境简单）</li><li>casperjs中基于PhantomJS和SlimerJS的导航脚本和测试工具，包函了对于一些对于网页的基本操作的工具</li><li>SlimerJS与phantomjs类似，互相补充</li></ul><h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><ul><li>end_process: 通过扫描进程，按顺序杀死进程比Ctrl+C更加安全可靠</li><li>erina:==与tagui——helper有关，暂时无法看懂 #009688==</li><li>sleep: 补充win10环境中对于进程延迟的控制</li><li>tagui：TagUI接受脚本和参数</li><li>tagui_chrome: 用于连接chrome，通过控制浏览器发送和接收数据</li><li>tagui_crontab: 运行tagui服务端tagui_service</li><li>tagui_footer: 输出当前网站的url和title</li><li>tagui_global: ==暂时不懂 #009688==</li><li>tagui_header: ==作为一个工具包 #009688==</li></ul><h3 id="功能实现详细阐述"><a href="#功能实现详细阐述" class="headerlink" title="功能实现详细阐述"></a>功能实现详细阐述</h3><ol><li>监控对应任务进程进行杀死【php,chrome,sikuli,python,r,tagui】</li><li>sss</li><li>在Windows环境中无法进程设置延时，所以通过ping.exe补充功能</li><li>tagui框架入口源码交易理解，不做详细分析</li><li>tagui_chrome主要是依赖Textalk实现与chrome并发通信,同时它集成了Sikuli，可以通过图像识别实现业务流程</li><li>通过监控服务端状态，运行或者重复运行tagui_service</li><li>利用casperJs抓取当前脚本的url和title</li><li>sss</li><li>sss</li></ol><h3 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h3><p><a href="https://zhuanlan.zhihu.com/p/366304958">https://zhuanlan.zhihu.com/p/366304958</a><br><a href="https://github.com/kensoh/TagUI/tree/before_aisg">https://github.com/kensoh/TagUI/tree/before_aisg</a></p><h4 id="shell语言规范"><a href="#shell语言规范" class="headerlink" title="shell语言规范"></a>shell语言规范</h4><p><a href="https://www.cnblogs.com/zrmw/p/9625727.html">https://www.cnblogs.com/zrmw/p/9625727.html</a></p><p><a href="https://blog.csdn.net/weixin_37766087/article/details/99974385">https://blog.csdn.net/weixin_37766087/article/details/99974385</a></p><h4 id="curl工具"><a href="#curl工具" class="headerlink" title="curl工具"></a>curl工具</h4><p><a href="https://www.ruanyifeng.com/blog/2019/09/curl-reference.html">https://www.ruanyifeng.com/blog/2019/09/curl-reference.html</a></p><h4 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h4><p><a href="https://blog.csdn.net/shenhuan1104/article/details/75852822">https://blog.csdn.net/shenhuan1104/article/details/75852822</a></p><p>grep -iq 404 ，匹配到404，则返回1；反之</p><h4 id="业务流程模型（BPMN）"><a href="#业务流程模型（BPMN）" class="headerlink" title="业务流程模型（BPMN）"></a>业务流程模型（BPMN）</h4><h4 id="流程引擎"><a href="#流程引擎" class="headerlink" title="流程引擎"></a>流程引擎</h4><p>CasperJS + PhantomJS==》Puppeteer + Node.js引擎</p><p><a href="https://blog.csdn.net/qq_38941937/article/details/110296665">https://blog.csdn.net/qq_38941937/article/details/110296665</a></p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><ol><li>流式无并行</li></ol><h4 id="开题失败—题目比较无实际意义"><a href="#开题失败—题目比较无实际意义" class="headerlink" title="开题失败—题目比较无实际意义"></a>开题失败—题目比较无实际意义</h4><p><img src="./attachments/RPA%E5%8A%A8%E6%80%81%E6%84%9F%E7%9F%A5%E5%88%86%E9%85%8D%E4%B8%9A%E5%8A%A1%E8%B5%84%E6%BA%90%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%BA%94%E7%94%A8.pptx" alt="RPA动态感知分配业务资源的研究与应用"></p>]]></content>
      
      
      <categories>
          
          <category> FrameWork </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> RPA </tag>
            
            <tag> code </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>小论文阶段性报告</title>
      <link href="/2021/04/25/%E5%B0%8F%E8%AE%BA%E6%96%87%E9%98%B6%E6%AE%B5%E6%80%A7%E6%8A%A5%E5%91%8A/"/>
      <url>/2021/04/25/%E5%B0%8F%E8%AE%BA%E6%96%87%E9%98%B6%E6%AE%B5%E6%80%A7%E6%8A%A5%E5%91%8A/</url>
      
        <content type="html"><![CDATA[<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li><input checked="" disabled="" type="checkbox"> 数据处理</li><li><input checked="" disabled="" type="checkbox"> 构建虚拟环境</li><li><input disabled="" type="checkbox"> 搭建模型，进行初步运行</li><li><input checked="" disabled="" type="checkbox"> 学习已有模型</li></ul><h1 id="DONE"><a href="#DONE" class="headerlink" title="DONE"></a>DONE</h1><p>1、数据方面前几周已经处理完成，主要时间花费在对于数据中结点直接的关系进行梳理，主要元素来自于9个页面和若干个弹窗，总共数据有约一百个结点信息组成。<br>2、深度增强学习中如何能够快速找到最优动作会大大缩短训练时间，获得最大q值，所以通过将同层元素聚集在一起，实现Agent以最小代价寻找到合适动作，我通过将数据绑定到Gosper曲线结点上，满足同层元素在二维空间上聚集，然后在此基础上根据离散点的分布位置画出泰森多边形，这样就可以凸显出各模块元素特征，最后通过颜色以及结点之间关系可以之间凸显示出元素关系。这部分是环境的显示部分。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/1650860851444.png" alt="结点数据"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/1650865770175.png" alt="Goper生成规则"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/1650865873956.png" alt="代码中实现"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/myplot1.png" alt="Gosper曲线"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/myplot3.png" alt="绑定曲线后，隐藏掉曲线"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/1650867119647.png" alt="局部约束"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/myplot4.png" alt="根据数据离散点生成泰森多边形"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/voro.png" alt="去掉无用元素生成环境图"></p><p>3、第三阶段是环境构建agent的动作以及环境反馈。主要工作在于动作，以及规则的写入，状态空间的构建,以及历史动作的保存以及读取</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/VeryCapture_20220425124642.gif" alt="动作空间，奖惩，状态空间构建完成"></p><p>4、构建深度增强模型，baseline模型DQN。目前状态空间由4x2的矩阵存储最近四步动作来表示，同时使用一维3*7矩阵作为离散动作空间。这里主要是优化大论文中第一个创新点，结合使用第二个创新点的思想。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/1650866999994.png" alt="大论文，创新点一"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20224/1650867028297.png" alt="大论文，创新点二"></p><h1 id="NEED-NEXT-STEP"><a href="#NEED-NEXT-STEP" class="headerlink" title="NEED NEXT STEP"></a>NEED NEXT STEP</h1><p>1、目前baseline还需要调试<br>2、为每个结点加入添加判断，以满足实际需求<br>3、优化模型，以图片方式当如为状态，进行训练比对。</p><h1 id="验证与改进"><a href="#验证与改进" class="headerlink" title="验证与改进"></a>验证与改进</h1><p>状态表示不学习，恶婆塞鲁值学习慢，超参数实验未向目标移动值奖励很大【值设置】，问题依旧有【奖励设置】，多模型学习，学习后期后奖励下降，创新</p><p>1、修改环境，一开始通过连续四个位置信息构建的状态空间，经过多次训练（1000yinei）后发现，agent很难记到</p><h2 id="实验进行一《距离为四》"><a href="#实验进行一《距离为四》" class="headerlink" title="实验进行一《距离为四》"></a>实验进行一《距离为四》</h2><h3 id="实验第一次"><a href="#实验第一次" class="headerlink" title="实验第一次"></a>实验第一次</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/20225/1651806092845.png" alt="参数1"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20225/1651806113103.png" alt="参数二"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20225/1651806154911.png" alt="参数三"></p><h4 id="DDQN"><a href="#DDQN" class="headerlink" title="DDQN"></a>DDQN</h4><p><img src="https://gitee.com/merlynr/img-store/raw/master/20225/1651806365863.png" alt="理想一"></p>]]></content>
      
      
      <categories>
          
          <category> plan </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-04-12【Week】</title>
      <link href="/2021/04/12/2021-04-12%E3%80%90Week%E3%80%91/"/>
      <url>/2021/04/12/2021-04-12%E3%80%90Week%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="本周安排"><a href="#本周安排" class="headerlink" title="本周安排"></a>本周安排</h2><ul><li><input disabled="" type="checkbox"> MIT6.003要听四节课程</li><li><input checked="" disabled="" type="checkbox"> 阅读并总结论文</li></ul><blockquote><p>Automated Discovery of Data Transformations for Robotic Process Automation</p></blockquote><ul><li><input checked="" disabled="" type="checkbox"> 阅读 “Robotic Process Automation (RPA) and Security ”制定一份RPA系统配置计划书</li><li><input checked="" disabled="" type="checkbox"> 完成RPA总结</li><li><input disabled="" type="checkbox"> 搭建实验室论坛</li><li><input disabled="" type="checkbox"> 完成小论文框架</li></ul><p><strong>后期补充</strong></p><ul><li><input checked="" disabled="" type="checkbox"> 帮涛总完成数据库整理</li><li><input checked="" disabled="" type="checkbox"> 确定基本RPA系统的组成</li></ul><h2 id="完成情况"><a href="#完成情况" class="headerlink" title="完成情况"></a>完成情况</h2><p><strong>任务完成</strong></p><ol><li>MIT6.003只听完第一节课，英语讲需要字幕反复听；</li><li>两篇论文，第一篇是关于RPA在进行文档操作过程中数据转换的改进，这篇还没有细读，后面细读一下、第二篇是关于RPA可能存在的问题，只是一篇综述，没有实际建议</li><li>RPA总结也初步完成，包括给那几个本科生讲了一下，就当时情况看，他们确实没有多少了解，几位同学可能还需要一些项目培养一下编码能力，可能需要更多努力来完成比赛，同时对于比赛题目的确定也需要多多了解RPA的应用场景</li><li>实验室论坛这块准备先让新来的师弟试试呀，和他交流过，他对于网络这块比较擅长，但是对于服务器这块比较欠缺，目前他和邹瑞学习，正好可以锻炼一下，如果后期没有完成，我再完成</li><li>目前研究点基本明确，只是缺少一个对于RPA研究下去信心，资料少，人少，学习内容多，工程大，确实需要先把UiPath搭建起来，并研究通了才能有信息继续研究下去</li><li>小论文这块想的是，本来学硕要求变难了，在平时学习过程中就开始填充知识，尽可能的跟上戴师兄和陈剑秋师兄的脚步</li><li>周五上午的数据整理初步完成，当时整理只是整理了部分，涛总也只是催了几个数据库的整理，后续情况等下次涛总安排吧</li><li>周六周日的时间，调研了一下UiPath的搭建，确定了基本的需求和流程，准备下周准备资源并进行搭建</li></ol><p><strong>学习方面</strong></p><blockquote><p>主要精力集中在RPA的总结上了，通过梳理几个大型公司的RPA产品，确定了目前比较热门以及将会被推广的产品有点：</p></blockquote><ol><li>对于屏幕抓取的智能解决方案，通过AI自我修复流程，极低的降低了业务流程因因素抓取失败或因被其它相近元素干扰导致流程作业失败的机率</li><li>为用户提供一个可以用户可以自己训练AI的场景，让用户可以根据自己实际生产需求，训练出更符合自身的AI</li><li>视频录制业务流程，传统的录制由于对于元素的获取容易受到旁边元素干扰，而且对于未知问题处理能力极差，所有需要专门RPA开发员的，但是目前有个别公司推出了一个图像识别算法，大体意思是通过扫描页面元素树确定鼠标触碰元素，几乎达到无失误识别，同时加上AI修正流程功能，录制视频来创建业务流程的目的已经可以达到了。</li><li>还有一点是比较容易忽略的同时是很实际的，对于RPA的部署，本身RPA对于资源的消耗是比较大的，但是却是弹性的，所以比较难以控制RPA部署规模，有个别公司也提出了解决方案，就是，算法，bot，已经中台控制都是分开，分规模，分类别可选择的进行部署。</li></ol><p> <strong>论文方面</strong></p><ol><li>RPA相关的论文，除了一些综述已经找不到其它有价值的了，下一步可能更多去一些公司的论坛进行查看了</li><li>目前有两个点，一个是，通过大量阅读和对于各个公司的观察，发现他们的重心都放在与AI的结合，扩展使用场景，却回避了RPA安全的严重缺陷，可能他们的场景是公司内网吧，所以第一个研究点就是RPA中的安全传输或者RPA中bot的数字认证；第二个是大点，还未确定可能与第一点，就是寻找一个应用场景，RPA需要与场景结合，通用性太高就容易导致研究</li><li>为RPA场景做准备，会阅读一些与人工智能相关的论文</li></ol><h2 id="遇到问题"><a href="#遇到问题" class="headerlink" title="遇到问题"></a>遇到问题</h2><ol><li>学习资料已经只剩下框架的官方文档了，国内外的论文可以查到的都是一些综述了，后期只能查阅一些一些公司的讨论</li><li>对于UiPath的搭建进行了初步了解，RPA框架本身存在的问题就是无法容器化，这也是一个研究点，所以如果公司没用空的服务器，我只能在本地虚拟金进行尝试了，我今天在阿里云买了一个两核4G的服务器上进行搭建，发现内存不够，但是扩容需要钱太多了，就放弃了，下一步就在本地搭建RPA只能在本地进行尝试</li></ol><h2 id="后期安排"><a href="#后期安排" class="headerlink" title="后期安排"></a>后期安排</h2><ul><li><input disabled="" type="checkbox"> 提出一个较为可操作的部署方案，并在本地进行尝试并总结</li><li><input disabled="" type="checkbox"> 了解一下市场需求，构思一个RPA隐患会造成极大破坏的场景，提出解决方案</li><li><input disabled="" type="checkbox"> 查阅一些公司的技术思路，了解一下他们在安全这块的研究点及解决方案，目前我总结的有几点：<ol><li>如何最大化的职责分配保障业务安全并最小的避免对业务流程的干扰</li><li>如何有效的进行身份认证和凭证的发放与验证</li><li>是否可以通过数据加密有效保证安全，还待考虑！</li><li>日志监控这块研究一下，思路是构建一个日志记录追踪，类似微服务中的日志记录</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> weekly report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> RPA </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RPA</title>
      <link href="/2021/03/28/what%E2%80%98s%20the%20mean%20of%20RPA/"/>
      <url>/2021/03/28/what%E2%80%98s%20the%20mean%20of%20RPA/</url>
      
        <content type="html"><![CDATA[<h2 id="RPA"><a href="#RPA" class="headerlink" title="RPA"></a>RPA</h2><h3 id="进化历史"><a href="#进化历史" class="headerlink" title="进化历史"></a>进化历史</h3><ol><li>上个世纪二十年代 亨利·福特，改革了工业生产方式，开启了工业时代，提出了对于处理重复工作的需求</li><li>1990-2000，计算机被广泛使用，用于处理办公，提出批处理脚本和触发器</li><li>2000-2015，VBA宏编程（EXCEL宏）和BPA</li><li>2015-2018，RPA模型创建成功，并投入使用</li><li>2019~，RPA+AI，即RPA4.0被推出，被大企业认可</li></ol><p>1.2. 反应了为了解决重复工作，提出了批处理事务<br>脚本自动化：在RPA技术出现之前，脚本自动化是企业自动化可选的比较靠谱自动化落地技术。用于解决最基础的几步任务自动化，技术的缺点是没有容错、任务管理、弱鸡的基于GUI的能力。商业上的优势是，几乎可以免费使用。<br>3. VBA编程语言的创建是为了解决办公中常遇到的重复性问题【简单化】、BPA（业务流程自动化）通过深度关注业务流程，集成所有相关应用程序来实现功能，业务的实现与程序耦合太重【复杂化】</p><p>目前给出三个区别：<br><strong>集成</strong>：BPA相较于RPA对于一个业务流程提出了更加全面、更加精确的解决方法，但是BPA是一种侵入性很强的整合形式。它用自己的软件对现有的系统进行大修，并实现自己的系统。RPA不会破坏现有的业务流程。【存在优缺点】<br><strong>工作流</strong>：RPA机器人访问桌面现有的用户界面并执行人工任务，但是目前大多数机器人无法进行决策。BPA中使用的工作流程更加复杂，使用单一的处理模型来创建集成多种系统的工作流程。这些系统彼此交换和提取信息，以实现任务自动化，这需要API和数据库访问。这需要对编码和开发的大量IT支持。【应用场景的不同，无优缺点之分】<br><strong>定价</strong>：BPA定价取决于公司的规模。还有其涉及到的业务的规模。UiPath(RPA龙头企业)更加使用RPA类型来定价。【站在技术方面，RPA更加灵活，也更加适用】<br>4. 通过集成现有的业务不紧破坏了已有业务，同时过度的耦合、高昂的成本和无法普遍推广，这些条件都指定了传统化业务自动化流程只能为大公司所用。<br>这个时候屏幕抓取技术的诞生就突破了传统BPA的过度耦合的问题，它不需要过度依赖以前的业务来获取和处理数据，同时自动化与管理工具（管理系统的版本，安装，卸载等）使得RPA更易于推广，最后一个就是AI的加入，它是解放人类双手的核心，它可以根据人类先前的判断来执行任务。<br>5. RPA4.0的提出 我们不仅要看到AI为RPA提供的红利，同时也要看到RPA技术对于AI技术发展的重要意义，RPA为AI技术的发展提供了手和脚，RPA作为AI技术与现实生活的连接器，扩大了AI技术的使用范围</p><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><p>RPA的核心是通过自动化、智能化技术来“代替人”进行重复性、低价性、无需人工决策等固定性流程化操作，从而有效的提高工作效率，减少错误。</p><p>The main difference between software<br>robots and applications is the identity access<br>management (IAM) domain —  RPA instances<br>behave like an individual user. </p><h3 id="RPA进化四个阶段"><a href="#RPA进化四个阶段" class="headerlink" title="RPA进化四个阶段"></a>RPA进化四个阶段</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618314304547.png" alt="四个阶段"></p><p>1：辅助性RPA（Assisted RPA）<br>　　在RPA 1.0阶段，作为“虚拟助手”出现的RPA，几乎涵盖了机器人自动化的主要功能，以及现有桌面自动化软件的全部操作。部署在员工PC机上，以提高工作效率。缺点则是难以实现端到端的自动化，成规模地应用还很难。<br>　　2：非辅助性RPA（Unassisted RPA）<br>　　在RPA 2.0阶段，被称为“虚拟劳动力”的RPA，主要目标即实现端到端的自动化，以及虚拟员工分级。主要部署在VMS虚拟机上，能够编排工作内容，集中化管理机器人、分析机器人的表现等。缺点则是对于RPA软件机器人的工作仍然需要人工的控制和管理。<br>　　3：自主性RPA（Autonomous RPA）<br>　　在RPA 3.0阶段，其主要目标是实现端到端的自动化和成规模多功能虚拟劳动力。通常部署在云服务器和SaaS上，特点是实现自动分级、动态负载平衡、情景感知、高级分析和工作流。缺点则是处理非结构化数据仍较为困难。<br>　　4：认知性RPA（Cognitive RPA）<br>　　RPA 4.0将是未来RPA发展的方向。开始运用人工智能、机器学习以及自然语言处理等技术，以实现非结构化数据的处理、预测规范分析、自动任务接受处理等功能。<br>　　目前，尽管大多数RPA软件产品，都还集中在2.0 - 3.0之间，但其发展已相当成熟，产品化程度亦是很高。一些行业巨头已经开始向RPA 4.0发起了探索。</p><h3 id="播放几个视频"><a href="#播放几个视频" class="headerlink" title="播放几个视频"></a>播放几个视频</h3><h3 id="扩展理解"><a href="#扩展理解" class="headerlink" title="扩展理解"></a>扩展理解</h3><p>轻量级IT，任何电子设备都可以被操控，<br>智能客服、智能家居，以及很多重复性较高、朝左流程固定的办公工作都可以被替代</p><h2 id="国内外现状"><a href="#国内外现状" class="headerlink" title="国内外现状"></a>国内外现状</h2><p>就国内外发展现状进行对比，全球五强RPA占有47%的市场，中国国产RPA目前智能更多被使用在能源、医疗、政务等一些领域。</p><h3 id="国内外"><a href="#国内外" class="headerlink" title="国内外"></a>国内外</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021412/1618235359990.png" alt="国内外RPA"></p><p>国内主要厂商：来也科技、达观数据、云扩科技、艺赛旗、阿里云等<br>国外及世界领先的厂商：UiPath(免费社区版)、Blue Prism、Automation Anywhere</p><p>虽然国际RPA依旧扮演领导者和行业的规则的制定者，但是在各种新技术与RPA融合进程中，以及在生态建设成为RPA厂商主要竞争力的主流打法上，国产RPA并没有落后。甚至在一些方面，已经超越某些国外厂商。</p><p>可以通过近几年的融资金额和市场估值可以看出国产RPA也在蓬勃发展。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618313802380.png" alt="2020年融资"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618314424625.png" alt="近五年的投资事件"></p><h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p><a href="https://zhuanlan.zhihu.com/p/275757075">https://zhuanlan.zhihu.com/p/275757075</a></p><h3 id="UiPath"><a href="#UiPath" class="headerlink" title="UiPath"></a>UiPath</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618316991750.png" alt="UiPath服务器平台三层逻辑"></p><p>1）表示层<br>数据REST API端点<br>通知API<br>Web应用程序<br>2）Web服务层xiac<br>业务逻辑实现（下层为单个任务节点的实现提供服务，上层是bot根据任务队列，任务组成等多因素来控制任务执行）<br>3）持久层<br>弹性搜索<br>SQL服务器</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618317691754.png" alt="设计框架"></p><ol><li>开发人员在UiPath Studio中构建流程</li><li>使用Development Orchestrator和Quality Assurance Qrcheestrator对其进行测试；完成后，他们将工作流（未打包）签入uiatph中主UiProcess Library文件夹（在VCS上）</li><li>将工作流封装，并保存到QA，为本机专有使用</li><li>如果在测试期间发现任何问题，则重复上述步骤。</li><li>一旦所有的QA测试都通过了，包就被复制到生产环境（P包）</li><li>生产过程正在进行，由生产机器人运行</li></ol><ul><li><p>UiPath由studio（开发工具），Orchestrator（自动化云平台和监控平台），robot（运行已开发的机器人服务）组成</p></li><li><p>Robot分为Front Office Robot和Back Office Robot.缩写分别为FOR和BOR。 FOR需要手工启动。</p></li><li><p>BOR需要配合Orchestrator启动。</p></li><li><p>现在又分别叫Attended和Unattended：</p></li><li><p>Attended要有人照看，不能在电脑锁屏的状态下运行自动工作流</p></li><li><p>Unattended不用人工照看，可以在电脑锁屏的状态下运行自动工作流，由Orchestrator远程执行</p></li></ul><blockquote><p>Invokes Repository 调用（调用存储库）==公用部分，被多方调用 #00BCD4==<br>Reusable Code Library 可重用代码库</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618320047098.png" alt="新版设计框架"></p><ul><li>提供免费社区版</li><li>产品线丰富，拓展了AI、process mining方面的能力</li><li>它提供了多种托管选项，例如云环境，虚拟机和终端服务</li><li>它支持各种Web和桌面应用程序</li><li>它支持自动登录功能来运行机器人</li><li>它包括可与 .Net，Java，Flash，PDF，Legacy，SAP配合使用的抓取解决方案，且准确性最高</li></ul><h3 id="阿里云RPA"><a href="#阿里云RPA" class="headerlink" title="阿里云RPA"></a>阿里云RPA</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618321774264.png" alt="流程编辑器"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618323038585.png" alt="整体结构"></p><p>阿里云RPA4.0采用主流C/S架构模式，前端客户端采用.net平台，基于Windows系统具有自主研发的SDK及各项功能，后端服务端采用Linux（CentOS）操作系统，提供各类后台服务和组件。</p><ul><li>对接阿里达摩院，NLP、OCR等人工智能能力深度整合，让机器人更智能</li><li>拥有丰富的SDK自动化模块，支持自定义SDK库</li><li>阿里云统一售后支持体系</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618323129695.png" alt="场景"></p><h3 id="实在智能-章鱼数字员工"><a href="#实在智能-章鱼数字员工" class="headerlink" title="实在智能-章鱼数字员工"></a>实在智能-章鱼数字员工</h3><p>解决问题：<br>    - 用户可以根据自身需求指定AI套件<br>    - 通用AI能力精度不足</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021415/1618463061303.png" alt="AaaS架构"></p><ol><li>RPA与算法平台进行无缝衔接</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021415/1618463296265.png" alt="与算法平台衔接"></p><p>【视频–实在智能】</p><ol start="2"><li>集群以及AI定制</li></ol><blockquote><p>不同的系统对于计算能力，内容，硬盘以及网络的要求是不同的，可以根据系统不同分集群部署，不如算法运行在GPU上，而小型数据中台选择数据库服务器集群等；同时用户可以根据自身要求，选择算法和算法服务集群。</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021415/1618463370738.png" alt="根据用户需求定制"></p><ol start="3"><li>算法开发训练</li></ol><blockquote><p>集成传统BPA的优势，为当前业务提供更加精确的算法</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021415/1618463186299.png" alt="算法开发训练"></p><p><strong>产品优势：</strong></p><blockquote><p>北斗****<br>1.传统的无锚点拾取，只能在简单场景<br>2.当页面中出现相同元素时通过附近元素进行判断并标识,选择不当容易导致流程失败<br>3.完全无感知的自动锚点选择，通过step-of-out图神经网络技术学习页面上的拓扑关系</p></blockquote><blockquote><p>神盾<br>通过监控流程，如果发生异常，则通过北斗自动修复元素来修正自动流程</p></blockquote><p><a href="https://mp.weixin.qq.com/s?__biz=MzI2NjE2NjQ0Ng==&mid=2247484934&idx=1&sn=d7d105996c81ac9af8a5567a6db799aa&chksm=ea930fc7dde486d137d60d0a013db9d2f7390c0b3876da95a47ef8b0f17857fbab6fa40bd17b&scene=21#wechat_redirect">开源框架</a></p><blockquote><p>魔镜</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021415/1618464900207.png" alt="自动化开发"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021415/1618464926504.png" alt="魔镜"></p><p>  目前各大公司对于RPA的使用多处于RPA2.0-RPA3.0之间，即需要RPA开发者介于，而魔镜这种通过视频与日志结合的开发模式将很大程度降低客户使用成本。</p><h3 id="框架总结"><a href="#框架总结" class="headerlink" title="框架总结"></a>框架总结</h3><p>RPA解决方案是依托于各类先进信息技术手段的虚拟劳动力，根据预先设定的程序操作指令对任务进行自动化处理，实现业务流程由机器人自动化处理。</p><p><strong>RPA能做的</strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618320374905.png" alt="可以满足我们的"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618323364197.png" alt="新的行业标准"></p><ol><li>作为辅助甚至代替传统职工的工作软件，它需要员工的权限，但是却又脱离了系统的安全保障，这就造成了安全危机。<br>任子旭的对于网络安全和内部合规的提议：<br>对网络安全和内控合规的要求和约束时，主要是两个思路：<strong>遵从和自证清白</strong>。</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618320690337.png" alt="保障安全"></p><ol start="2"><li>作为一个辅助软件，本身高效性的前提是与相对应的工作量对照的，这就需要在配置时根据公司业务量来取舍，防止资源被浪费</li><li>虚拟化和环境一致性。整个项目的交付过程中，并没有那么简单。我们要考虑空间环境、系统环境、程序适用、版本兼容等多个因素。</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021413/1618320927712.png" alt="部署中的注意点"></p><h2 id="研究内容"><a href="#研究内容" class="headerlink" title="研究内容"></a>研究内容</h2><p>RPA到底可以发展到什么程度？</p><h3 id="可研究点"><a href="#可研究点" class="headerlink" title="可研究点"></a>可研究点</h3><h4 id="RPA-网络安全风险"><a href="#RPA-网络安全风险" class="headerlink" title="RPA 网络安全风险"></a>RPA 网络安全风险</h4><ol><li>滥用特权访问</li></ol><ul><li>攻击者可能能够危及机器人使用的管理员帐户。攻击者可以使用管理员帐户获得对敏感数据的访问权限</li><li>在离职之前，前员工可以编程机器人删除重要数据并中断业务流程</li></ul><ol start="2"><li>披露敏感数据</li></ol><ul><li>机器人开发人员可能会错误地编写BOT，以将高机密数据（例如信用卡信息）上传到公众通过Web访问的数据库。</li><li>机器人开发人员可以使用他或她的账户窃取业务其他服务信息</li></ul><ol start="3"><li>安全漏洞</li></ol><ul><li>虚拟机环境中可能存在安全漏洞，这是机器人运行的环境。</li><li>机器人开发人员编程机器人发送/接收敏感数据而不加密。此数据很脆弱，可以由攻击者利用</li></ul><ol start="4"><li>拒绝服务</li></ol><ul><li>一些不良的编程实践可以使机器人消耗所有虚拟机系统资源并导致虚拟机变得无响应，因此无法执行任何工作</li><li>虚拟机可能受到计划受到计划升级或网络维护的影响，可能导致中断损失。</li></ul><p><strong>应对策略</strong></p><ol><li>先进的职责分工，这就限制RPA用户只能执行分配给分配的任务，并且它们没有提升访问权限。同时也要限制代码开发人员与使用者的行为。</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021414/1618390329616.png" alt="主要RPA角色"></p><ol start="2"><li>数字身份认证和凭证的发放与验证，大部分黑客攻击都是在凭据被损害后发起的。为了避免这种情况，就需要设置机器人为最小的特权角色，那么机器人只能执行它的设计，并且其用户角色不能用于执行其他功能</li><li>数据加密，保证数据在传输过程前被加密，以及作业完成后删除。</li><li>监视日志并在内部控件损坏时执行审计，机器人活动可用于监测异常行为并进行审计，以防问题存在问题。</li><li>在发布生产代码之前，需要先扫描代码的漏洞，可以通过一些工具实现，Dynamic Application Security Testing (DAST) 【动态应用安全测试】and Fortify. </li></ol><h4 id="业务流程转型，RPA部署的效率、评估和解决方案"><a href="#业务流程转型，RPA部署的效率、评估和解决方案" class="headerlink" title="业务流程转型，RPA部署的效率、评估和解决方案"></a>业务流程转型，RPA部署的效率、评估和解决方案</h4><h4 id="对于其他功能的聚合，如应用控制，OCR-桌面自动化，中央管理等"><a href="#对于其他功能的聚合，如应用控制，OCR-桌面自动化，中央管理等" class="headerlink" title="对于其他功能的聚合，如应用控制，OCR,桌面自动化，中央管理等"></a>对于其他功能的聚合，如应用控制，OCR,桌面自动化，中央管理等</h4><h4 id="分区平台的共享服务必然会被需求较小的公司需求"><a href="#分区平台的共享服务必然会被需求较小的公司需求" class="headerlink" title="分区平台的共享服务必然会被需求较小的公司需求"></a>分区平台的共享服务必然会被需求较小的公司需求</h4><h4 id="跨平台的应用操作能力"><a href="#跨平台的应用操作能力" class="headerlink" title="跨平台的应用操作能力"></a>跨平台的应用操作能力</h4><h4 id="容器化"><a href="#容器化" class="headerlink" title="容器化"></a>容器化</h4><h4 id="RPA开发运维"><a href="#RPA开发运维" class="headerlink" title="RPA开发运维"></a>RPA开发运维</h4><p>从软件供应商转变为服务供应商<br>在共享服务中，自动化会变得极其慢，集群</p><h3 id="后期安排"><a href="#后期安排" class="headerlink" title="后期安排"></a>后期安排</h3><p>UiPath、tensorFlow</p>]]></content>
      
      
      <categories>
          
          <category> RPA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> RPA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-03-26【周总结】</title>
      <link href="/2021/03/24/2021-03-24%E3%80%90Week%E3%80%91/"/>
      <url>/2021/03/24/2021-03-24%E3%80%90Week%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="本周安排"><a href="#本周安排" class="headerlink" title="本周安排"></a>本周安排</h2><ul><li><input disabled="" type="checkbox"> MIT6.004课程完成</li><li><input checked="" disabled="" type="checkbox"> 学位英语</li><li><input disabled="" type="checkbox"> 继续查询项目依赖bug</li><li><input checked="" disabled="" type="checkbox"> 查询论文，并阅读总结两篇</li><li><input checked="" disabled="" type="checkbox"> openRPA实例实现</li></ul><h2 id="完成情况"><a href="#完成情况" class="headerlink" title="完成情况"></a>完成情况</h2><blockquote><p>主要精力放在学位英语上了，后期学习了部分MIT6003的课程，以及最后研究了openRPA的使用</p></blockquote><p><strong>论文方面</strong></p><pre><code>    与openRPA技术相关的论文还是没有查阅到，只是查阅了一些综述以及国内外对于RPA预测的推文，现在归纳了三个可研究点：</code></pre><ol><li>RPA机器人在运行时一般需要最高权限，这就可能引起黑客的攻击直接让过传统权限控制系统，通过直接攻击黑客来攻击系统</li><li>找到一个适合的场景，做RPA+AI，类似文本、语音、或者直接获取通讯记录来给RPA传输指令，这个研究点是目前比较常被提到的RPA4.0</li><li>RPA缺乏对于未知问题的解决能力，这个点预计很难研究，这是一个普遍问题</li></ol><p><strong>个人课程学习</strong></p><blockquote><p>空间技术课程提到一个“社会计算”，这个是杨老师他们大实验的学长有过研究就是给我们科普了一下，不过李波老师提到了他们大实验室有个好的idea就是搭建一个实验室的微服务系统，然后把每届的研究成果数据都放上去，以方便给后几届学弟学妹使用，老师我觉得我们实验室与师兄师姐交流太少了，而且他们也很忙几乎没有空和我们交流，这个idea也可以实现在我们实验室，对于学生提供了一个很好的学习见解。</p></blockquote><p><strong>公司方面</strong></p><blockquote><p>每周没有任务跟进，后期会对公司依赖bug进行查询补充</p></blockquote><h2 id="下周安排"><a href="#下周安排" class="headerlink" title="下周安排"></a>下周安排</h2><ul><li><input disabled="" type="checkbox"> 根据已经发现的RPA研究点中的第一个小点进行查阅论文并总结</li><li><input disabled="" type="checkbox"> 今天对openRPA进行了初步阅读，发现openRPA是C#的项目，本身没有学习过，会花两到三天进行学习C#语言，然后阅读源码</li><li><input disabled="" type="checkbox"> 继续学习MIT6003课程</li><li><input disabled="" type="checkbox"> 补充公司项目依赖部分bug</li><li><input disabled="" type="checkbox"> 每天尽量听会英语课程</li></ul>]]></content>
      
      
      <categories>
          
          <category> weekly report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021-3-19【周总结】</title>
      <link href="/2021/03/19/2021-3-19%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/"/>
      <url>/2021/03/19/2021-3-19%E3%80%90%E5%91%A8%E6%80%BB%E7%BB%93%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h2 id="本周安排"><a href="#本周安排" class="headerlink" title="本周安排"></a>本周安排</h2><ul><li><input checked="" disabled="" type="checkbox"> 熟悉OpenRPA框架</li><li><input checked="" disabled="" type="checkbox"> 通过代码实操学习对数据库的操作</li><li><input checked="" disabled="" type="checkbox"> 阅读相关论文–流程机器人+AI</li><li><input checked="" disabled="" type="checkbox"> 做网络安全课程PPT</li><li><input checked="" disabled="" type="checkbox"> 英语学习</li><li><input disabled="" type="checkbox"> 对比五个框架，并总结</li></ul><h2 id="后加入的任务"><a href="#后加入的任务" class="headerlink" title="后加入的任务"></a>后加入的任务</h2><ol><li>帮助公司接口优化整理项目依赖资料</li><li>完成部分公司项目依赖版本与最新版之间错误的总结</li></ol><h2 id="完成情况"><a href="#完成情况" class="headerlink" title="完成情况"></a>完成情况</h2><blockquote><p>本周主要主要精力集中于论文、学习实操了一些mabtis代码后面有花费了不到两天整合公司项目依赖相关材料,五个框架没有整理太多。</p></blockquote><p><strong>论文方面：</strong></p><pre><code>观看了为了“提出轻量级IT程序与自动化流程集成的规范化”的论文和The Forrester Wave™2018年发表的RPA总结汇报。</code></pre><p>1、第一篇中详细阐明RPA中的轻量IT的使用场景，规则以及与传统系统的区别，更加容易明白轻量IT在自动化流程中的作用，加深了对于RPA的理解—–只要有载体可以实现所有人的行为【可能一开始从五个框架入手，被局限于自动化测试了】<br>2、第二篇从报告中了解较为认可的15个成熟的框架，以及这个报告详细阐述了RPA评定的规则</p><p><strong>个人课程学习</strong></p><ul><li>加深了在小论文方面的学习</li><li>对于小论文的发表有了基本的概念，现在加强论文方面阅读，寻找该方向研究点</li></ul><p> <strong>公司方面</strong></p><ul><li>主要参与负责总结公司项目依赖版本以及总结公司当前版本的无法修补的bug情况。前期基本完成，后期由于工作量比较大，完成了部分，我问了实验室其它人，他们说好像优化完成了，涛总也没问过我了，后期的bug调研就没有跟进了</li></ul><h2 id="下周安排"><a href="#下周安排" class="headerlink" title="下周安排"></a>下周安排</h2><ol><li>先将2018的年度关于RPA总结报告看完，理解RPA的评定规范</li><li>详细阅读OpenRPA源码，总结优缺点</li><li>查询与RPA相关的AI算法，扩展学习</li><li>将英语学习提上日常，每天背后单词，练下口语</li><li>不能放下代码能力，依旧进行少量代码实操</li></ol>]]></content>
      
      
      <categories>
          
          <category> weekly report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> study </tag>
            
            <tag> weekly </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>五个RPA框架通读</title>
      <link href="/2021/02/22/%E4%BA%94%E4%B8%AARPA%E6%A1%86%E6%9E%B6%E9%80%9A%E8%AF%BB/"/>
      <url>/2021/02/22/%E4%BA%94%E4%B8%AARPA%E6%A1%86%E6%9E%B6%E9%80%9A%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="Robot-Framework"><a href="#Robot-Framework" class="headerlink" title="Robot Framework"></a>Robot Framework</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul><li>接受测试驱动开发（ATDD），行为驱动开发（BDD）和机器人流程自动化（RPA）</li><li><a href="https://robotframework.org/#examples">社区</a></li></ul><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><blockquote><p>Robot Framework的环境搭建</p></blockquote><ol><li>安装wxpython需要安装wheel，不然无法打包安装======</li><li>需要安装与chrome版本匹配的driver到目录中</li></ol><h3 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h3><ol><li>通过代码来进行生产</li></ol><ul><li>项目组成</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202136/1615015210514.png" alt="项目组成"></p><blockquote><p>项目见压缩文件—项目一，下面是robot的代码结构组成</p></blockquote><p><a href="https://github.com/robotframework/QuickStartGuide/blob/master/QuickStart.rst#executing-this-guide">参考文档</a></p><p>robot核心结构是由三部分组成的，一个是keywords的依赖，第二个是关键字，最后则是执行动作</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202136/1615015362634.png" alt="robot结构"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202136/1615015469911.png" alt="关键字组成"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202136/1615015588995.png" alt="动作"></p><p>运行效果，打包视频-robot1【视频总一个robot执行了两动作，所以结果都是两个】</p><p><img src="./videos/robot1.mkv" alt="robot1"></p><ol start="2"><li>通过较为成熟的工具–robocorp Lab</li></ol><p>==此工具可以实现的，robot framework都可以实验 #009688==</p><ul><li>结构组成</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202136/1615016378239.png" alt="项目结构"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202136/1615016399861.png" alt="robot结构"></p><ul><li>较为简单的栗子，自动打开浏览器然后访问url</li></ul><p><img src="./videos/robocorp1.mkv" alt="robocorp1"></p><ul><li>另一个栗子，登录功能的测试</li></ul><p><img src="./videos/robocorp2.mkv" alt="robocorp2"></p><blockquote><p>总结：和邹瑞进行过交流确实这个框架确实可以提升测试效率，由于执行动作可以通过传参来改变动作执行对象，所以可重复度明显提升，目前没有感觉到人工智能的应用点，下步继续了解。</p></blockquote><h2 id="TagUI"><a href="#TagUI" class="headerlink" title="TagUI"></a>TagUI</h2><h3 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h3><pre><code>    就是传统的，较为灵活但是复用性低；这个框架可以控制鼠标模拟动作    </code></pre><p><img src="https://gitee.com/merlynr/img-store/raw/master/202136/1615018851173.png" alt="代码结构"></p><h3 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h3><ol><li><p>访问网站并截图</p><p> <img src="https://gitee.com/merlynr/img-store/raw/master/202136/1615019129522.png" alt="源码"></p></li></ol><p><img src="./videos/tagui_1.mkv" alt="tagui_1"></p><p>==tagui在模拟人的行为上确实比robot framework #00BCD4==</p><ol start="2"><li>访问github上项目并下载等待完成</li></ol><p><img src="./videos/tagui_2.mkv" alt="tagui_2"></p><ol start="3"><li>可以通过表格来设置参数，高重复性</li></ol><p>  <img src="./videos/tagui_3.mkv" alt="tagui_3"></p><pre><code>      还有一些官方也提到可以获取数控中数据来进行测试，也可以通过中文命令来测试等</code></pre><h2 id="UI-Vision"><a href="#UI-Vision" class="headerlink" title="UI.Vision"></a>UI.Vision</h2><blockquote><p>有两个，一个是浏览器插件，另一个是桌面版。桌面版适用于手机上app的测试【没有进行实验】</p></blockquote><p><img src="./videos/2021-03-06_17-29-08.mkv" alt="2021-03-06 17-29-08"></p><p>总结：很傻瓜式，所有动作需要一模一样，否则无法找到指定的属性来换参，前面有一点不一样，后面将可能无法执行。</p><h2 id="open-RPA"><a href="#open-RPA" class="headerlink" title="open RPA"></a>open RPA</h2><p><a href="https://open-rpa.readthedocs.io/en/latest/">https://open-rpa.readthedocs.io/en/latest/</a></p><p><a href="https://docs.openiap.io/">https://docs.openiap.io/</a></p>]]></content>
      
      
      <categories>
          
          <category> RPA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> RPA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式开发---消息机制</title>
      <link href="/2021/02/01/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BC%80%E5%8F%91---%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6/"/>
      <url>/2021/02/01/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BC%80%E5%8F%91---%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="学习安排"><a href="#学习安排" class="headerlink" title="学习安排"></a>学习安排</h2><ol><li>理解目前微服务中消息机制的工作原理</li><li>了解消息服务生产时的机制</li><li>总结当前较为成熟的框架，即当前使用的使用程度</li><li>对比当前几大消息机制框架</li></ol><h2 id="学习关键内容记录"><a href="#学习关键内容记录" class="headerlink" title="学习关键内容记录"></a>学习关键内容记录</h2><h3 id="理解目前微服务中消息机制的工作原理"><a href="#理解目前微服务中消息机制的工作原理" class="headerlink" title="理解目前微服务中消息机制的工作原理"></a>理解目前微服务中消息机制的工作原理</h3><h4 id="基本架构的理解"><a href="#基本架构的理解" class="headerlink" title="基本架构的理解"></a>基本架构的理解</h4><p><a href="https://segmentfault.com/a/1190000019411260">source</a></p><blockquote><p>消息机制主要分为同步架构和异步架构</p></blockquote><ol><li><p>同步架构</p><p><strong>是指从请求的发起一直到最终的处理完成期间，请求的调用方一直在同步阻塞等待调用的处理完成。期间消息服务处于阻塞状态，只能等待当前事务处理完成。</strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614450258790.png" alt="同步调用"></p><pre><code>如图没产生一个消息都会通过中间服务一次传递然后等待消费者接收，并最后返回处理响应。</code></pre></li><li><p>异步架构</p><p><strong>指在请求发起的处理过程中，客户端的代码已经返回了，它可以继续进行自己的后续操作，而不需要等待调用处理完成，这就叫做异步调用。</strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614450508273.png" alt="异步调用"></p><pre><code>异步框架中，消息生产者无需等待消息处理结果返回，只需将消息传输到指定队列中即可，期间也不会发生阻塞。在这个过程中，客户端的调用，也就是应用程序的调用，和业务逻辑真正发送邮件的操作是不同步的。</code></pre></li></ol><blockquote><p>主要组成部分：消息生产者、消息消费者、分布式消息队列</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614450706484.png" alt="异步调用框架组成"></p><p><font color="#A47D13">注意：</font></p><ul><li>消息队列实现的方法有好多种，可以用共享文件夹，也可以用关系数据库或者NoSQL系统，当然最主要的还是使用专门的分布式消息队列服务器来实现。</li><li>消息的消费者不需要知道生产者存在，它只依赖消息队列中的消息。</li></ul><blockquote><p>主要模型：点对点模型和发布订阅模型。</p></blockquote><ul><li>点对点模型：主要用于一些耗时较长的、逻辑相对独立的业务。</li><li>发布订阅模型：根据使用场景给用户提供主题订阅，提供特点业务。</li></ul><h4 id="消息队列的好处"><a href="#消息队列的好处" class="headerlink" title="消息队列的好处"></a>消息队列的好处</h4><ol><li>实现异步处理，提升处理性能</li><li>可以让系统获得更好的伸缩性</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614451922193.png" alt="伸缩性"></p><pre><code>可以通过增加队列来提高负载    </code></pre><ol start="3"><li>可以平衡流量峰值，削峰填谷</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614451962482.png" alt="削峰填谷"></p><pre><code>使用消息队列，即便是访问流量持续的增长，系统依然可以持续地接收请求。</code></pre><ol start="4"><li><p>失败隔离和自我修复</p><pre><code> 因为发布者不直接依赖消费者，所以分布式消息队列可以将消费者系统产生的错误异常与生产者系统隔离开来，生产者不受消费者失败的影响。 当在消息消费过程中出现处理逻辑失败的时候，这个错误只会影响到消费者自身，而不会传递给消息的生产者，也就是应用程序可以按照原来的处理逻辑继续执行。 所以，这也就意味着在任何时候都可以对后端的服务器执行维护和发布操作。可以重启、添加或删除服务器，而不影响生产者的可用性，这样简化了部署和服务器管理的难度。</code></pre></li><li><p>可以使生产者和消费者的代码实现解耦合</p></li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614452072670.png" alt="解耦"></p><h3 id="消息服务详细运行机制"><a href="#消息服务详细运行机制" class="headerlink" title="消息服务详细运行机制"></a>消息服务详细运行机制</h3><pre><code>    消息服务主要用于异步处理，应用解耦，流量削锋和消息通讯四个场景。</code></pre><blockquote><p>异步处理</p></blockquote><p><font color="#011E47">应对场景：</font>避免因网络问题或者用户主观问题，消息未能及时得到处理而丢失的问题</p><p><strong>传统两种做法</strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614485333157.png" alt="串行方式"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614485380154.png" alt="并行方式"></p><p><em>与串行的差别是，并行的方式可以提高处理的时间。</em></p><blockquote><p>应用解耦</p></blockquote><p><font color="#011E47">应对场景：</font></p><ul><li>传统模式下，消息的分发都集成在服务端，一旦系统错误，消息都将配发失败</li><li>与服务端耦合</li></ul><blockquote><p>流量削峰</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614492372088.png" alt="削峰"></p><pre><code>秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。</code></pre><blockquote><p>日志处理</p></blockquote><pre><code>指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。</code></pre><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614492539873.png" alt="新浪kafka日志处理"></p><ol><li>Kafka：接收用户日志的消息队列。</li><li>Logstash：做日志解析，统一成JSON输出给Elasticsearch。</li><li>Elasticsearch：实时日志分析服务的核心技术，一个schemaless，实时的数据存储服务，通过index组织数据，兼具强大的搜索和统计功能。</li><li>Kibana：基于Elasticsearch的数据可视化组件，超强的数据可视化能力是众多公司选择ELK stack的重要原因。</li></ol><blockquote><p>消息通讯</p></blockquote><pre><code>☞消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。</code></pre><ul><li>点对点通讯</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614492613488.png" alt="点对点通讯"></p><ul><li>聊天室通讯</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614492657622.png" alt="聊天室通讯"></p><h3 id="主要框架"><a href="#主要框架" class="headerlink" title="主要框架"></a>主要框架</h3><p><a href="https://segmentfault.com/a/1190000019411260">source</a></p><blockquote><p>RabbitMQ 、ActiveMQ、RocketMQ 、Kafka</p></blockquote><ol><li>RabbitMQ 的主要特点是性能好，社区活跃，但是RabbitMQ用Erlang开发，我们的应用很少用Erlang，所以不便于二次开发和维护。</li><li>ActiveMQ 影响比较广泛，可以跨平台，使用Java开发，对Java比较友好。</li><li>RocketMQ 是阿里推出的一个开源产品，也是使用Java开发，性能比较好，可靠性也比较高。</li><li>Kafka 是LinkedIn出品的，专门针对分布式场景进行了优化，因此分布式的伸缩性会比较好。</li></ol><blockquote><p>目前看来，Kafka因为最初设计时就是针对互联网的分布式、高可用应用场景而设计，并且在大数据领域得到广泛支持，资料文档更加完善，因此在互联网企业得到更多的应用。</p></blockquote><h3 id="五个主流框架"><a href="#五个主流框架" class="headerlink" title="五个主流框架"></a>五个主流框架</h3><p><a href="https://cloud.tencent.com/developer/article/1449951">多维度对比5款主流分布式MQ消息队列</a></p><ol><li><p>Kafka</p><pre><code> Kafka作为时下最流行的开源消息系统，被广泛地应用在数据缓冲、异步通信、汇集日志、系统解耦等方面。相比较于RocketMQ等其他常见消息系统，Kafka在保障了大部分功能特性的同时，还提供了超一流的读写性能。 Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下： 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输。 支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输。 同时支持离线数据处理和实时数据处理。 Scale out：支持在线水平扩展。 很明显的看出Kafka的性能远超RabbitMQ。不过这也是理所当然的，毕竟2个消息队列实现的协议是不一样的，处理消息的场景也大有不同。 *RabbitMQ适合处理一些数据严谨的消息，比如说支付消息，社交消息等不能丢失的数据。Kafka是批量操作切不报证数据是否能完整的到达消费者端，所以适合一些大量的营销消息的场景。*</code></pre></li><li><p>RabbitMQ</p><pre><code> RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。 它支持开放的高级消息队列协议 (AMQP，Advanced Message Queuing Protocol)，从根本上避免了生产厂商的封闭，使用任何语言的各种客户都可以从中受益。这种协议提供了相当复杂的消息传输模式，所以基本上不需要MassTransit或NServiceBus的配合。它还具有“企业级”的适应性和稳定性。这些东西对我的客户来说十分的有吸引力。 </code></pre></li><li><p>ZeroMQ</p><pre><code> ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。跟其它几个接受测试的产品不同，你不需要安装和运行一个消息服务器，或中间件。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。非常有趣的是，他们也同样使用这方式在任何利用ZeroMQ进行强大的进程内通信的语言里创建Erlang风格的这种执行角色。ZeroMQ和其它的不是一个级别。它的性能惊人的高。公平的说，ZeroMQ跟其它几个比起来像头巨兽，尽管这样，结论很清楚：如果你希望一个应用程序发送消息越快越好，你选择ZeroMQ。当你不太在意偶然会丢失某些消息的情况下更有价值。其中，Twitter的Storm中使用ZeroMQ作为数据流的传输。 </code></pre></li><li><p>ActiceMQ</p><pre><code> Java世界的中坚力量。基于JMS协议。它有很长的历史，而且被广泛的使用。它还是跨平台的，给那些非微软平台的产品提供了一个天然的集成接入点。然而，它只有跑过了MSMQ才有可能被考虑。 ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。 </code></pre></li><li><p>Jafka</p><pre><code> Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。</code></pre></li></ol><h2 id="扩展学习"><a href="#扩展学习" class="headerlink" title="扩展学习"></a>扩展学习</h2><h3 id="JMS消息服务"><a href="#JMS消息服务" class="headerlink" title="JMS消息服务"></a>JMS消息服务</h3><h4 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h4><h4 id="JMS编程模型"><a href="#JMS编程模型" class="headerlink" title="JMS编程模型"></a>JMS编程模型</h4><pre><code>JMS（JAVA Message Service,java消息服务）API是一个消息服务的标准/规范，允许应用程序组件基于JavaEE平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。同样也是两种基本通信模式：点对点（Point-to-Point Messaging Domain），发布/订阅模式（Publish/Subscribe Messaging Domain）。</code></pre><blockquote><p>P2P模式</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614493377889.png" alt="P2P"></p><pre><code>P2P模式包含三个角色：消息队列（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。</code></pre><p><strong>特点：</strong></p><ul><li>每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)</li><li>发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列</li><li>接收者在成功接收消息之后需向队列应答成功</li></ul><blockquote><p>发布/订阅模式</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614493982534.png" alt="Pub/sub模式"></p><pre><code>包含三个角色主题（Topic），发布者（Publisher），订阅者（Subscriber） 。多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。</code></pre><p><strong>特点：</strong></p><ul><li>每个消息可以有多个消费者；</li><li>发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息；</li><li>为了消费消息，订阅者必须保持运行的状态。（为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅，即使订阅者没有被激活（运行），它也能接收到发布者的消息。）</li></ul><p><font color=""></font></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/2021228/1614494208056.png" alt="JMS模型"></p><p><strong>组成</strong></p><ol><li>管理对象（Administered objects）-连接工厂（Connection Factories）和目的地（Destination）</li><li>连接对象（Connections）</li><li>会话（Sessions）</li><li>消息生产者（Message Producers）</li><li>消息消费者（Message Consumers）</li><li>消息监听者（Message Listeners）</li></ol><ul><li><p>ConnectionFactory<br>创建Connection对象的工厂，针对两种不同的jms消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。</p></li><li><p>Destination<br>Destination的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的Destination是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的Destination也是某个队列或主题（即消息来源）。<br>所以，Destination实际上就是两种类型的对象：Queue、Topic可以通过JNDI来查找Destination。</p></li><li><p>Connection<br>Connection表示在客户端和JMS系统之间建立的链接（对TCP/IP socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。</p></li><li><p>Session<br>Session是操作消息的接口。可以通过session创建生产者、消费者、消息等。Session提供了事务的功能。当需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分QueueSession和TopicSession。</p></li><li><p>消息的生产者<br>消息生产者由Session创建，并用于将消息发送到Destination。同样，消息生产者分两种类型：QueueSender和TopicPublisher。可以调用消息生产者的方法（send或publish方法）发送消息。</p></li><li><p>消息消费者<br>消息消费者由Session创建，用于接收被发送到Destination的消息。两种类型：QueueReceiver和TopicSubscriber。可分别通过session的createReceiver(Queue)或createSubscriber(Topic)来创建。当然，也可以session的creatDurableSubscriber方法来创建持久化的订阅者。</p></li><li><p>MessageListener<br>消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。</p><h3 id="MSMQ"><a href="#MSMQ" class="headerlink" title="MSMQ"></a>MSMQ</h3><p>  MSMQ是微软的产品里唯一被认为有价值的东西。对客户来说，如果MSMQ能证明可以应对这种任务，他们将选择使用它。关键是这个东西并不复杂，除了接收和发送，没有别的；它有一些硬性限制，比如最大消息体积是4MB。然而，通过和一些像MassTransit或NServiceBus这样的软件的连接，它完全可以解决这些问题。</p><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>  Redis是一个Key-Value的NoSQL数据库，开发维护很活跃，虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个<strong>轻量级的队列服务</strong>来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> weekly report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> study </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式复习-2</title>
      <link href="/2021/01/03/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%A4%8D%E4%B9%A0-2/"/>
      <url>/2021/01/03/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%A4%8D%E4%B9%A0-2/</url>
      
        <content type="html"><![CDATA[<h1 id="里氏替换原则（Liskov-Substitution-Principle，LSP）"><a href="#里氏替换原则（Liskov-Substitution-Principle，LSP）" class="headerlink" title="里氏替换原则（Liskov Substitution Principle，LSP）"></a>里氏替换原则（Liskov Substitution Principle，LSP）</h1><h2 id="爱恨纠葛的父子关系—继承"><a href="#爱恨纠葛的父子关系—继承" class="headerlink" title="爱恨纠葛的父子关系—继承"></a>爱恨纠葛的父子关系—继承</h2><p><strong>优点：</strong></p><ol><li>代码共享，减少创建类的工作量，每个子类都拥有父类的方法和属性；</li><li>提高代码的重用性；</li><li>子类可以形似父类，但又异于父类，“龙生龙，凤生凤，老鼠生来会打洞”是说子拥有父的“种”，“世界上没有两片完全相同的叶子”是指明子与父的不同；</li><li>提高代码的可扩展性，实现父类的方法就可以“为所欲为”了，君不见很多开源框架的扩展接口都是通过继承父类来完成的；</li><li>提高产品或项目的开放性</li></ol><p> <strong>缺点：</strong></p><ol><li> 继承是侵入性的。只要继承，就必须拥有父类的所有属性和方法；</li><li> 降低代码的灵活性。子类必须拥有父类的属性和方法，让子类自由的世界中多了些约束；</li><li> 增强了耦合性。当父类的常量、变量和方法被修改时，需要考虑子类的修改，而且在缺乏规范的环境下，这种修改可能带来非常糟糕的结果——大段的代码需要重构。</li></ol><blockquote><p>“利”大于弊，发挥利的最大作用。</p></blockquote><p><strong>What‘s mwan LSP?</strong><br>最正宗的定义：If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T,the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.（如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1都代换成o2时，程序P的行为没有发生变化，那么类型S是类型T的子类型。）<br>最清晰明确的：Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it.（所有引用基类的地方必须能透明地使用其子类的对象。）通俗点讲，<font color="#86AECE">只要父类能出现的地方子类就可以出现，而且替换为子类也不会产生任何错误或异常，使用者可能根本就不需要知道是父类还是子类。但是，反过来就不行了，有子类出现的地方，父类未必就能适应。</font></p>]]></content>
      
      
      <categories>
          
          <category> exam </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
            <tag> exam </tag>
            
            <tag> design-model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高级软件考试准备---研究生</title>
      <link href="/2021/01/03/%E9%AB%98%E7%BA%A7%E8%BD%AF%E4%BB%B6%E8%80%83%E8%AF%95%E5%87%86%E5%A4%87---%E7%A0%94%E7%A9%B6%E7%94%9F/"/>
      <url>/2021/01/03/%E9%AB%98%E7%BA%A7%E8%BD%AF%E4%BB%B6%E8%80%83%E8%AF%95%E5%87%86%E5%A4%87---%E7%A0%94%E7%A9%B6%E7%94%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="考试内容"><a href="#考试内容" class="headerlink" title="考试内容"></a>考试内容</h1><ol><li>面向对象</li></ol><ol start="2"><li>六大原则</li></ol><ul><li>单一职责原则</li><li>里氏替换原则</li><li>依赖倒置原则</li><li>接口隔离原则</li><li>迪米特法则</li><li>关闭原则</li></ul><ol start="3"><li>主讲了九个模式一个机制</li></ol><ul><li>策略</li><li>观察[主动or被动]</li><li>工厂，抽象工厂</li><li>装饰</li><li>建造</li><li>组合</li><li>外观</li><li>状态</li><li>适配</li><li>反射机制</li></ul><p><img src="https://gitee.com/merlynr/img-store/raw/master/202113/%E9%AB%98%E8%BD%AF%E5%A4%8D%E8%AF%95%E6%9D%90%E6%96%99.jpg" alt="往年考试题"></p><h1 id="分数占比分析"><a href="#分数占比分析" class="headerlink" title="分数占比分析"></a>分数占比分析</h1><blockquote><p>概念:模式设计 = 六四开<br><font color="red">抓好概念，模式设计这些言之有理即可</font></p></blockquote><h1 id="复习记录"><a href="#复习记录" class="headerlink" title="复习记录"></a>复习记录</h1><h2 id="程序设计方法基础"><a href="#程序设计方法基础" class="headerlink" title="程序设计方法基础"></a>程序设计方法基础</h2><ol><li>传统分层</li></ol><p>划分方式： 物理/逻辑<br>层数：两/三层</p><ol start="2"><li>逻辑上的三层结构</li></ol><ul><li>显示层View/UI（User Interface)</li><li>业务逻辑层BLL（Business Logic Layer）</li><li>数据访问层DAL（Data Access Layer）</li></ul><ol start="3"><li>原则，目的，优点</li></ol><p>分层访问<strong>原则</strong>：不可跨层进行访问、当前层只处理该职责的业务<br><strong>目的</strong>：隔离/解耦合<br><strong>优点</strong>：可维护性/扩展性/性能/安全性/</p><h2 id="面向对象方法的引入"><a href="#面向对象方法的引入" class="headerlink" title="面向对象方法的引入"></a>面向对象方法的引入</h2><ol><li>推广原因</li></ol><p><strong>为了解决块间的同名变量冲突，就会在编程中进行封装（保护）的尝试</strong>，对封装的进一步发展就提出了对象的概念，并增加了类，类继承的概念。、</p><ol start="2"><li>那么如何度量派生继承是良好的呢？</li></ol><p><strong>存在问题</strong>：代码的重用性和可扩展性都大大提升了，但是也带来了强耦合</p><blockquote><p><font color="#FF726A">LSP</font>：Liskov Substitution Principle<br>里氏原则可度量继承关系的质量，是面向对象的重要基石，该原则使得软件的功能扩展成为可能。</p></blockquote><ul><li>向下兼容思想【高版本可以打开低版本，子类可以透明替代父类，反之则否】</li></ul><p>如何满足向下兼容，且可扩展？<br>功能模块的<strong>可修改性</strong>，即程序中函数的调用不是在编译的时候确定，而是在运行时刻被确定的。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/202113/1609667788985.png" alt="虚函数"></p><p><em>c++的虚基类用在控制重复继承上，表示这个基类在实例化子类时只生成一个副本 java只能单继承，不存在重复继承</em></p><ol start="3"><li>面向对象的特性</li></ol><ul><li>抽象(Abstraction)</li><li>封装(Encapsulation)</li><li>继承派生(Inheritance)</li><li>多态(Polymorphism)</li><li>组合(Composition)</li></ul><ol start="4"><li>面向对象引入的目的</li></ol><ul><li>重用（Reuse：Inheritance &amp; composition）</li><li>统一接口（Unified interface）</li><li>适用变化（Adapt to Change of Request）</li></ul>]]></content>
      
      
      <categories>
          
          <category> exam </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
            <tag> exam </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式复习-1</title>
      <link href="/2020/12/28/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%A4%8D%E4%B9%A0-1/"/>
      <url>/2020/12/28/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%A4%8D%E4%B9%A0-1/</url>
      
        <content type="html"><![CDATA[<h1 id="辅助工具学习"><a href="#辅助工具学习" class="headerlink" title="辅助工具学习"></a>辅助工具学习</h1><h2 id="UML类图"><a href="#UML类图" class="headerlink" title="UML类图"></a>UML类图</h2><h3 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h3><p><a href="http://www.cleey.com/blog/single/id/873.html">源头</a></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609158745582.png" alt="栗子"></p><ol><li>车的类图结构为&lt;&gt;，表示车是一个抽象类； </li><li>它有两个继承类：小汽车和自行车；它们之间的关系为实现关系，使用 带空心箭头的虚线表示； </li><li>小汽车为与SUV之间也是继承关系，它们之间的关系为泛化关系，使用带空心箭头的实线表示； </li><li>小汽车与发动机之间是组合关系，使用带实心箭头的实线表示； </li><li>学生与班级之间是聚合关系，使用带空心箭头的实线表示； </li><li>学生与身份证之间为关联关系，使用一根实线表示； </li><li>学生上学需要用到自行车，与自行车是一种依赖关系，使用带箭头的虚线表示；</li></ol><h3 id="详细学习"><a href="#详细学习" class="headerlink" title="详细学习"></a>详细学习</h3><p> <strong>泛化关系(Generalization)</strong></p><blockquote><p>【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。</p></blockquote><p><em>继承关系为 is-a</em></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609159498467.png" alt="A继承自B"></p><pre><code>【代码体现】：表现为继承非抽象类</code></pre><p><strong>实现关系(Realization)</strong></p><blockquote><p>【实现关系】：是一种类与接口的关系，表示类是接口所有特征和行为的实现.</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609159705360.png" alt="实现关系表现为继承抽象类"></p><pre><code>【代码体现】：表现为继承抽象类</code></pre><p><strong>聚合关系(Aggregation)</strong></p><blockquote><p>【聚合关系】：是整体与部分的关系，且部分可以离开整体而单独存在。如车和轮胎是整体和部分的关系，轮胎离开车仍然可以存在。</p></blockquote><p>  <em>聚合关系是关联关系的一种，是强的关联关系；关联和聚合在语法上无法区分，必须考察具体的逻辑关系。【箭头及指向】：带空心菱形的实心线，菱形指向整体</em></p><p>  <img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609159862416.png" alt="表示A聚合到B上，或者说B由A组成"></p><p> <em>聚合关系用于表示实体对象之间的关系，表示整体由部分构成的语义；例如一个部门由多个员工组成；<br>与组合关系不同的是，整体和部分不是强依赖的，即使整体不存在了，部分仍然存在；例如， 部门撤销了，人员不会消失，他们依然存在</em></p><pre><code>【代码体现】：成员变量</code></pre><p><strong>组合关系(Composition)</strong></p><blockquote><p>【组合关系】：是整体与部分的关系，但部分不能离开整体而单独存在。如公司和部门是整体和部分的关系，没有公司就不存在部门。</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609159977459.png" alt="A组成B，或者B由A组成">  </p><pre><code>【代码体现】：成员变量</code></pre><p><strong>关联关系(Association)</strong></p><blockquote><p>【关联关系】：是一种拥有的关系，它使一个类知道另一个类的属性和方法。</p></blockquote><p><em>老师与学生，丈夫与妻子关联可以是双向的，也可以是单向的。双向的关联可以有两个箭头或者没有箭头，单向的关联有一个箭头。</em></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609160265231.png" alt="【箭头及指向】：指向被拥有者"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609160313507.png" alt="自身关联"></p><pre><code>【代码体现】：成员变量</code></pre><p><strong>依赖关系(Dependency)</strong></p><blockquote><p>【依赖关系】：是一种使用的关系，即一个类的实现需要另一个类的协助，所以要尽量不使用双向的互相依赖.</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609160418902.png" alt="【箭头及指向】：指向被使用者"></p><p><em>与关联关系不同的是，它是一种临时性的关系，通常在运行期间产生，并且随着运行时的变化； 依赖关系也可能发生变化；</em></p><p><font color="red">依赖也有方向，双向依赖是一种非常糟糕的结构，我们总是应该保持单向依赖，杜绝双向依赖的产生；</font></p><pre><code>【代码表现】： 局部变量、方法的参数或者对静态方法的调用</code></pre><h3 id="疑惑与解答"><a href="#疑惑与解答" class="headerlink" title="疑惑与解答"></a>疑惑与解答</h3><blockquote><p>问题来了小汽车是车的实现，那么SUV本身也是小汽车的实现呀，为何这归为泛化？</p></blockquote><p><strong>答：</strong> 泛化关系表现为继承非抽象类,(可以查看上边实现关系与泛化关系的定义)</p><h1 id="设计模式之禅"><a href="#设计模式之禅" class="headerlink" title="设计模式之禅"></a>设计模式之禅</h1><p><a href="https://gitee.com/merlynr/img-store/blob/d1481813922e92a8e297194f2c8176aab822be66/resource/e-book/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%A6%85%EF%BC%88%E7%AC%AC2%E7%89%88%EF%BC%89.pdf">感谢秦小波大佬的开阔前路</a></p><h2 id="大旗不挥，谁敢冲锋——6大设计原则全新解读"><a href="#大旗不挥，谁敢冲锋——6大设计原则全新解读" class="headerlink" title="大旗不挥，谁敢冲锋——6大设计原则全新解读"></a>大旗不挥，谁敢冲锋——6大设计原则全新解读</h2><h3 id="单一职责原则Single-Responsibility-Principle–SRP"><a href="#单一职责原则Single-Responsibility-Principle–SRP" class="headerlink" title="单一职责原则Single Responsibility Principle–SRP"></a>单一职责原则Single Responsibility Principle–SRP</h3><blockquote><p>单一职责原则的定义是：应该<font color="red">有且仅有一个</font>原因引起类的变更</p></blockquote><p><strong>SRP</strong> :There should never be more than one reason for a class to change.</p><p>文中作者举了个打电话的例子，电话通话的时候有4个过程发生：拨号、通话、回应、挂机四步骤。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609163346475.png" alt="电话类图"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609163496643.png" alt="代码清单"></p><p>这是目前比较正常的做法，面向接口编程。作者认为这个接口接近<em>完美</em> 但是却没有SRP，一个接口或者类只有一个原因引起变化。细谈打电话这个栗子，打电话这个接口不只一个职责，作者将其 分为两个，一个是底层数据交互时的<strong>协议管理</strong>，另一个是<strong>数据传输</strong>。dial()和hangup()两个方法实现的是协议管理，分别负责通过协议拨号接通和挂机；chat()实现的是数据的传送。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609163747222.png" alt="职责分明的电话类图"></p><p>于是根据SRP，实现了上图的设计。但是一个手机类要把ConnectionManager和DataTransfer组合在一块才能使用。<strong>组合</strong>是一种强耦合关系，你和我都有<strong>共同的生命期</strong>，这样的强耦合关系还不如使用接口实现的方式呢，而且还增加了类的复杂性，多了两个类。经过这样的思考后，我们再修改一下类图，如图。</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609164425134.png" alt="简洁清晰、职责分明的电话类图"></p><p>这个设计实现了一个类实现两个接口，把两个职责融合到一块。这个已经符合SRP，一个协议控制的责任，一个数据传输的协议，但是和我理解的不一样，为什么定义说的是类呢?，那么就需要重新理解了，<font color="red">什么是SRP呢？</font><br><font color="green">答:</font> 实现最小责任的面向接口编程。<font color="#86AECE">这里的接口只是因为我们现在编程的习惯将功能与接口相对应，所以我们也需要考虑类是否满足最小责任，甚至方法。。。</font>，这就需要我们将“责任”和“变化原因”纳入衡量接口或类的质量考量范畴了。</p><blockquote><p>与当前编程环境相结合：</p><ol><li>不可强行SRP，这样就会是很多功能被强行拆分，然后使用时通过大量聚合和组合耦合在一块，无疑增加了系统复杂性</li><li>国内各个公司普遍开发环境还是面向对象开发，即一个对象的所以动作，都抽象到一个接口中例如图1-1，但是我们已经尽可能的实现SRP，例如图1-2</li></ol></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609166170558.png" alt="图1-1"></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201228/1609166184445.png" alt="图1-2"></p>]]></content>
      
      
      <categories>
          
          <category> exam </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
            <tag> exam </tag>
            
            <tag> design-model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Towards developing a secure medical image sharing system based on zero trust principles and blockchain technology</title>
      <link href="/2020/12/24/Towards%20developing%20a%20secure%20medical%20image%20sharing%20system%20based%20on%20zero%20trust%20principles%20and%20blockchain%20technology/"/>
      <url>/2020/12/24/Towards%20developing%20a%20secure%20medical%20image%20sharing%20system%20based%20on%20zero%20trust%20principles%20and%20blockchain%20technology/</url>
      
        <content type="html"><![CDATA[<p><a href="https://gitee.com/merlynr/img-store/blob/d1481813922e92a8e297194f2c8176aab822be66/resource/paper/%E8%87%B4%E5%8A%9B%E4%BA%8E%E5%BC%80%E5%8F%91%E5%9F%BA%E4%BA%8E%E9%9B%B6%E4%BF%A1%E4%BB%BB%E5%8E%9F%E5%88%99%E5%92%8C%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E7%9A%84%E5%AE%89%E5%85%A8%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%85%B1%E4%BA%AB%E7%B3%BB%E7%BB%9F/paper.pdf">论文</a></p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ol><li>The traditional hospital network framework is very fragile in the era when it needs to be partially opened up.传统医院网络框架在现在需要部分开放的时代显得十分脆弱</li><li>Proper security measures have not been taken around the internal instruments of the hospital, they are easy to be manipulated and tampered with, and the data sources are extremely vulnerable to persecution.–医院内部仪器周围没有采取适当的安全措施，它们很容易被操控和篡改，数据源极易受到迫害。</li><li>Electronic medical records have become a trend to preserve the results of medical treatment, so it is necessary not only to ensure the safety of medical records, but also to ensure the security in the process of transmission.–电子病历已经成为一种保存治病结果的趋势，那么不仅要保障病历保存的安全，还要保证传输过程中的安全。</li></ol><p>Data security has been a critical topic of research and discussion since the onset of data sharing in e-health systems.The traditional hospital network mostly adopts the construction mode of multiple sets of network connection isolation, such as internal network, external network, intelligent private network and so on.The traditional hospital network architecture relies too much on physical isolation, with the popularity of electronic medical system, which requires its network to be partially open to the outside world, and the vulnerability of its network architecture is infinitely magnified, which can be easily broken by hackers.–传统医院网络架构过度依赖物理隔离，随着电子医疗系统普及，这就要求它的网络对外部分开放，它网络架构的脆弱性就被无限放大，黑客很容易就可以攻破。</p><h3 id="Preliminary-Knowledge"><a href="#Preliminary-Knowledge" class="headerlink" title="Preliminary Knowledge"></a>Preliminary Knowledge</h3><p><strong>Zero trust reference architecture</strong></p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201224/1608811874254.png" alt="零信任框架的关键能力模型"></p><p>零信任的本质是在访问主体和客体之间构建以身份为基石的动态可信访问控制体系，通过以身份为基石、业务安全访问、持续信任评估和动态访问控制的关键能力，基于对网络所有参与实体的数字身份，对默认不可信的所有访问请求进行加密、认证和强制授权，汇聚关联各种数据源进行持续信任评估，并根据信任的程度动态对权限进行调整，最终在访问主体和访问客体之间建立一种动态的信任关系。</p><h3 id="System-Model"><a href="#System-Model" class="headerlink" title="System Model"></a>System Model</h3><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201224/1608817000638.png" alt="Zero trust principles in the proposed model"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote><p>这篇论文是一个分享模型，只有被分享的人才可以看到文件。</p></blockquote><p>疑惑：如何实现多次分享，避免单个文件多次上传的做法！</p><p><a href="https://gitee.com/merlynr/img-store/blob/d1481813922e92a8e297194f2c8176aab822be66/resource/paper/%E8%87%B4%E5%8A%9B%E4%BA%8E%E5%BC%80%E5%8F%91%E5%9F%BA%E4%BA%8E%E9%9B%B6%E4%BF%A1%E4%BB%BB%E5%8E%9F%E5%88%99%E5%92%8C%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E7%9A%84%E5%AE%89%E5%85%A8%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%85%B1%E4%BA%AB%E7%B3%BB%E7%BB%9F/ppt.pptx">详细内容见PPT</a></p>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> paper </tag>
            
            <tag> block chain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Block chain transaction privacy protection method and system</title>
      <link href="/2020/11/10/Block%20chain%20transaction%20privacy%20protection%20method%20and%20system/"/>
      <url>/2020/11/10/Block%20chain%20transaction%20privacy%20protection%20method%20and%20system/</url>
      
        <content type="html"><![CDATA[<p><a href="https://patents.google.com/patent/WO2019080933A1/zh">https://patents.google.com/patent/WO2019080933A1/zh</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><ol><li>解决交易信息透明，造成隐私信息暴露</li><li>论文提出解决方案使用到了秘密共享方式，解决共谋问题</li><li>确保关键字安全性</li></ol><h4 id="预处理方法"><a href="#预处理方法" class="headerlink" title="预处理方法"></a>预处理方法</h4><ol><li>将层次属性加密与线性秘密共享相结合，提出了一种基于可搜索属性加密的区块链数据隐私保护控制方案，解决了传统区块链交易中的隐私暴露问题。</li><li>用户的访问控制由验证节点实现，避免了向区块链网络提交私钥和访问结构的安全风险。将私钥组件与区块链中用户节点的随机身份相关联可以解决共谋问题</li><li>授权用户可以通过可搜索的加密来快速搜索和监督交易信息。改进的算法确保了关键字的安全性。【算法应该看不懂】</li></ol><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ol><li><p>提出基于椭圆曲线加密算法m的更有效的盲签名混合方案—该方案简单易用，通常适用于各种数字货币，【但它是集中式货币方案】。</p><blockquote><p>传统公钥密码体制（密钥长度一般为512bit）随着计算机运算速度的提升，已经有被破解的趋势了，同时RSA运算效率较低。利用曲线上的有理点组成的Abel群《TODO》及其上离散对数问题求解的困难性构成一些公钥密码体制，即密钥的每个bit都具有最高的安全强度，椭圆曲线密码体制中160bit长的密钥所展示的安全强度相当于RSA的1024bit</p></blockquote></li><li><p>使用盲签名之类《TODO》的混合加密技术—区块链隐私保护机制【增加了技术成本，并且第三方实施令牌处理不可避免地增加了额外的服务开销】</p></li><li><p>提出了一种改进的基于环的秘密交易方案《TODO》</p><blockquote><p>在该方案中，大量的环签名被放置在可链接的自发匿名组签名的多层中，其解决方案可以保护身份隐私和交易隐私。尽管环签名提供了强大的匿名性，但它具有三个限制：产生交易数据较多，需要更多的记录的存储空间、签名的大小与参与者数量成正比，因此传统每个事务做了限制，每个事务有四个输出、隐藏的数量增加了检查的难度，即，它不仅验证交易期间是否生成了秘密加密货币，而且还确定了特定时刻的额外数量。</p></blockquote></li></ol><h3 id="初步知识"><a href="#初步知识" class="headerlink" title="初步知识"></a>初步知识</h3><h4 id="Bilinear-Mapping"><a href="#Bilinear-Mapping" class="headerlink" title="Bilinear Mapping"></a>Bilinear Mapping</h4><blockquote><p>双线性映射</p><blockquote><p>群</p><ol><li>封闭性——如果a和b都属于G，则a+b也属于G。</li><li>结合律——对于G中的任意元素a、b和c，都有（a+b）+c=a+（b+c）成立。</li><li>单位元——G中存在元素e，对于G中任意元素a，都有a+e=e+a=a成立。</li><li>逆元——对于G中任意元素a，G中都存在元素a’，使得a+a’=a’+a=e成立。G就叫作一个群，记为（G，+）</li><li>在群中定义求幂运算为重复使用群中的运算，如a^4 =a+a+a+a。规定a^0 =e为单位元。如果一个群的所有元素都是a的幂a^k，则称这个群是一个==循环群 #00BCD4==，这里的k是整数。a也被称为这个群的生成元。</li></ol></blockquote></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201223/1608734193371.png" alt="双线性映射"></p><p>设G1、G2都是阶为p的循环群，p是素数。如果映射e: G1 × G1 → G2 满足以下性质：</p><ol><li>双线性性。<br>对于任意a，b∈Z<sub>p</sub>和R，S∈G1，有e(R<sup>a</sup>, S<sup>b</sup>) = e(R, S)<sup>ab<sup>；</li><li>非退化性。<br>存在R，S∈G<sub>1</sub>，使得e(R, S) ≠ 1<sub>G2</sub>。这里1<sub>G2</sub>代表G2群的单位元；</li><li>可计算性。<br>存在有效的算法对任意的R，S∈G<sub>1</sub>，计算e(R, S)的值。<br>那么称<strong>e</strong>是一个<strong>双线性映射</strong>。</li></ol><h4 id="Determining-the-Bilinear-Diffie–"><a href="#Determining-the-Bilinear-Diffie–" class="headerlink" title="Determining the Bilinear Diffie–"></a>Determining the Bilinear Diffie–</h4><p>ellman Assumption (DBDH)</p><blockquote><p>确定双线性参数生产区的假设（DBDH）</p></blockquote><p>选择一个G1的生成器，设a,b,c,r属于（1，q-1）中任意质数，当g^a,g^b,g^c,g^r属于G1，e(g,g)<sup>abc</sup>和e(g,g)<sup>r</sup>属于G2,判断<strong>e(g,g)<sup>abc</sup>和e(g,g)<sup>r</sup>是否相等</strong></p><p><strong>判断条件：</strong><br>对于任意多项式概率时间算法的对手A，解决决策双线性Diffie-Hellman（DBDH）假设[i]的优势定义为</p><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201223/1608734247064.png" alt="DBDH判断条件"></p><p>如果确定的值Adv<sup>DBDH</sup><sub> A</sub>可忽略不计，则将建立决策双线性Diffie-Hellman假设。</p><h4 id="Lsss-Linear-Secret-Sharing-Scheme"><a href="#Lsss-Linear-Secret-Sharing-Scheme" class="headerlink" title="Lsss Linear Secret Sharing Scheme"></a>Lsss Linear Secret Sharing Scheme</h4><blockquote><p>Lsss线性秘密共享方案【是对密钥的管理策略】</p></blockquote><p><a href="https://zhuanlan.zhihu.com/p/95362628">有趣的栗子</a></p><p>在信息系统中使用的秘密共享，可以防止系统密钥的遗失、损坏和来自地方的攻击，减小秘密保存者的责任。在(t,n)秘密共享体制中，秘密分发者将一个秘密信息分成n个秘密份额，分发给n 个人，当需要恢复秘密信息时，任意少于t个的秘密保存者都得不到该秘密的任何信息。<br>现目前进行秘密共享的主流方案有基于访问控制树和秘密共享矩阵的。基于访问控制树进行秘密分享时，通过门限控制进行合理的多项式构造，最终将秘密分享给树的每一个子节点。</p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><h4 id="系统模型"><a href="#系统模型" class="headerlink" title="系统模型"></a>系统模型</h4><blockquote><p>基于可搜索属性加密的区块链数据隐私访问控制系统模型如图</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201223/1608734364209.png" alt="基于可搜索属性加密的区块链数据隐私访问控制系统模型"></p><blockquote><p>包含的四个实体</p></blockquote><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201223/1608734388573.png" alt="四个实体"></p><ol><li>数据所有者：首先进行初始化，生成索引密钥和陷门密钥，提取交易的关键词，然后使用索引密钥对索引进行加密，形成索引密文；其次，对陷门密钥进行加密以形成陷门密钥密文并共享数据。最后，使用安全签名算法对交易进行签名并加密，同时，数据所有者将索引关键字附加到交易密文的密文文件中。最重要的是，数据所有者可以是区块链上进行比特币交易的用户或矿工。</li><li>用户：注册系统生成与真实身份相对应的身份标识符RID和与用户属性相对应的私钥。另外，用户解密陷门密文并使用 用户密钥以生成陷门，然后发送区块链以请求交易密文。</li><li>验证节点：验证用户身份和权限的正确性，并在属性集合中计算用户的属性和私钥参数以及权限参数，以分发陷密钥密文，并将用户密钥UK分发给合法用户。</li><li>矿工节点：矿工节点在此期间广播所有交易信息，每个节点执行验证并在验证后加入区块链。计算并匹配数据所有者发送的陷门和索引，然后在匹配成功后将交易密文发送到数据使用方。</li></ol><h4 id="威胁模式"><a href="#威胁模式" class="headerlink" title="威胁模式"></a>威胁模式</h4><p><strong>前提：</strong> 只有“验证节点”是完全可信的，私钥能正常生成和分发给用户。大多数矿工节点半诚实【不破坏协议，根据规则可以推测用户信息】。此外，用户可能会合谋解密他们无法访问的数据。</p><h4 id="安全模型"><a href="#安全模型" class="headerlink" title="安全模型"></a>安全模型</h4><p><strong>安全模型是指对手与挑战者之间的博弈。</strong></p><ol><li>IND-CPA security model【Indistinguishability under chosen-plaintext attack】</li></ol><blockquote><p>选择明文攻击。可理解为攻击者拥有加密机的使用权限，可以加密自己想加密的任何明文。攻击目的：由明文和对应的密文来分析和推断加密算法的信息，主要是加密密钥。</p></blockquote><ul><li>初始化：挑战者A使用初始化算法生成公共参数和主密钥【重复使用的密钥，对称密钥】，并将主密钥发送给对手C。—-<em>每次通信只使用一次的密钥称为会话密钥（session key）。相对于会话密钥，重复使用的密钥称为主密钥（master key）。</em></li><li>第一步：对手C重复尝试一组属性S1-Sq，但是没有属性满足访问</li><li>挑战：对手C选择两条消息M0; M1并将它们发送给挑战者A。挑战者A选择0或者1，和加密的访问结构的消息M，并将密文发送给对手C</li><li>第二步：</li></ul><ol start="2"><li>IND-CKA security model</li></ol><blockquote><p>关键字攻击</p></blockquote><h3 id="具体结构即功能实现"><a href="#具体结构即功能实现" class="headerlink" title="具体结构即功能实现"></a>具体结构即功能实现</h3><h4 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h4><p>用户向系统提交注册申请，获取真实身份信息对应的身份RID和用户属性集，数据所有者（交易用户）进行注册获取密钥和身份标识。</p><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p><a href="https://blog.csdn.net/zhangwenjiezw886/article/details/51006774">双线性</a></p><ol><li>数据拥有者:：选择一个以质数为序的群G<sub>0</sub>,用元素g(单位元)生成群，在限制字段中选择N个元素(N为阶)，并使用系统属性形成系统属性集S，并根据属性之间的相关性来确定S中的属性。S被分为x个树，H<sub>i</sub>被设置为i个树的深度，H为树中最大深度；随机选择向量U=(U<sub>y</sub>)<sub>1=&lt;x=&lt;y</sub>和U’=(U’<sub>y’</sub>)<sub>1=&lt;x‘=&lt;y’</sub>，u<sub>y</sub>代表与y属性树相对应的public参数，数据所有者选择素数p的序列，并生成群G<sub>1</sub>,H<sub>1</sub>。数据拥有者选择两个随机数η(姨塔)，μ(谬)，然后计算生成公钥PK={g,g<sup>μ</sup>}和私钥SK=η代表陷门。</li><li>验证结点：Z<sup>*</sup><sub>p</sub>在有限域中用p-基元表达一组元素，从中选择两个大小不同的随机数α，β，验证结点通过计算PK={G<sub>0</sub>,g,g<sup>β</sup>,Y=e(g,g)<sup>α</sup>,U,U’}和MK={α，β}来定义一个双线性图e:G<sub>0</sub>xG<sub>0</sub>=G<sub>1</sub>。</li><li>交易生成和签名：交易用户A生成交易信息，通过钱包签名算法对自身身份进行加密，并使用钱包地址对应的私钥对其签名，然后发送给交易用户B。签名的算法如下()：</li></ol><p><img src="https://gitee.com/merlynr/img-store/raw/master/20201223/1608734446144.png" alt="签名算法"></p><blockquote><p>Trans:交易信息、<br>δ A为用户自身加密后的信息即用于标识、<br>CT<sub>A</sub>（Ciphertext密文）私钥加密产生签名</p></blockquote><ol start="4"><li>产生索引：交易者从交易明文信息中提取关键字，并用索引密钥g<sup>μ</sup>和两个随机数字进行加密。</li><li>加密：Encrypt(M，TK，PK)[信息，非对称传输密钥，公钥]</li></ol>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> paper </tag>
            
            <tag> block chain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习D一天</title>
      <link href="/2020/11/10/%E5%AD%A6%E4%B9%A0D%E4%B8%80%E5%A4%A9/"/>
      <url>/2020/11/10/%E5%AD%A6%E4%B9%A0D%E4%B8%80%E5%A4%A9/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Plane</p></blockquote><hr><ul><li><input checked="" disabled="" type="checkbox"> 提出信息安全理论项目初步计划</li><li><input checked="" disabled="" type="checkbox"> 14:00-16:00 读身份加密的材料</li><li><input checked="" disabled="" type="checkbox"> 16:10-17:20 完成医院系统项目日志集成</li></ul><p><em>- [ ]  18:50-20:50 数据库的系统学习</em></p><ul><li><input disabled="" type="checkbox"> 21:00-22:30 springmvc学习</li><li><input disabled="" type="checkbox"> 22:30-23:30 总结</li></ul><hr><h3 id="信息安全理论项目安排"><a href="#信息安全理论项目安排" class="headerlink" title="信息安全理论项目安排"></a>信息安全理论项目安排</h3><ol><li>李完成基本项目搭建及核心抓包功能实现</li><li>陈完成数据库表完成【先将需要的表构思一下发群里看一下】</li><li>邹完成规则及书写功能需求</li><li>郑和邹书写功能需求，及将规则写入后端</li><li>郑艺根据功能需求完成基本的框架搭建和样式</li></ol><h3 id="身份认证相关论文"><a href="#身份认证相关论文" class="headerlink" title="身份认证相关论文"></a>身份认证相关论文</h3><h4 id="A-Survey-of-Zero-Trust-Research"><a href="#A-Survey-of-Zero-Trust-Research" class="headerlink" title="A Survey of Zero Trust Research"></a>A Survey of Zero Trust Research</h4><p>@author 张宇 张妍【北京数字认证股份有限公司】</p><h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><ol><li>“边界防护”</li></ol><ol start="2"><li>何为无边界趋势下的网络安全问题</li><li></li><li>何为基于网络位置的隐式信任</li><li>何为静态防御</li><li>了解“ Google基于零信任构建的BeyondCorp项目”</li><li>了解“提出了软件定义边界（software defined perimeter,SDP)网络安全模型”</li><li>计算机专业词汇</li></ol><ul><li><strong>策略引擎（Policy Engine）：</strong> 该组件负责最终决定是否授予指定访问主体对资源（访问客体）的访问权限。策略引擎使用企业安全策略以及来自外部源（例如IP黑名单，威胁情报服务）的输入作为“信任算法”的输入，以决定授予或拒绝对该资源的访问，策略引擎的核心作用是信任评估。</li><li><strong>策略管理器（Policy Administrator）：</strong> 组件负责建立客户端与资源之间的连接。它将生成客户端用于访问企业资源的任何身份验证令牌或凭据。它与策略引擎紧密相关并依赖于其决定最终允许或拒绝连接，策略管理器的核心作用是策略判定点，是零信任动态权限的判定组件。</li><li><strong>策略执行点（Policy Enforcement Point）：</strong> 这实际上是一个组件系统，负责开始，持续监控、并最终结束访问主体与访问客体之间的连接。策略执行点实际可分为两个不同的组件：客户端组件（如用户笔记本电脑上的agent）与资源端组件（如资源前控制访问的网关），策略执行点的核心作用是确保业务的安全访问。</li><li><ul><li><strong>持续诊断和缓解计划系统（CDM System）：</strong> 该系统收集关于企业系统当前状态的信息，并将更新应用到配置和软件组件中。企业CDM系统还提供给策略引擎关于系统访问请求的信息。</li></ul></li><li><ul><li><strong>行业合规系统（Industry Compliance System）：</strong> 该系统确保企业与当前政府管理的一致性。包括企业开发的所有策略规则来确保合规。</li></ul></li><li><ul><li><strong>威胁情报流（Threat Intelligence）：</strong> 该系统提供帮助策略引擎进行访问决策的信息。</li></ul></li><li><ul><li><strong>数据访问策略（Data Access Policy）：</strong> 数据访问策略是企业为企业资源创建的关于数据访问的属性、规则和策略的集合。策略规则集可以编码在策略引擎中或有PE动态生成。</li></ul></li><li><ul><li><strong>企业公钥基础设施（PKI）：</strong> 该系统负责生成和记录企业对资源、应用等发布的证书。既包括全局CA生态系统和联邦PKI。</li></ul></li><li><ul><li><strong>ID管理系统（ID Management）：</strong> 系统负责创建、保存和管理企业用户帐户和身份记录。系统中既含有必要的用户信息，也含有其他企业特征，比如角色、访问属性、或分配的系统。</li></ul></li><li><ul><li><strong>安全应急和事件管理系统（SIEM System）：</strong> 集合了系统日志、网络流量、资源权利和其他信息的企业系统为企业信息系统体佛那个安全态势的反馈。</li></ul></li></ul><ol start="8"><li>何为分配基于二元决策的策略</li><li>了解RADIUS协议</li><li>了解SSO方式认证</li></ol><h5 id="梳理"><a href="#梳理" class="headerlink" title="梳理"></a>梳理</h5><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>如何进行动态认证？如何有效进行动态认证？</p><p><a href="https://www.secrss.com/articles/14045">引用</a><br><a href="chrome-extension://gfbliohnnapiefjpjlpjnehglfpaknnc/pages/pdf_viewer.html?r=https://www.gartner.com/teamsiteanalytics/servePDF?g=/imagesrv/media-products/pdf/Qi-An-Xin/Qianxin-1-1XXWAXWM.pdf">引用</a></p><h3 id="对于数据库的详细学习"><a href="#对于数据库的详细学习" class="headerlink" title="对于数据库的详细学习"></a>对于数据库的详细学习</h3>]]></content>
      
      
      <categories>
          
          <category> daily report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> study </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当前区块链交易的缺陷</title>
      <link href="/2020/11/10/%E5%BD%93%E5%89%8D%E5%8C%BA%E5%9D%97%E9%93%BE%E4%BA%A4%E6%98%93%E7%9A%84%E7%BC%BA%E9%99%B7/"/>
      <url>/2020/11/10/%E5%BD%93%E5%89%8D%E5%8C%BA%E5%9D%97%E9%93%BE%E4%BA%A4%E6%98%93%E7%9A%84%E7%BC%BA%E9%99%B7/</url>
      
        <content type="html"><![CDATA[<blockquote><p>The first type: existing blockchain systems, such as the privacy protection technology used in Bitcoin and Ethereum, use “pseudo-anonymous” technology only for the nodes of the transaction, and the transaction party can create multiple addresses for transaction, each The address corresponds to a public key in the asymmetric encryption, and has no binding relationship with the true identity of the transaction party, that is, the address of the node is anonymous, and the transaction details are public and transparent, and the balance operation of the two transaction nodes is directly performed during the transaction. However, this method does not really guarantee that the node is “anonymous”. For example, in the transaction of the Bitcoin system, the user does not need to use the real name, but uses the public key hash value as the transaction identifier. However, by associating transaction information with personal information in real life, combined with address information and public account books of service providers, the address can correspond to individual users, and all their consumption records will be revealed, which will bring serious users private issues.</p></blockquote><ol><li>第一个现存的问题，现有系统只对交易过程进行“匿名”处理，但是交易内容和现实生活中的个人信息有所联系，例如比特币和以太坊通过为交易方提供多个地址，每个地址对应非对称加密过程中的一个公钥，即地址匿名，来保障用户匿名，只是对于交易内容进行操作。比特币交易系统中，也是类似，用户不需要真实信息，同时公钥哈希值作为交易标识。这样的交易内容是透明的，这样就存在一个问题，交易内容为透明的，同时避不开免的与现实生活有所关联，此时结合服务提供商等的地址及公共账本，地址即对应的个人用户，这样隐私就基本完全泄漏。–伪匿名，信息泄露风险</li></ol><blockquote><p>The second type: directly encrypts the balance on the public ledger. Only the node itself or the related party that gives the right can view the transaction information, and the other nodes cannot operate the data, and the book information is difficult to maintain consistency. For example, Chinaledger proposed a scheme based on the Central Counterparty (CCP). The transaction initiator uses the CCP’s public key to encrypt the transaction. After signing, it is submitted to the CCP. The CCP realizes decryption, checks the signature, checks the balance, and if it is valid, realizes the transfer of the transfer amount. . In this method, the remaining nodes can only endorse the transaction, but cannot endorse the balance. Although this scheme protects the privacy of the node user, it is too centralized, and the whole system relies on the reputation transaction of the CCP. There is also a State Channel-based privacy protection scheme proposed by the Ethereum community. In this transaction process, nodes in the blockchain submit transactions to smart contracts, and smart contracts implement encryption of intermediate process details. Not visible; when the transaction is completed, the final value allocation scheme is decrypted and returned to the rest of the blockchain. However, this method only protects the privacy of the intermediate process part, and the total transaction change is also transparent to all nodes.</p></blockquote><ol start="2"><li><p>通过对公共账本上的余额进行加密，只有节点本身或赋予权力的相关才能对交易信息可见，其余节点无法操作数据，账本信息难以保持一致性。例如Chinaledger提出了基于中央对手方(CCP)的方案，交易发起方使用CCP的公钥加密交易，签名后提交给CCP，由CCP实现解密、检验签名、检验余额，如果是有效再实现转账金额过户。此方法中，其余节点只能背书交易，而不能背书余额，此方案虽然保护了节点用户隐私，但过于中心化，整个系统依赖于CCP的信誉交易。还有以太坊社区提出的基于状态旁路(State channel)的隐私保护方案，此方案交易过程中，区块链中节点将交易提交到智能合约里,智能合约实现中间流程明细的加密，其余节点不可见;到交易完成时，再把最终价值分配方案解密，返回到区块链其余节点上。但此方法只保护了中间过程部分的隐私，交易的总额变动也是对所有节点透明的。—过度依赖CCP，违背去中心化；以太网提出的基于状态旁路的隐私保护方案则是不在依赖CCP，但是最后结果依旧是透明的<br>.</p><blockquote><p>Third: Encryption methods such as additive homomorphic encryption or zero-knowledge proof are used to ensure privacy. Addition homomorphic encryption is an asymmetric encryption for numerical values. For encrypted values of A, B, and C, Enc(A), Enc(B), and Enc(C) are respectively characterized. If A+B= C, then Enc(A)+Enc(B)=Enc(C). For example, in the invention patent “CN106549749A”, “a blockchain privacy protection method based on additive homomorphic encryption”, the following scheme is disclosed: on a blockchain network, a transaction request node initiates a transaction, and The network node verifies that the transaction recipient receives the transaction amount and completes the transaction. The steps of the transaction encryption method are specifically: homomorphic key generation; splitting the sender’s account visible balance into transaction amount and remaining balance; using the entire network The public key encryption transaction amount and remaining balance are recorded as ciphertext X1 and X2; the transaction amount is encrypted by the recipient’s public key to obtain ciphertext Y1; the sender initiates the transaction, and the transaction content includes three fields of X1, X2 and Y1; The entire network node verifies the transaction information, maintains the public ledger, and updates the visible balance of the recipient. The above solution realizes the function of hiding the transaction amount and the user balance on the blockchain by using the additive homomorphic encryption technology, and hopes to solve the problem that the traditional blockchain transaction exposes the real transfer amount to realize the blockchain. Privacy protection. However, this solution cannot confirm the consistency of the transaction and lacks the verification link for the validity of the transaction. In addition, ZCash provides complete identity privacy protection and transaction content privacy protection based on Bitcoin using zero-knowledge proof technology. In the ZCash system, transactions have “zero knowledge”, neither exposing the addresses of both parties to the transaction, nor exposing the transaction amount. Since zero-knowledge proofs are complex cryptographic protocols, their introduction can significantly affect performance and lack the supervision of relevant authorities.</p></blockquote></li><li><p>第三:使用加法同态加密技术或者零知识证明等加密方法来保证隐私。加法同态加密技术虽然保障了交易的隐私保护功能，却无法保障交易一致性，同时无法保障交易的有效性；零知识证明则需要复杂的密码协议，这将大幅度影响性能，且确实相关权威的监管，同样失去交易的有效性，例如ZCash系统。</p></li></ol><p>Summary：<br>    提供隐私数据保护，对数据进行分布式确权和管理，满足对交易进行监管的功能【有效性】</p>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graduate student </tag>
            
            <tag> paper </tag>
            
            <tag> block chain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020-10-24【Daily】</title>
      <link href="/2020/10/24/2020-10-24daily/"/>
      <url>/2020/10/24/2020-10-24daily/</url>
      
        <content type="html"><![CDATA[<h3 id="毕设开题"><a href="#毕设开题" class="headerlink" title="毕设开题"></a>毕设开题</h3><ol><li>背景==》缩写、划点</li><li>国内外现状==》在自己相关研究方向上进行国内外分析【数据化】（有话题相关就进行分析）（没有话题就对技术进行分析）</li><li>目标==》进行详细阐述实现过程</li><li>开题即检验后期开发过程中的详细步骤是否合理可完成【需要详细阐述出来】</li><li>区分“研究方案”和“解决方案”</li></ol>]]></content>
      
      
      <categories>
          
          <category> daily report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> summarize </tag>
            
            <tag> study </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《囚徒》普希金</title>
      <link href="/2020/10/19/lesslessqiu-tu-greatergreater-pu-xi-jin/"/>
      <url>/2020/10/19/lesslessqiu-tu-greatergreater-pu-xi-jin/</url>
      
        <content type="html"><![CDATA[<p><strong>我坐在阴湿牢狱的铁栏后<br>一只在禁锢中成长的鹰雏<br>和我郁郁地做伴；<br>它扑着翅膀，<br>在铁窗下啄食着血腥的食物。<br>它啄食着，丢弃着，又望望窗外，<br>像是和我感到同样的烦恼。<br>它用眼神和叫声向我招呼，<br>像要说：“我们飞去吧，是时候了，<br>“我们原是自由的鸟儿，飞去吧——<br>飞到那乌云后面明媚的山峦，<br>飞到那里，到那蓝色的海角，<br>只有风在欢舞……还有我做伴……</strong></p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> study </tag>
            
            <tag> book </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020-10-17【Daily】</title>
      <link href="/2020/10/17/2020-10-17daily/"/>
      <url>/2020/10/17/2020-10-17daily/</url>
      
        <content type="html"><![CDATA[<h2 id="EMMMMM，今天没学到东西，姿势不对，而且张柯师兄带妹儿在我旁边秀，太eeeeeeeeeeeeeeeex了"><a href="#EMMMMM，今天没学到东西，姿势不对，而且张柯师兄带妹儿在我旁边秀，太eeeeeeeeeeeeeeeex了" class="headerlink" title="EMMMMM，今天没学到东西，姿势不对，而且张柯师兄带妹儿在我旁边秀，太eeeeeeeeeeeeeeeex了"></a>EMMMMM，今天没学到东西，姿势不对，而且张柯师兄带妹儿在我旁边秀，太eeeeeeeeeeeeeeeex了</h2>]]></content>
      
      
      <categories>
          
          <category> daily report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> study </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020-10-15【Daily】</title>
      <link href="/2020/10/15/2020-10-15daily/"/>
      <url>/2020/10/15/2020-10-15daily/</url>
      
        <content type="html"><![CDATA[<h2 id="社会工程"><a href="#社会工程" class="headerlink" title="社会工程"></a>社会工程</h2><ul><li>emmmm,扣手机了，只看了几页的pdf</li><li>明天学下Google搜索的技巧</li><li>多关注容易忽视的信息查询窗口：校友录网站，支付宝，查询网，qq群，，，，，</li></ul><h2 id="数据库注入"><a href="#数据库注入" class="headerlink" title="数据库注入"></a>数据库注入</h2><ul><li>DVWA结合burpsuite的数据库注入操场预演练搞定了，后边可以快速发育了</li></ul><h2 id="springboot-ioc"><a href="#springboot-ioc" class="headerlink" title="springboot ioc"></a>springboot ioc</h2><ul><li>Bean的延长加载：spring会在项目启动的时候就初始化大量Bean，这就会导致项目启动慢，所有需要加入”default-lazy-init”属性，来减轻启动负担，可以通过延迟在关键的时候创建Bean来提高效率，<b>不过，spring启动时初始化Bean时可以检查是否存在配置错误，提早预警</b></li><li>＜context:component-scan/＞与＜context:annotation-config/＞，很多注解需要配置，而大部分通过xml配置进行注解驱动注册和包扫描功能。</li><li>IOC与依赖注入的区别：</li><li><ul><li>IOC:控制反转:将对象的创建权,由Spring管理.</li></ul></li><li><ul><li>DI(依赖注入):在Spring创建对象的过程中,把对象依赖的属性注入到类中。</li></ul></li></ul><h2 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h2><ul><li>我傻了，后天考试，发现这两天刷错题了🙂🙂🙂</li></ul>]]></content>
      
      
      <categories>
          
          <category> daily report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> summarize </tag>
            
            <tag> Java </tag>
            
            <tag> security </tag>
            
            <tag> front-end </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020-10-14【Daily】</title>
      <link href="/2020/10/14/2020-10-14daily/"/>
      <url>/2020/10/14/2020-10-14daily/</url>
      
        <content type="html"><![CDATA[<h2 id="Bean的作用域"><a href="#Bean的作用域" class="headerlink" title="Bean的作用域"></a>Bean的作用域</h2><p><a href="https://blog.csdn.net/javazejian/article/details/54561302#bean%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F">Source</a></p><ol><li>Singleton作用域</li></ol><p>Bean的默认作用域，即每个bean在Spring整个容器中一直都是同一个，<b>一般用于过程操作流中的bean设置为Singleton</b></p><ol start="2"><li>prototype作用域</li></ol><p>每次获取Bean实例时都会新创建一个实例对象，对于需要避免数据污染的bean设置</p><ol start="3"><li>request与session作用域</li></ol><ul><li>对于每次HTTP请求到达应用程序，Spring容器会创建一个全新的Request作用域的bean实例，该bean实例仅在当前HTTP request内有效</li><li>每当创建一个新的HTTP Session时就会创建一个Session作用域的Bean，并该实例bean伴随着会话的存在而存在</li></ul><ol start="4"><li>globalSession作用域</li></ol><p>类似于Session作用域，相当于全局变量，类似Servlet的Application，适用基于portlet的web应用程序，请注意，portlet在这指的是分布式开发，而不是portlet语言开发。</p><p>【注】<b>请务必明确一点，默认情况下Spring容器在启动阶段就会创建bean，这个过程被称为预先bean初始化，这样是有好处的，可尽可能早发现配置错误，如配置文件的出现错别字或者某些bean还没有被定义却被注入等。当然如存在大量bean需要初始化，这可能引起spring容器启动缓慢，一些特定的bean可能只是某些场合需要而没必要在spring容器启动阶段就创建，这样的bean可能是Mybatis的SessionFactory或者Hibernate SessionFactory等，延迟加载它们会让Spring容器启动更轻松些，从而也减少没必要的内存消耗。</b></p>]]></content>
      
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> study </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020-10-12【Daiily】</title>
      <link href="/2020/10/12/2020-10-12daiily/"/>
      <url>/2020/10/12/2020-10-12daiily/</url>
      
        <content type="html"><![CDATA[<h2 id="SpringBoot-IOC学习"><a href="#SpringBoot-IOC学习" class="headerlink" title="SpringBoot IOC学习"></a>SpringBoot IOC学习</h2><p>SpringBoot IOC架构利用反射技术通过配置文件的完全限定类名在运行时创建所需要的实现类，即在调用实体的时候不需要new，也不需要销毁新建的类了，因为Service没有和Dao进行关联，两者的耦合程度也降到最低了。</p><span id="more"></span><p><a href="https://blog.csdn.net/javazejian/article/details/54561302#spring-%E5%AE%B9%E5%99%A8%E8%A3%85%E9%85%8Dbeanxml%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F%E5%92%8C%E6%B3%A8%E8%A7%A3%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F">Source</a></p><h3 id="Spring容器装配BeanXML配置方式和注解配置方式"><a href="#Spring容器装配BeanXML配置方式和注解配置方式" class="headerlink" title="Spring容器装配BeanXML配置方式和注解配置方式"></a>Spring容器装配BeanXML配置方式和注解配置方式</h3><blockquote><p>装配方法：就是将dao和service的Bean保存到xml文件中，当使用时，在通过文件加载函数【ClassPathXmlApplicationContext，FileSystemXmlApplicationContext】来加载配置。</p></blockquote><blockquote><p>注解配置方式：这个比装配方法更简单，通过注释标明，然后通过声明加载函数【AnnotationConfigApplicationContext】来加载配置</p></blockquote><h3 id="Spring依赖注入"><a href="#Spring依赖注入" class="headerlink" title="Spring依赖注入"></a>Spring依赖注入</h3><p>所谓的依赖注入，其实是当一个bean实例引用到了另外一个bean实例时spring容器帮助我们创建依赖bean实例并注入（传递）到另一个bean中，如Service依赖于Dao，Spring容器会在创建Service的实现类和Dao的实现类后，把Dao的实现类注入Service实例中。</p><ol><li>Setter注入</li></ol><ul><li>被注入属性需要有set方法</li><li>通过配置文件中的<property> 来注入</li></ul><ol start="2"><li>构造函数注入</li></ol><ul><li>通过构造方法注入依赖，构造函数的参数一般情况下就是依赖项，spring容器会根据bean中指定的构造函数参数来决定调用那个构造函数</li><li>与Setter类似，这里使用<constructor-arg>来注入</li></ul><ol start="3"><li>循环依赖</li></ol><p><img src="http://merlynr.github.io/post-images/1602511259264.png"></p><ul><li>互相注入，容易出现逻辑错误</li></ul><ol start="4"><li>自动装配与注解注入</li></ol><blockquote><p>基于xml的自动装配</p></blockquote><ul><li>基于xml配置，autowrie属性</li><li>包含三种模式：byTpye(根据类型)，byName(根据名称)、constructor(根据构造函数)</li><li><ul><li>在byTpye模式中，Spring容器会基于反射查看bean定义的类，然后找到与依赖类型相同的bean注入到另外的bean中，这个过程需要借助setter注入来完成，因此必须存在set方法，否则注入失败。</li></ul></li><li><ul><li>事实上byType模式可能存一种注入失败的情况，由于是基于类型的注入，因此当xml文件中存在多个相同类型名称不同的实例Bean时，Spring容器依赖注入仍然会失败,<b>可以通过＜bean＞标签的autowire-candidate设置为false来过滤那些不需要注入的实例Bean</b></li></ul></li></ul><blockquote><p>基于注解的自动装配(@Autowired&amp;@Resource&amp;@Value)</p></blockquote><ul><li>通过 @Autowired的使用标注到成员变量时不需要有set方法</li><li>@Autowired 默认按类型匹配的</li><li>使用注解时必须启动注解驱动 &lt;context:annotation-config /&gt;</li><li>与@Autowried具备相同功效的还有@Resource，默认按 byName模式 自动注入</li><li>@Resource有两个中重要的属性：name和type</li></ul><blockquote><p>基于@Value注解的自动装配以及properties文件读取</p></blockquote><p><img src="http://merlynr.github.io/post-images/1602512057020.png" alt="注释使用"></p><p><img src="http://merlynr.github.io/post-images/1602512073526.png" alt="xml配置"></p>]]></content>
      
      
      <categories>
          
          <category> daily report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> summarize </tag>
            
            <tag> Java </tag>
            
            <tag> study </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2020-10-09【Daily】</title>
      <link href="/2020/10/09/2020-10-09/"/>
      <url>/2020/10/09/2020-10-09/</url>
      
        <content type="html"><![CDATA[<h2 id="《SQL注入攻击与防御》P1-P36"><a href="#《SQL注入攻击与防御》P1-P36" class="headerlink" title="《SQL注入攻击与防御》P1-P36"></a>《SQL注入攻击与防御》P1-P36</h2><h3 id="理解出现数据库安全威胁的原因"><a href="#理解出现数据库安全威胁的原因" class="headerlink" title="理解出现数据库安全威胁的原因"></a>理解出现数据库安全威胁的原因</h3><blockquote><p>我认为出现安全威胁的原因主要是两部分原因，一部分是由互联网公司对于配置和使用数据的不重视导致，尤其是广泛的中小企业后端开发和数据库配置都有后端开发程序员来掌控，而由于技术专精，后端程序员的更多能力体现在对于数据库的使用，而数据库中对于库甚至表的权限却没有能力管理；第二部分就是导致数据库注入攻击事件频发的原因，数据库与开发框架的混合使用，对于传入参数无法进行精确及时的判断，导致数据库无法判断传入的是参数还是指令。</p></blockquote><h2 id="《社工档案袋》P1-P20"><a href="#《社工档案袋》P1-P20" class="headerlink" title="《社工档案袋》P1-P20"></a>《社工档案袋》P1-P20</h2><blockquote><p>重新理解信息安全攻击，开阔眼界，消除对于网络安全的狭义理解。网络安全不仅仅应该局限于网络上的信息收集，还要将这种安全攻击策略用于真实社会上进行尝试，及广义上的社会工程学。</p></blockquote><h2 id="spring的学习"><a href="#spring的学习" class="headerlink" title="spring的学习"></a>spring的学习</h2><ol><li><a href="https://blog.csdn.net/javazejian/article/details/54561302gh">spring的ioc原理</a></li><li><a href="https://www.cnblogs.com/leoo2sk/archive/2008/04/10/1146447.html#">面向对象和面向接口</a></li><li>反射的编程技术<ul><li>我理解就是ioc的技术支持</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> daily report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> graduate student </tag>
            
            <tag> report </tag>
            
            <tag> Java </tag>
            
            <tag> study </tag>
            
            <tag> security </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>加密通信的演化</title>
      <link href="/2020/09/15/jia-mi-tong-xin-de-yan-hua/"/>
      <url>/2020/09/15/jia-mi-tong-xin-de-yan-hua/</url>
      
        <content type="html"><![CDATA[<p>私密和公密都可以进行加密解密，但是加密与解密对应的关系，必须是一方加密另一方解密</p><p>RSA<br>1.安全漏洞：黑客可以通过传输简单字符给服务器，服务器又把用私密加密的报文传给客户端，黑客就可以较为容易的破解出私密<br>避免方法：服务端进行加密之前先将客户端传来的信息包进行hash计算，然后对hash☞进行加密。<br>2.安全威胁：在通信过程中，黑客将获取到的数据包反复发送给服务器，严重占用资源。<br>解决方法：通过加入标识【序号或随机数】，服务端发现这个报文是被反复发送的则立即中断网络通信。<br>存在问题：如果这种反复提交情况一直持续，则会造成网络通信持续中断<br>3.安全威胁：:黑客可以修改通信中的密文，从而影响客户端与服务端的正常通信<br>解决方法：在传输之前将要传输的内容进行一次hash计算，然后将传输内容和hash值一起传输给接收方，接收方接收后将拿到的内容进行hash计算，然后比对hash值，如果一样说没就没有被修改过，否则立马中止通信，并进行安全维护</p><p>2020-9.16 4. 在windows中对数字证书进行管理</p>]]></content>
      
      
      <categories>
          
          <category> security </category>
          
      </categories>
      
      
        <tags>
            
            <tag> summarize </tag>
            
            <tag> security </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>详记HTTP向HTTPS进化</title>
      <link href="/2020/06/19/xiang-ji-http-yu-https-zhi-jian-de-qu-bie/"/>
      <url>/2020/06/19/xiang-ji-http-yu-https-zhi-jian-de-qu-bie/</url>
      
        <content type="html"><![CDATA[<p>老师这个是我自己学习的，同时我也上传过这篇文章到我的博客，如果您想要验证，可以在<a href="https://blog.zuishuailcq.xyz/">博客</a>中搜索ssl就可以查到这篇文章了</p><h1 id="两者表面的区别"><a href="#两者表面的区别" class="headerlink" title="两者表面的区别"></a>两者表面的区别</h1><ol><li>HTTP（Hypertext Transfer Protocol）是超文本传输协议，<font color=#DE6B6E>信息是明文</font>，HTTPSHypertext Transfer Protocol Secure则是既有安全性的SSL加密传输协议。基本可以理解为在HTTP的传输基础上加入SSL层来加密信息。两者请求和响应都是已相同的方式进行工作。</li><li>HTTP采用80端口连接，HTTPS采用443端口连接qi</li><li>HTTP与HTTPS<font color=#FAE05C>连接方式不同</font></li><li>HTTPS在连接中需要CA证书认证身份，一般需要money购买</li><li>HTTP连接是<font color=#DE6B6E>无状态的</font>，可以短连接也可以长连接，更加灵活；HTTPS协议是由<font color=#DE6B6E>SSL+HTTP协议</font>构建的可加密传输，身份认证的网络协议，虽然建立连接变得复杂但是更加安全，需要多次握手，所以一般会加剧50%时间延迟，且会消耗 CPU 资源，对服务器资源消耗较大</li></ol><h1 id="HTTP和HTTPS建立连接方式"><a href="#HTTP和HTTPS建立连接方式" class="headerlink" title="HTTP和HTTPS建立连接方式"></a>HTTP和HTTPS建立连接方式</h1><h2 id="HTTP建立连接"><a href="#HTTP建立连接" class="headerlink" title="HTTP建立连接"></a>HTTP建立连接</h2><h3 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h3><p><img src="https://merlynr.github.io/post-images/1592550376754.png"></p><p>==TCP三次握手(Three-way Handshake)==<br>TCP/IP协议是传输层协议，主要解决数据如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。“即互联网中TCP/IP就可以满足信息通信，但是想要识别传输的信息是否有意义，我们就需要应用层协议”</p><blockquote><p>  TCP提供的可靠数据传输服务，是依靠接收端TCP软件按序号对收到的数据分组进行逐一确认实现的。这个过程在TCP收发端开始通信时，被称为三次握手初始化。<br>     三次握手的目的是使收发端的数据发送和接收同步，协调可以收发的数据量，建立虚连接。双方的TCP协议软件在交换数据时必须首先建立会话连接，然后才能够以数据分组为单位进行通信。接收端TCP协议软件每收到一个数据分组，在检验传输无误后，就对发送端计算机发送确认信息(ACK，Acknowledgement)，通知该序号分组收到。<br>     数据传输过程中，发送端对已经发出的分组要有记录，并且设置等待确认的计时器，对超过规定时间未收到确认的分组按照丢失重传处理；接收端的TCP协议软件会自动检查是否所有的数据分组都已收到，如果发现哪个数据分组损坏，接收端会将它舍弃，并通知发送端重传；接收端的TCP协议软件还能对未按顺序到达的数据分组进行重新排序，解决乱序问题。<br>     收发端TCP协议软件进行带确认的数据传送过程如所示。在图中，发送端将序号为100的数据分组(SEQ=100)送出；接收端收到后，向发送端回应一个序号为200的分组(SEQ=200)，内容是对收到序号为100的数据分组的确认，确认信息是对收到的数据分组序号加1(ACK=101)；发送端得知序号100的分组收到后，发送下一个数据分组(序号为101， SEQ=101)，并且在该分组中带有对收到序号为200的回应分组的确认(仍然是对收到的分组序号加1，ACK=201)。<br>     最后，当接收端计算机的TCP协议软件确认收到的数据分组无误，就根据封装在分组头部的目的端口号，识别出目的应用程序，将分组中的数据取出并按照原来顺序组合好交付给相应程序。</p><blockquote><p><a href="https://blog.csdn.net/wwj_748/article/details/11855289">FROM:TCP协议的作用？-IT_xiao小巫</a> </p></blockquote></blockquote><ul><li>初始状态：A，B都属于初始状态都是关闭状态</li><li>状态变化：A主动打开连接，B被动打开连接并进入监听状态</li><li>第一次握手：A向B发送一个TCP包，其中包中SYN标志设置为1，表明A向B请求建立连接，并设置序号seq=x，其中x的值表示第一个数据字节序号为x（x不确定，即seq是个随机值）。<br><font color=#DE6B6E>注意：</font>SYN包就是SYN标设为1的TCP包，只有A收到B发来的SYN包，才可以建立连接，否则无法建立连接。因此，<font color=#FAE05C>如果你的防火墙丢弃所有的发往外网接口的SYN包，那么你将不能让外部任何主机主动建立连接。</font></li><li>状态变化：A进入SYN_SEND状态，等待B的确认</li><li>第二次握手：B如果同意建立连接，会向A发送一个对A发送的SYN包的确认（SYN/ACK）包， 确认号ack=x+1，初始序号seq=y（随机值）<br><font color=#DE6B6E>注意：</font>SYN/ACK包是仅SYN 和 ACK 标记为1的包。这个报文也不能携带数据，但是同样要消耗一个序号。</li><li>状态变化：B进入SYN-RCVD状态（同步收到）</li><li>第三次握手：A收到B的确认TCP报后，向B发送一个确认收到B发送的确认报，其中确认报确认报文段（ACK=1，确认号ack=y+1，序号seq=x+1）</li><li>状态变化：A接到B的确认报文进行检查后变为ESTABLISHED（已建立连接）</li><li>状态变化：当B收到A的确认报文进行检查后变为ESTABLISHED（已建立连接）<br><font color=#DE6B6E>注意：</font>A收到确认后，检查ack是否为x+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=y+1，并且此时操作系统为该TCP连接分配TCP缓存和变量，并将该数据包发送给B，B检查ack是否为y+1，ACK是否为1，如果正确则连接建立成功。</li></ul><blockquote><blockquote><p><a href="https://blog.csdn.net/xingerr/article/details/72834303">FROM：TCP三次握手详解-Shirsen</a><br><a href="https://juejin.im/post/5b1d34eb6fb9a01e7d5c3e25">FROM：注意！是TCP不是HTTP的3次握手与4次挥手-鲍康霖</a></p></blockquote></blockquote><blockquote><p>三次握手的目的是连接服务器指定端口，建立 TCP连接，并同步连接双方的序列号和确认号，交换 TCP窗口大小信息。在 socket 编程中，客户端执行 connect() 时。将触发三次握手。</p></blockquote><h3 id="HTTPS通信中存在问题"><a href="#HTTPS通信中存在问题" class="headerlink" title="HTTPS通信中存在问题"></a>HTTPS通信中存在问题</h3><ol><li>容易被监听<br>http通信都是明文，数据在客户端与服务器通信过程中，任何一点都可能被劫持。比如，发送了银行卡号和密码，hacker劫取到数据，就能看到卡号和密码，这是很危险的</li><li>被伪装<br>http通信时，无法保证通行双方是合法的，通信方可能是伪装的。比如你请求<a href="http://www.taobao.com,你怎么知道返回的数据就是来自淘宝,中间人可能返回数据伪装成淘宝./">www.taobao.com,你怎么知道返回的数据就是来自淘宝，中间人可能返回数据伪装成淘宝。</a></li><li>被篡改<br>hacker中间篡改数据后，接收方并不知道数据已经被更改</li></ol><h2 id="HTTPS连接方式"><a href="#HTTPS连接方式" class="headerlink" title="HTTPS连接方式"></a>HTTPS连接方式</h2><p>==https是http与ssl的结合体==</p><p><img src="https://merlynr.github.io/post-images/1592735988318.png"></p><h3>客户端与服务器获取验证的通信过程</h3><ul><li>客户端发送请求到服务器端</li><li>服务器端返回证书和公开密钥，公开密钥作为证书的一部分而存在</li><li>客户端验证证书和公开密钥的有效性，如果有效，则生成共享密钥并使用公开密钥加密发送到服务器端</li><li>服务器端使用私有密钥解密数据，并使用收到的共享密钥加密数据，发送到客户端</li><li>客户端使用共享密钥解密数据</li><li>SSL加密建立………</li></ul>]]></content>
      
      
      <categories>
          
          <category> security </category>
          
      </categories>
      
      
        <tags>
            
            <tag> daily </tag>
            
            <tag> summarize </tag>
            
            <tag> Java </tag>
            
            <tag> security </tag>
            
            <tag> front-end </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
