<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>二分类之类别不平衡 | 吾辈之人，自当自强不息！</title><meta name="keywords" content="二分类，数据不均衡，欠采样，过采样"><meta name="author" content="Merlynr"><meta name="copyright" content="Merlynr"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="目中出现了二分类数据不平横问题，研究总结下对于类别不平横问题的处理经验">
<meta property="og:type" content="article">
<meta property="og:title" content="二分类之类别不平衡">
<meta property="og:url" content="https://merlynr.github.io/2021/05/31/%E4%BA%8C%E5%88%86%E7%B1%BB%E4%B9%8B%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1/index.html">
<meta property="og:site_name" content="吾辈之人，自当自强不息！">
<meta property="og:description" content="目中出现了二分类数据不平横问题，研究总结下对于类别不平横问题的处理经验">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.obzhi.com/wp-content/uploads/2022/03/boji2.png">
<meta property="article:published_time" content="2021-05-30T16:00:00.000Z">
<meta property="article:modified_time" content="2021-06-08T16:00:00.000Z">
<meta property="article:author" content="Merlynr">
<meta property="article:tag" content="graduate student">
<meta property="article:tag" content="study">
<meta property="article:tag" content="algorithm">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="data mining">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.obzhi.com/wp-content/uploads/2022/03/boji2.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://merlynr.github.io/2021/05/31/%E4%BA%8C%E5%88%86%E7%B1%BB%E4%B9%8B%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="NxG6l55lxRJBy3WWiA4lqhdm77dCzqIMonHurWHQtu0"/><meta name="baidu-site-verification" content="code-K9eCtVEPQ1"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?2b88427b12";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=NxG6l55lxRJBy3WWiA4lqhdm77dCzqIMonHurWHQtu0"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'NxG6l55lxRJBy3WWiA4lqhdm77dCzqIMonHurWHQtu0');
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: true
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Merlynr","link":"链接: ","source":"来源: 吾辈之人，自当自强不息！","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '二分类之类别不平衡',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-06-09 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="吾辈之人，自当自强不息！" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/thumb-78833.gif" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('http://www.obzhi.com/wp-content/uploads/2022/03/boji2.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">吾辈之人，自当自强不息！</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">二分类之类别不平衡</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-05-30T16:00:00.000Z" title="发表于 2021-05-31 00:00:00">2021-05-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-06-08T16:00:00.000Z" title="更新于 2021-06-09 00:00:00">2021-06-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/algorithm/">algorithm</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>24分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="二分类之类别不平衡"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/massquantity/p/8550875.html">机器学习之类别不平衡问题 (1) —— 各种评估指标 - massquantity - 博客园</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/question/269698662">欠采样（undersampling）和过采样（oversampling）会对模型带来怎样的影响？</a><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/inchbyinch/p/12642760.html">详解类别不平衡问题 - 天地辽阔 - 博客园</a></p>
<h2 id="类别不平衡-class-imbalance"><a href="#类别不平衡-class-imbalance" class="headerlink" title="类别不平衡(class-imbalance)"></a>类别不平衡(class-imbalance)</h2><blockquote>
<p><font color="#D2691E"> 惯例</font><br>在二分类问题中，一般将数目少的类别视为正例，数目多的类别视为负例</p>
</blockquote>
<p><font color="#228B22">也叫数据倾斜，数据不平衡指分类任务中不同类别的训练样例数目差别很大的情况。</font></p>
<h2 id="各种评估指标"><a href="#各种评估指标" class="headerlink" title="各种评估指标"></a>各种评估指标</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/massquantity/p/8550875.html">机器学习之类别不平衡问题 (1) —— 各种评估指标 - massquantity - 博客园</a></p>
<p><img src="http://files.shanqianche.cn/202167/1623024781731.png" alt="混淆矩阵图"></p>
<ul>
<li>True Positive(真正例，TP)：实例为正例，预测为正例</li>
<li>False Negative (假负例，FN)：实际为正例，预测为负例。</li>
<li>True Negative (真负例，TN)：实际为负例，预测为负例。</li>
<li>False Positive (假正例，FP)：实际为负例，预测为正例。</li>
</ul>
<ol>
<li>Precision (查准率) = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></math> ，Precision衡量的是<font color="#7FFF00">所有被预测为正例的样本中有多少是真正例</font>。<font color="#A52A2A">但Precision并没有表现有多少正例是被错判为了负例(即FN)</font>，举个极端的例子，分类器只将一个样本判为正例，其他所有都判为负例，这种情况下Precision为100%，但其实遗漏了很多正例，所以Precision常和下面的Recall (TPR) 相结合。</li>
<li>True Positive Rate (TPR，真正例率) = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></math> ，又称__Recall__(查全率,召回率)，Sensitivity(灵敏性)。Recall (TPR)衡量的是所有的正例中有多少是被<font color="#008B8B">正确分类</font>了，也可以看作是为了<font color="#057748">避免假负例(FN)的发生</font>，<font color="#0000FF">即将真正例分类到真正中而不是通过假负来判断的</font>，因为TPR高意味着FN低。Recall的问题和Precision正相反，没有表现出有多少负例被错判为正例(即FP)，若将所有样本全划为正例，则Recall为100%，但这样也没多大用。</li>
<li>True Negative Rate (TNR，真负例率) = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></math> ，又称Specificity(特异性)。Specificity衡量的是<font color="#006400">所有的负例中有多少是被正确分类</font>了，由于<font color="#1E90FF">类别不平衡问题中通常关注正例能否正确被识别，Specificity高则FP低，意味着很少将正例错判为负例，即该分类器对正例的判别具有“特异性”，在预测为正例的样本中很少有负例混入</font>。</li>
<li>False Positive Rate (FPR，假正例率) = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></math> = 1− $TNR$ , 由混淆矩阵可以看出该指标的<font color="#D2691E">着眼点</font>在于负例，意为有多少负例被错判成了正例。在ROC曲线中分别以TPR和FPR作为纵、横轴作图，显示出一种正例与负例之间的“<font color="#9400D3">博弈</font>”，在下篇文章中详解。</li>
</ol>
<p>F1 score = <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>2</mn><mrow><mfrac><mn>1</mn><mtext>&#xA0;recall&#xA0;</mtext></mfrac><mo>+</mo><mfrac><mn>1</mn><mtext>&#xA0;precision&#xA0;</mtext></mfrac></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><mo>&#xD7;</mo><mtext>&#xA0;precision&#xA0;</mtext><mo>&#xD7;</mo><mtext>&#xA0;recall&#xA0;</mtext></mrow><mrow><mtext>&#xA0;precision&#xA0;</mtext><mo>+</mo><mtext>&#xA0;recall&#xA0;</mtext></mrow></mfrac></math></p>
<p>F1分数（F1-Score），又称为平衡F分数（BalancedScore），是一个综合指标,它被定义为精确率和召回率的调和平均数 (harmonic mean),数值上一般接近于二者中的<font color="#1E90FF">较小值</font>，因此如果F1 score比较高的话，意味着Precision和Recall都较高。</p>
<blockquote>
<p><font color="#7FFF00"> 知识补充</font><br>调和平均数（harmonic mean）又称倒数平均数，是总体各统计变量倒数的算术平均数的倒数。调和平均数是平均数的一种。<br>算数平均数中，重要性取决于绝对值大的一方（强），而在调和平均数中，<font color="#057748">重要性</font>取决于<font color="#8B0000">绝对值小的一方</font>（弱）。</p>
</blockquote>
<p>FP和FN还有个还有个与之相关的概念，那就是统计假设检验中的<font color="#483D8B">第一类错误</font> (Type I error)和<font color="#483D8B">第二类错误 (Type II error)</font> 。由于我们比较关心正例，所以将负例视为零假设，正例视为备选假设，则第一类错误为错误地拒绝零假设 (负例)，选择备选假设，则为FP；第二类错误为错误地接受零假设，则为FN。</p>
<blockquote>
<p><font color="#006400">知识补充</font><br>零假设的内容一般是希望证明其错误的假设。</p>
</blockquote>
<hr>
<p>上面介绍的这些指标都没有考虑检索结果的先后顺序，而像搜索问题中我们通常希望第一个结果是与查询最相关的，第二个则是次相关的，以此类推，因而有时候不仅要预测准确，<font color="#6495ED">对于相关性的顺序也非常看重</font>。所以最后介绍两个广泛应用的<font color="#9400D3">排序指标</font>。</p>
<p>Mean Average Precision (MAP，平均准确率均值)，对于<font color="#B8860B">单个</font>信息需求，返回结果中在每篇相关文档上 Precision 的平均值被称为 Average Precision (AP)，然后对<font color="#D2691E">所有</font>查询取平均得到 MAP。<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>AP</mi><mo>=</mo><mfrac><mrow><msubsup><mo>&#x2211;</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>P</mi><mo>(</mo><mi>k</mi><mo>)</mo><mo>&#xD7;</mo><mo>rel</mo><mo>(</mo><mi>k</mi><mo>)</mo></mrow><mi>M</mi></mfrac></math><br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>MAP</mi><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>Q</mi></munderover><mfrac><msub><mi>AP</mi><mi>q</mi></msub><mi>Q</mi></mfrac></math><br>其中 P(k) 为前 k 个结果的 Precision，又可写为P@k。 rel(k) 表示第 k 个结果是否为相关文档，相关为1不相关为0，M 表示所有相关文档的数量，n 表示所有文档数量。如果只关心<font color="#00008B">前 K 个查询的情况</font>，则是下式：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>AP</mi><mo>@</mo><mi>K</mi><mo>=</mo><mfrac><mrow><msubsup><mo>&#x2211;</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mi>P</mi><mo>(</mo><mi>k</mi><mo>)</mo><mo>&#xD7;</mo><mo>rel</mo><mo>(</mo><mi>k</mi><mo>)</mo></mrow><msub><mi>M</mi><mi>K</mi></msub></mfrac></math><br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>MAP</mi><mo>@</mo><mi>K</mi><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>Q</mi></munderover><mfrac><mrow><msub><mi>AP</mi><mi>q</mi></msub><mo>@</mo><mi>K</mi></mrow><mi>Q</mi></mfrac></math><br>这里的 <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>M</mi><mi>K</mi></msub></math> 为前 K 个结果中相关文档的数量。</p>
<p>对于单个信息需求来说，Average Precision 是<font color="#bf242a"> PR 曲线</font>下面积的近似值，因此 MAP 可粗略地认为是某个查询集合对应的多条 PR 曲线下面积的平均值。</p>
<p><strong>Normalized Discounted Cumulative Gain</strong> (NDCG，归一化折扣累计增益) 。如果说 <font color="#0000FF">MAP 是基于 0/1 二值描述相关性</font>，那么 <font color="#9932CC">NDCG 则是可将相关性分为多个等级的指标</font>。<br>对于信息检索和推荐之类的问题，每一个返回的结果都被赋予一个相关性分数 rel，则 NDCG 中的 CG 表示前 k 个结果的分数之和，即累计增益 ：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>CG</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>rel</mi><mi>i</mi></msub></math></p>
<p>CG 没有考虑推荐的次序，所以在此基础上引入对结果顺序的考虑，即<font color="#DC143C">相关性高的结果</font>若排在后面则会受更多的惩罚，于是就有了 DCG (discounted CG)，折扣累积增益。公式如下：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>DCG</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mfrac><mrow><msup><mn>2</mn><msub><mi>rel</mi><mi>i</mi></msub></msup><mo>-</mo><mn>1</mn></mrow><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mfrac></math></p>
<p>i 表示一个结果在结果集中的顺序，如果该结果 rel 很高，但排在后面，意味着分母 log2(i+1) 会变大，则相应的总体 DCG 会变小 (注意这里的 log 是以 2 为底的)。</p>
<p>对于不同的查询，往往会返回不同的结果集，而不同结果集之间因为大小不同难以直接用 DCG 进行比较，所以需要进行<font color="#006400">归一化</font>，这其实和机器学习中不同特征因量纲不同要进行归一化差不多意思。这个归一化后的指标就是 NDCG ：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>NDCG</mi><mi>k</mi></msub><mo>=</mo><mfrac><msub><mi>DCG</mi><mi>k</mi></msub><msub><mi>IDCG</mi><mi>k</mi></msub></mfrac></math><br>其中 IDCG 表示 Ideal DCG， 指<font color="#006400">某个查询所能返回的最好结果集</font>，IDCG 的值也是结果集中最大的。将所有结果按相关性大小排序，计算出的 DCG 即为前 k 个结果的 IDCG：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>IDCG</mi><mi>k</mi></msub><mo>=</mo><munderover><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo>|</mo><mi>R</mi><mi>E</mi><mi>L</mi><mo>|</mo></mrow></munderover><mfrac><mrow><msup><mn>2</mn><msub><mi>rel</mi><mi>i</mi></msub></msup><mo>-</mo><mn>1</mn></mrow><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow></mfrac></math><br>其中 |REL| 表示按相关性顺序排列的结果集。因此 DCG 的值介于 (0, IDCG] ，故 NDCG 的值介于(0,1]，这样就起到了归一化的效果。不同查询或用户的 NDCG 平均起来可以用以评估一个搜索引擎或推荐系统的整体效果。</p>
<p>NDCG 的缺点是<font color="#483D8B">需要预先指定每一个返回结果的相关性</font>，这个超参数需要人为指定。</p>
<h2 id="常用的评估方法"><a href="#常用的评估方法" class="headerlink" title="常用的评估方法"></a>常用的评估方法</h2><h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>ROC曲线常用于二分类问题中的模型比较，主要表现为一种<font color="#0000FF">真正例率 (TPR) </font>和<font color="#0000FF">假正例率 (FPR) </font>的权衡。</p>
<p><strong><font color="#ff7500">概述：</font></strong> 是在不同的分类阈值 (threshold) 设定下分别以TPR和FPR为纵、横轴作图。由ROC曲线的两个指标，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mi>P</mi></mfrac><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></math>，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mi>N</mi></mfrac><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></math> 可以看出，当一个样本被分类器判为正例，若其本身是正例，则TPR增加；若其本身是负例，则FPR增加，因此ROC曲线可以看作是随着阈值的不断移动，所有样本中正例与负例之间的“对抗”。曲线越靠近左上角，意味着<font color="#FF1493">越多的正例优先于负例，模型的整体表现也就越好</font>。</p>
<p><img src="http://files.shanqianche.cn/202167/1623072321656.png" alt="ROC曲线"></p>
<p> <strong><font color="#008B8B">AUC (Area Under the Curve)</font></strong></p>
<p> <img src="http://files.shanqianche.cn/202167/1623073223653.png" alt="ROC space"></p>
<p>先看一下ROC曲线中的随机线，图中[0,0]到[1,1]的虚线即为随机线，该线上所有的点都<font color="#00FFFF">表示该阈值下TPR=FPR</font><br>根据定义，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mi>P</mi></mfrac></math>，表示所有正例中被预测为正例的概率；<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mi>N</mi></mfrac></math>，表示所有负例中被被预测为正例的概率。<font color="#B8860B">若二者相等，意味着无论一个样本本身是正例还是负例，分类器预测其为正例的概率是一样的，这等同于随机猜测</font>（注意这里的“随机”不是像抛硬币那样50%正面50%反面的那种随机）。</p>
<p>上图中B点就是一个随机点，无论是样本数量和类别如何变化，始终将75%的样本分为正例。</p>
<p><font color="#B8860B">ROC曲线围成的面积 (即AUC)可以解读为</font>：从所有正例中随机选取一个样本A，再从所有负例中随机选取一个样本B，分类器将A判为正例的概率比将B判为正例的概率大的可能性。可以看到位于随机线上方的点(如图中的A点)被认为好于随机猜测。在这样的点上TPR总大于FPR，意为正例被判为正例的概率大于负例被判为正例的概率。<br>从另一个角度看，由于画ROC曲线时都是先将所有样本按分类器的<font color="#1E90FF">预测概率</font>排序，<font color="#B22222">所以AUC反映的是分类器对样本的排序能力</font>，依照上面的例子就是A排在B前面的概率。<font color="#008B8B">AUC越大，自然排序能力越好</font>，即分类器将越多的正例排在负例之前。</p>
<p><font color="#8B0000">ROC曲线的绘制方法</font>：假设有P个正例，N个反例，首先拿到分类器对于每个样本预测为正例的概率，根据概率对所有样本进行<font color="#006400">逆序排列</font>，然后将<font color="#0000FF">分类阈值设为最大</font>，即把所有样本均预测为反例，此时图上的点为 (0,0)。然后将分类阈值依次设为每个样本的预测概率，即依次将每个样本划分为正例，如果该样本为真正例，则TP+1，即<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mi>P</mi><mi>R</mi><mo>+</mo><mfrac><mn>1</mn><mi>P</mi></mfrac></math>; 如果该样本为负例，则FP+1，即<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>+</mo><mfrac><mn>1</mn><mi>N</mi></mfrac></math>。最后的到所有样本点的TPR和FPR值，用线段相连。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/massquantity/Class-Imbalance/tree/master/">massquantity/Class-Imbalance: 《机器学习之类别不平衡问题》文章代码</a></p>
</blockquote>
<h4 id="ROC的优点"><a href="#ROC的优点" class="headerlink" title="ROC的优点"></a>ROC的优点</h4><p><img src="http://files.shanqianche.cn/202168/1623131643148.png" alt="混淆矩阵图"></p>
<ol>
<li><p>兼顾正例和负例的权衡。因为TPR聚焦于正例，FPR聚焦于与负例，使其成为一个比较均衡的评估方法。</p>
</li>
<li><p>ROC曲线选用的两个指标，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mi>P</mi></mfrac><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></math>，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mi>N</mi></mfrac><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></math>，都不依赖于具体的类别分布。</p>
<p> 注意TPR用到的TP和FN同属<font color="#FF1493">P</font>列，FPR用到的FP和TN同属<font color="#1E90FF">N</font>列，<font color="#7FFF00">所以即使P或N的整体数量发生了改变，也不会影响到另一列</font>。也就是说，即使正例与负例的比例发生了很大变化，ROC曲线也不会产生大的变化，而像Precision使用的TP和FP就分属两列，则易受类别分布改变的影响。</p>
</li>
</ol>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf">参考文献</a>中举了个例子，负例增加了10倍，ROC曲线没有改变，而PR曲线则变了很多。作者认为这是ROC曲线的优点，即具有<font color="#0000FF">鲁棒性</font>，在类别分布发生明显改变的情况下依然能客观地识别出较好的分类器。</p>
<blockquote>
<p><font color="#006400">代码验证</font><br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/massquantity/p/8592091.html">相关资料</a></p>
</blockquote>
<h4 id="ROC的缺点"><a href="#ROC的缺点" class="headerlink" title="ROC的缺点"></a>ROC的缺点</h4><ol>
<li>上文提到ROC曲线的优点是不会随着类别分布的改变而改变，但这在某种程度上也是其缺点。因为负例N增加了很多，而曲线却没变，这等于产生了大量FP。像信息检索中如果主要关心正例的预测准确性的话，这就不可接受了。</li>
<li>在类别不平衡的背景下，负例的数目众多致使FPR的增长不明显，导致ROC曲线呈现一个过分乐观的效果估计。ROC曲线的横轴采用FPR，根据<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>FPR</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mi>N</mi></mfrac><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></math>，当负例N的数量远超正例P时，FP的大幅增长只能换来FPR的微小改变。<font color="#B22222">结果是虽然大量负例被错判成正例，在ROC曲线上却无法直观地看出来。</font>（当然也可以只分析ROC曲线左边一小段）<br>举个例子，假设一个数据集有正例20，负例10000，开始时有20个负例被错判，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><mi>R</mi><mo>=</mo><mfrac><mn>20</mn><mrow><mn>20</mn><mo>+</mo><mn>9980</mn></mrow></mfrac><mo>=</mo><mn>0</mn><mo>.</mo><mn>002</mn></math>，接着又有20个负例错判，<math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mi>P</mi><msub><mi>R</mi><mn>2</mn></msub><mo>=</mo><mfrac><mn>40</mn><mrow><mn>40</mn><mo>+</mo><mn>9960</mn></mrow></mfrac><mo>=</mo><mn>0</mn><mo>.</mo><mn>004</mn></math>，在ROC曲线上这个变化是很细微的。而与此同时Precision则从原来的0.5下降到了0.33，在PR曲线上将会是一个大幅下降。</li>
</ol>
<h3 id="PR-Precision-Recall-曲线"><a href="#PR-Precision-Recall-曲线" class="headerlink" title="PR(Precision Recall)曲线"></a>PR(Precision Recall)曲线</h3><p>PR曲线展示的是Precision vs Recall的曲线，PR曲线与ROC曲线的相同点是都采用了TPR (Recall)，都可以用AUC来衡量分类器的效果。不同点是ROC曲线使用了FPR，而PR曲线使用了Precision，因此<font color="#8A2BE2">PR曲线的两个指标都聚焦于正例</font>。<font color="#8A2BE2">类别不平衡问题中由于主要关心正例</font>，所以在此情况下PR曲线被广泛认为<font color="#FF8C00">优于</font>ROC曲线。</p>
<p>PR曲线的绘制与ROC曲线类似，PR曲线的AUC面积计算公式为：</p>
<p><math xmlns="http://www.w3.org/1998/Math/MathML"><munder><mo>&#x2211;</mo><mi>n</mi></munder><mo>(</mo><msub><mi>R</mi><mi>n</mi></msub><mo>-</mo><msub><mi>R</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>)</mo><msub><mi>P</mi><mi>n</mi></msub></math></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/massquantity/Class-Imbalance/tree/master/">massquantity/Class-Imbalance: 《机器学习之类别不平衡问题》文章代码</a></p>
</blockquote>
<p><strong><font color="#FF00FF">使用场景</font></strong></p>
<ol>
<li>ROC曲线由于<font color="#1E90FF">兼顾</font>正例与负例，所以适用于评估分类器的<font color="#B22222">整体性</font>能，相比而言PR曲线完全聚焦于<font color="#FF00FF">正例</font>。</li>
<li>如果有多份数据且存在不同的类别分布，比如信用卡欺诈问题中每个月正例和负例的比例可能都不相同，这时候如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合，因为<font color="#1E90FF">类别分布改变</font>可能使得PR曲线发生变化时好时坏，这种时候难以进行模型比较；反之，如果想<font color="#FF00FF">测试不同类别分布下对分类器的性能</font>的影响，则PR曲线比较适合。</li>
<li>如果想要评估在相同的类别分布下正例的预测情况，则宜选PR曲线。</li>
<li>类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好。</li>
<li>最后可以根据具体的应用，在曲线上找到最优的点，得到相对应的precision，recall，f1 score等指标，去调整模型的阈值，从而得到一个符合具体应用的模型。</li>
</ol>
<h2 id="采样方法"><a href="#采样方法" class="headerlink" title="采样方法"></a>采样方法</h2><blockquote>
<p><font color="#FF1493">前提：</font>章节二三主要谈的是类别不平衡的评估指标，因此我们可以选择选择具体的类别不平衡问题的方法。</p>
</blockquote>
<p>采样方法大致可分为<font color="#00CED1">过采样 (oversampling)</font> 和<font color="#2F4F4F">欠采样 (undersampling) </font>，虽然过采样和降采样主题思想简单，但这些年来研究出了很多变种，本篇挑一些来具体阐述。见下思维导图：</p>
<p><img src="http://files.shanqianche.cn/202168/1623137294136.png" alt="采样方法"></p>
<h3 id="过采样"><a href="#过采样" class="headerlink" title="过采样"></a>过采样</h3><ol>
<li>随机过采样</li>
</ol>
<p>随机过采样顾名思义就是从样本少的类别中随机抽样，再将抽样得来的样本添加到数据集中。然而这种方法如今已经不大使用了，因为重复采样往往会导致<font color="#1E90FF">严重的过拟合</font>，因而现在的主流过采样方法是通过某种方式人工合成一些少数类样本，从而达到类别平衡的目的，而这其中的鼻祖就是SMOTE。</p>
<ol start="2">
<li>SMOTE</li>
</ol>
<p>SMOTE (synthetic minority oversampling technique) 的思想概括起来就是在<font color="#00FFFF">少数类</font>样本之间进行插值来产生额外的样本。具体地，对于一个少数类样本<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">X</mi><mi>i</mi></msub></math>使用K近邻法(k值需要提前指定)，求出离<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">X</mi><mi>i</mi></msub></math>距离最近的k个少数类样本，其中距离定义为样本之间n维特征空间的欧氏距离。然后从k个近邻点中随机选取一个，使用下列公式生成新样本：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">x</mi><mtext>new&#xA0;</mtext></msub><mo>=</mo><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub><mo>+</mo><mfenced><mrow><msub><mover><mi mathvariant="bold">x</mi><mo>^</mo></mover><mi>i</mi></msub><mo>-</mo><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></mrow></mfenced><mo>&#xD7;</mo><mi>&#x3B4;</mi></math><br>其中 <math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi mathvariant="bold">X</mi><mo>^</mo></mover></math> 为选出的k近邻点，δ∈[0,1]是一个随机数。下图就是一个SMOTE生成样本的例子，使用的是3-近邻，可以看出SMOTE生成的样本一般就在<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></math>和<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mover><mi mathvariant="bold">x</mi><mo>^</mo></mover><mi>i</mi></msub></math>相连的直线上：</p>
<p><img src="http://files.shanqianche.cn/202169/1623220386942.png" alt="SMOTE生成的样本"></p>
<p>SMOTE会随机选取少数类样本用以合成新样本，而不考虑周边样本的情况，这样容易带来两个<font color="#FF1493">问题</font>：</p>
<ol>
<li>如果选取的少数类样本周围也都是少数类样本，则新合成的样本不会提供太多有用信息。这就像支持向量机中远离margin的点对决策边界影响不大。</li>
<li>如果选取的少数类样本周围都是多数类样本，这类的样本可能是噪音，则新合成的样本会与周围的多数类样本产生大部分重叠，致使分类困难。</li>
</ol>
<p>总的来说我们希望新合成的少数类样本能处于两个类别的边界附近，这样往往能提供足够的信息用以分类。而这就是下面的 <strong>Border-line SMOTE</strong> 算法要做的事情。</p>
<blockquote>
<p><font color="#bf242a">知识补充</font><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/lemonaha/article/details/53410465#31-k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95">k近邻法–统计学习方法总结_lemonaha的博客-CSDN博客</a><br> k近邻法（k-nearest neighbor,<font color="#0000FF"> k-NN</font>）是一种基本分类与回归方法。这里只讨论分类问题中的k近邻法。k近邻法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。k近邻法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方法进行预测。因此，k近邻法不具有显式的学习过程。k近邻法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。**<font color="#1E90FF">k值的选择、距离度量及分类决策规则是k近邻法的三个基本要素</font>**。</p>
</blockquote>
<ol start="3">
<li>Border-line SMOTE</li>
</ol>
<p>这个算法会先将所有的少数类样本分成三类，如下图所示：</p>
<ul>
<li>“noise” ： 所有的k近邻个样本都属于多数类</li>
<li>“danger” ： 超过一半的k近邻样本属于<font color="#0000FF">多</font>数类</li>
<li>“safe”： 超过一半的k近邻样本属于<font color="#0000FF">少</font>数类</li>
</ul>
<p><img src="http://files.shanqianche.cn/202169/1623220611894.png" alt="Border-line SMOTE"></p>
<p>  <font color="#ff7500">Border-line SMOTE</font>算法只会从处于”<em>danger</em>“状态的样本中随机选择，然后用SMOTE算法产生新的样本。处于”danger“状态的样本代表靠近”边界“附近的少数类样本，而处于边界附近的样本往往更<font color="#B8860B">容易被误分类</font>。因而 Border-line SMOTE 只对那些靠近”边界“的少数类样本进行人工合成样本，而 SMOTE 则对所有少数类样本一视同仁。</p>
<p>Border-line SMOTE 分为两种: Borderline-1 SMOTE 和 Borderline-2 SMOTE。 Borderline-1 SMOTE 在合成样本时,是式中的<math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi mathvariant="bold">x</mi><mo>^</mo></mover></math>是一个<font color="#1E90FF">少数类样本</font>，而 Borderline-2 SMOTE 中的<math xmlns="http://www.w3.org/1998/Math/MathML"><mover><mi mathvariant="bold">x</mi><mo>^</mo></mover></math>则是k近邻中的<font color="#FF1493">任意</font>一个样本。</p>
<ol start="4">
<li>ADASYN</li>
</ol>
<p><font color="#8B008B">ADASYN</font>名为自适应合成抽样(adaptive synthetic sampling)，其最大的特点是<font color="#006400">采用某种机制自动决定每个少数类样本需要产生多少合成样本</font>，而不是像SMOTE那样对每个少数类样本合成同数量的样本。具体流程如下：</p>
<ol>
<li><p>首先计算需要合成的样本总量：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>G</mi><mo>=</mo><mfenced><mrow><msub><mi>S</mi><mrow><mi>m</mi><mi>a</mi><mi>j</mi></mrow></msub><mo>-</mo><msub><mi>S</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></mfenced><mo>&#xD7;</mo><mi>&#x3B2;</mi></math><br>其中<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mrow><mi>m</mi><mi>a</mi><mi>j</mi></mrow></msub></math>为多数类样本数量，<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>S</mi><mi>min</mi></msub></math>为少数类样本数量，β∈[0,1]为系数。G即为总共想要<font color="#8A2BE2">合成的少数类样本数量</font>，如果β=1则是合成后各类别数目相等。</p>
</li>
<li><p>对于每个少类别样本xi，找出其K近邻个点，并计算：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>&#x393;</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>&#x394;</mi><mi>i</mi></msub><mo>/</mo><mi>K</mi></mrow><mi>Z</mi></mfrac></math><br>其中Δi为K近邻个点中多数类样本的数量，Z为规范化因子以确保 Γ 构成一个分布。这样若一个少数类样本<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></math>的周围多数类样本越多，则其 Γi 也就越高。</p>
</li>
<li><p>最后对每个少类别样本<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">x</mi><mi>i</mi></msub></math>计算需要合成的样本数量<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi mathvariant="bold">g</mi><mi>i</mi></msub></math>，再用SMOTE算法合成新样本：<br><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>g</mi><mi>i</mi></msub><mo>=</mo><msub><mi>&#x393;</mi><mi>i</mi></msub><mo>&#xD7;</mo><mi>G</mi></math><br>可以看到ADASYN利用分布Γ来自动决定每个少数类样本所需要合成的样本数量，这等于是给每个少数类样本施加了一个权重，周围的多数类样本越多则权重越高。ADASYN的缺点是<font color="#A52A2A">易受离群点的影响</font>，如果一个少数类样本的K近邻都是多数类样本，则其权重会变得相当大，进而会在其周围生成较多的样本。</p>
</li>
</ol>
<p>下面利用sklearn中的 <em>make_classification</em> 构造了一个不平衡数据集，各类别比例为{0:54, 1:946}。原始数据，SMOTE，Borderline-1 SMOTE，Borderline-2 SMOTE和ADASYN的比较见下图，<font color="#0000FF">左侧为过采样后的决策边界</font>，<font color="#8B008B">右侧为过采样后的样本分布情况</font>，<font color="#B8860B">可以看到过采样后原来少数类的决策边界都扩大了，导致更多的多数类样本被划为少数类了</font>：</p>
<blockquote>
<p><font color="#0000FF">知识补充</font><br>决策边界顾名思义就是需要分类的数据中，区分不同类别的边界。</p>
</blockquote>
<pre><code>    原始数据
</code></pre>
<p><img src="http://files.shanqianche.cn/202169/1623222264899.png" alt="原始数据"><br>        SMOTE<br><img src="http://files.shanqianche.cn/202169/1623222317451.png" alt="SMOTE过采样"><br>        Borderline-1 SMOTE<br><img src="http://files.shanqianche.cn/202169/1623222382482.png" alt="Borderline-1 SMOTE"><br>        Borderline-2 SMOTE<br><img src="http://files.shanqianche.cn/202169/1623222404250.png" alt="Borderline-2 SMOTE"><br>        ADASYN<br><img src="http://files.shanqianche.cn/202169/1623222425227.png" alt="ADASYN"></p>
<p>从上图我们也可以比较几种过采样方法各自的特点。用 <code>SMOTE</code> 合成的样本分布比较平均，而<code>Border-line SMOTE</code>合成的样本则集中在类别边界处。<code>ADASYN</code>的特性是一个少数类样本周围多数类样本越多，则算法会为其生成越多的样本，从图中也可以看到生成的样本大都来自于原来与多数类比较靠近的那些少数类样本。</p>
<h3 id="欠采样"><a href="#欠采样" class="headerlink" title="欠采样"></a>欠采样</h3><ol>
<li><p>随机欠采样</p>
<p> 随机欠采样的思想同样比较简单，就是从多数类样本中随机选取一些剔除掉。这种方法的缺点是<font color="#0000FF">被剔除的样本可能包含着一些重要信息</font>，致使学习出来的模型效果不好。</p>
</li>
<li><p>EasyEnsemble 和 BalanceCascade<br>  EasyEnsemble和BalanceCascade采用集成学习机制来<font color="#8A2BE2">处理传统随机欠采样中的信息丢失</font>问题。</p>
</li>
</ol>
<ul>
<li>EasyEnsemble将多数类样本随机<font color="#00FFFF">划分成n个子集</font>，每个子集的数量等于少数类样本的数量，这相当于欠采样。接着将每个子集与少数类样本结合起来分别训练一个模型，最后将n个模型集成，这样虽然每个子集的样本少于总体样本，但集成后总信息量并不减少。</li>
<li>如果说EasyEnsemble是基于无监督的方式从多数类样本中生成子集进行欠采样，那么BalanceCascade则是采用了<font color="#7FFFD4">有监督</font>结合Boosting的方式。在第n轮训练中，将从多数类样本中抽样得来的子集与少数类样本结合起来训练一个基学习器H，训练完后多数类中能被H正确分类的样本会被剔除。在接下来的第n+1轮中，从被剔除后的多数类样本中产生子集用于与少数类样本结合起来训练，最后将不同的基学习器集成起来。BalanceCascade的有监督表现在每一轮的基学习器起到了在多数类中选择样本的作用，而其Boosting<font color="#bf242a">特点则体现在每一轮丢弃被正确分类的样本，进而后续基学习器会更注重那些之前分类错误的样本。</font></li>
</ul>
<blockquote>
<p><font color="#0000FF">知识补充</font>基学习器<br><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.biaodianfu.com/boosting.html">机器学习算法之Boosting – 标点符</a><br>同质集成中的个体学习器又称为基学习器（base learner），相应的学习算法也被称为基学习算法（base learning algorithm）。</p>
</blockquote>
<ol start="3">
<li>NearMiss</li>
</ol>
<p><font color="#725e82"><strong>NearMiss</strong></font>本质上是一种<font color="#BDB76B">原型选择</font>(prototype selection)方法，即从多数类样本中选取最具代表性的样本用于训练，主要是为了缓解随机欠采样中的信息丢失问题。NearMiss采用一些<font color="#A52A2A">启发式的规则</font>来选择样本，根据规则的不同可分为3类：</p>
<ul>
<li>NearMiss-1：选择到最近的K个少数类样本平均距离最近的多数类样本</li>
<li>NearMiss-2：选择到最远的K个少数类样本平均距离最近的多数类样本</li>
<li>NearMiss-3：对于每个少数类样本选择K个最近的多数类样本，目的是保证每个少数类样本都被多数类样本包围</li>
</ul>
<p>NearMiss-1和NearMiss-2的计算<font color="#0000FF">开销很大</font>，因为需要计算每个多类别样本的K近邻点。另外，NearMiss-1易受离群点的影响，如下面第二幅图中合理的情况是处于边界附近的多数类样本会被选中，然而由于右下方一些少数类离群点的存在，其附近的多数类样本就被选择了。相比之下NearMiss-2和NearMiss-3不易产生这方面的问题。</p>
<p><img src="http://files.shanqianche.cn/202169/1623224933174.png" alt="图一Oniginal data"></p>
<p><img src="http://files.shanqianche.cn/202169/1623225034300.png" alt="图二Resampling using Nearmiss-1"></p>
<p><img src="http://files.shanqianche.cn/202169/1623225086130.png" alt="图三Resampling using Nearmiss-2"></p>
<p><img src="http://files.shanqianche.cn/202169/1623225124104.png" alt="图四Resampling using Nearmiss-3"></p>
<ol start="4">
<li>数据清洗方法 (data cleaning tichniques)</li>
</ol>
<p>这类方法主要<font color="#8A2BE2">通过某种规则来清洗重叠的数据</font>，从而达到欠采样的目的，而这些规则往往也是启发性的，下面进行简要阐述：</p>
<ul>
<li><p><font color="#ff7500">Tomek Link</font>：Tomek Link表示<font color="#7FFFD4">不同类别</font>之间距离最近的一对样本，即<font color="#bf242a">这两个样本互为最近邻且分属不同类别</font>。这样如果两个样本形成了一个Tomek Link，则要么其中一个是噪音，要么两个样本都在边界附近。这样通过移除Tomek Link就能“清洗掉”类间重叠样本，使得互为最近邻的样本皆属于同一类别，从而能更好地进行分类。</p>
<pre><code>  下图一上为原始数据，图二上为SMOTE后的数据，图三虚线标识出Tomek Link，图四为移除Tomek Link后的数据集，可以看到不同类别之间样本重叠减少了很多。
</code></pre>
</li>
</ul>
<p><img src="http://files.shanqianche.cn/202169/1623226151018.png" alt="图一"></p>
<p><img src="http://files.shanqianche.cn/202169/1623226162443.png" alt="图二"></p>
<p><img src="http://files.shanqianche.cn/202169/1623226175192.png" alt="图三"></p>
<p><img src="http://files.shanqianche.cn/202169/1623226186988.png" alt="图四"></p>
<ul>
<li><font color="#ff7500"> Edited Nearest Neighbours(ENN)</font>：对于属于多数类的一个样本，如果其K个近邻点有超过一半都不属于多数类，则这个样本会被剔除。这个方法的另一个变种是所有的K个近邻点都不属于多数类，则这个样本会被剔除。、</li>
</ul>
<p>最后，数据清洗技术<font color="#0000FF">最大的缺点</font>是无法控制欠采样的数量。由于都在某种程度上采用了K近邻法，而事实上大部分多数类样本周围也都是多数类，因而能剔除的多数类样本比较有限。</p>
<h3 id="过采样和欠采样结合"><a href="#过采样和欠采样结合" class="headerlink" title="过采样和欠采样结合"></a>过采样和欠采样结合</h3><p>上文中提到SMOTE算法的缺点是生成的少数类样本容易与周围的多数类样本产生重叠难以分类，而数据清洗技术恰好可以处理掉重叠样本，所以可以将二者结合起来形成一个pipeline，先过采样再进行数据清洗。主要的方法是 <code>SMOTE + ENN</code> 和 <code>SMOTE + Tomek</code> ，其中 <code>SMOTE + ENN</code> 通常能清除更多的重叠样本，如下图：</p>
<p><img src="http://files.shanqianche.cn/202169/1623227628385.png" alt="Resampling using Original"></p>
<p><img src="http://files.shanqianche.cn/202169/1623227661187.png" alt="Resampling using SMOTE"></p>
<p><img src="http://files.shanqianche.cn/202169/1623227708226.png" alt="Resampling using SMOTE + ENN"></p>
<p><img src="http://files.shanqianche.cn/202169/1623227766137.png" alt="Resampling using SMOTE + TOMEK"></p>
<hr>
<p><strong><font color="#DC143C">★ 采样方法的效果</font></strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/massquantity/p/9382710.html">机器学习之类别不平衡问题 (3) —— 采样方法 - massquantity - 博客园</a></p>
<h2 id="省心的方法"><a href="#省心的方法" class="headerlink" title="省心的方法"></a>省心的方法</h2><h3 id="主动收集数据"><a href="#主动收集数据" class="headerlink" title="主动收集数据"></a>主动收集数据</h3><p>针对少量样本数据，可以尽可能去扩大这些少量样本的数据集，或者尽可能去增加他们特有的特征来丰富数据的多样性（尽量转化成情况1）。譬如，如果是一个情感分析项目，在分析数据比例时发现负样本（消极情感）的样本数量较少，那么我们可以尽可能在网站中搜集更多的负样本数量，或者花钱去买，毕竟数据少了会带来很多潜在的问题。</p>
<h3 id="将任务转换成异常检测问题、"><a href="#将任务转换成异常检测问题、" class="headerlink" title="将任务转换成异常检测问题、"></a>将任务转换成异常检测问题、</h3><p>如果少数类样本太少，少数类的结构可能并不能被少数类样本的分布很好地表示，那么用平衡数据或调整算法的方法不一定有效。如果这些少数类样本在特征空间中再分布的比较散，情况会更加糟糕。这时候不如将其转换为无监督的异常检测算法，不用过多的去考虑将数据转换为平衡问题来解决。</p>
<h3 id="调整权重"><a href="#调整权重" class="headerlink" title="调整权重"></a>调整权重</h3><p>可以简单的设置损失函数的权重，让模型增加对多数类的惩罚，更多的关注少数类。在python的scikit-learn中我们可以使用class_weight参数来设置权重。</p>
<p>另外，调整权重方法也适合于这种情况：不同类型的错误所造成的后果不同。例如在医疗诊断中，错误地把健康人诊断为患者可能会带来进一步检查的麻烦，但是错误地把患者诊断为健康人，则可能会丧失了拯救生命的最佳时机；再如，门禁系统错误地把可通行人员拦在门外，将使得用户体验不佳，但错误地把陌生人放进门内，则会造成严重的安全事故；在信用卡盗用检查中，将正常使用误认为是盗用，可能会使用户体验不佳，但是将盗用误认为是正常使用，会使用户承受巨大的损失。为了权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价”（unequal cost）。</p>
<h3 id="阈值调整（threshold-moving）"><a href="#阈值调整（threshold-moving）" class="headerlink" title="阈值调整（threshold moving）"></a>阈值调整（threshold moving）</h3><p>直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将原本默认为0.5的阈值调整到 <math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mo>|</mo><mi>P</mi><mo>|</mo></mrow><mrow><mo>(</mo><mo>|</mo><mi>P</mi><mo>|</mo><mo>+</mo><mo>|</mo><mi>N</mi><mo>|</mo><mo>)</mo></mrow></mfrac></math>即可。（大部分是负样本，因此分类器倾向于给出较低的分数）</p>
<h2 id="类别不平横影响模型的输出"><a href="#类别不平横影响模型的输出" class="headerlink" title="类别不平横影响模型的输出"></a>类别不平横影响模型的输出</h2><p>许多模型的输出是基于阈值的，大部分模型的默认阈值为输出值的中位数。比如逻辑回归的输出范围为[0,1]，当某个样本的输出大于0.5就会被划分为正例，反之为反例。在数据的类别不平衡时，采用默认的分类阈值可能会导致输出全部为反例，产生虚假的高准确度，导致分类失败。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://merlynr.github.io">Merlynr</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://merlynr.github.io/2021/05/31/%E4%BA%8C%E5%88%86%E7%B1%BB%E4%B9%8B%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1/">https://merlynr.github.io/2021/05/31/二分类之类别不平衡/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://merlynr.github.io" target="_blank">吾辈之人，自当自强不息！</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/graduate-student/">graduate student</a><a class="post-meta__tags" href="/tags/study/">study</a><a class="post-meta__tags" href="/tags/algorithm/">algorithm</a><a class="post-meta__tags" href="/tags/machine-learning/">machine learning</a><a class="post-meta__tags" href="/tags/data-mining/">data mining</a></div><div class="post_share"><div class="social-share" data-image="http://www.obzhi.com/wp-content/uploads/2022/03/boji2.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/05/30/kernal/"><img class="prev-cover" src="https://w.wallhaven.cc/full/x8/wallhaven-x8gwz3.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">kernal</div></div></a></div><div class="next-post pull-right"><a href="/2021/05/31/%E6%8B%9F%E5%90%88/"><img class="next-cover" src="https://images.wallpaperscraft.com/image/single/lamp_outlet_idea_electricity_120422_300x168.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">拟合</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/05/31/%E5%AD%A4%E7%AB%8B%E6%A3%AE%E6%9E%97%EF%BC%88Isolation%20Forest%EF%BC%89/" title="孤立森林（Isolation Forest）"><img class="cover" src="https://images.wallpaperscraft.com/image/single/face_paint_profile_abstraction_95073_300x168.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-31</div><div class="title">孤立森林（Isolation Forest）</div></div></a></div><div><a href="/2021/05/31/%E6%8B%9F%E5%90%88/" title="拟合"><img class="cover" src="https://images.wallpaperscraft.com/image/single/lamp_outlet_idea_electricity_120422_300x168.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-31</div><div class="title">拟合</div></div></a></div><div><a href="/2021/05/25/%E6%8C%96%E6%8E%98%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%EF%BC%8C%E7%BB%93%E5%90%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BF%9B%E8%A1%8C%E4%B8%9A%E5%8A%A1%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90/" title="挖掘业务流程，结合机器学习进行业务预测分析"><img class="cover" src="https://reddirect.ru/wp-content/uploads/2020/03/socialsovpost_00001-scaled.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-25</div><div class="title">挖掘业务流程，结合机器学习进行业务预测分析</div></div></a></div><div><a href="/2021/05/25/%E7%A6%BB%E7%BE%A4%E7%82%B9%E6%A3%80%E6%B5%8B/" title="离群点检测"><img class="cover" src="https://images.wallpaperscraft.com/image/single/smileys_stars_happy_125856_300x168.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-25</div><div class="title">离群点检测</div></div></a></div><div><a href="/2021/07/19/Long%20Short%20Term%20Memory%20Networks/" title="Long Short Term Memory Networks"><img class="cover" src="https://images.wallpaperscraft.com/image/single/smiles_emoticons_balls_141899_300x168.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-07-19</div><div class="title">Long Short Term Memory Networks</div></div></a></div><div><a href="/2021/05/26/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5/" title="协方差矩阵"><img class="cover" src="https://images.wallpaperscraft.com/image/single/smileys_stars_happy_125856_300x168.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-26</div><div class="title">协方差矩阵</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/thumb-78833.gif" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Merlynr</div><div class="author-info__description">向前一步</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Merlynr" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:lcq1013962426@gmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1-class-imbalance"><span class="toc-number">1.</span> <span class="toc-text">类别不平衡(class-imbalance)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%84%E7%A7%8D%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">2.</span> <span class="toc-text">各种评估指标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">常用的评估方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ROC%E6%9B%B2%E7%BA%BF"><span class="toc-number">3.1.</span> <span class="toc-text">ROC曲线</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">3.1.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ROC%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-number">3.1.2.</span> <span class="toc-text">ROC的优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ROC%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="toc-number">3.1.3.</span> <span class="toc-text">ROC的缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PR-Precision-Recall-%E6%9B%B2%E7%BA%BF"><span class="toc-number">3.2.</span> <span class="toc-text">PR(Precision Recall)曲线</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">采样方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E9%87%87%E6%A0%B7"><span class="toc-number">4.1.</span> <span class="toc-text">过采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AC%A0%E9%87%87%E6%A0%B7"><span class="toc-number">4.2.</span> <span class="toc-text">欠采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E9%87%87%E6%A0%B7%E5%92%8C%E6%AC%A0%E9%87%87%E6%A0%B7%E7%BB%93%E5%90%88"><span class="toc-number">4.3.</span> <span class="toc-text">过采样和欠采样结合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9C%81%E5%BF%83%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">省心的方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E5%8A%A8%E6%94%B6%E9%9B%86%E6%95%B0%E6%8D%AE"><span class="toc-number">5.1.</span> <span class="toc-text">主动收集数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86%E4%BB%BB%E5%8A%A1%E8%BD%AC%E6%8D%A2%E6%88%90%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E9%97%AE%E9%A2%98%E3%80%81"><span class="toc-number">5.2.</span> <span class="toc-text">将任务转换成异常检测问题、</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E6%95%B4%E6%9D%83%E9%87%8D"><span class="toc-number">5.3.</span> <span class="toc-text">调整权重</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%88%E5%80%BC%E8%B0%83%E6%95%B4%EF%BC%88threshold-moving%EF%BC%89"><span class="toc-number">5.4.</span> <span class="toc-text">阈值调整（threshold moving）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E6%A8%AA%E5%BD%B1%E5%93%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BE%93%E5%87%BA"><span class="toc-number">6.</span> <span class="toc-text">类别不平横影响模型的输出</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8B%E4%BA%8B%E4%BB%B6%E7%BB%84(%E4%BA%94)/" title="基于ESP32S3的FreeRTOS之事件组(五)"><img src="https://files.shanqianche.cn/202212/20221216215620.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于ESP32S3的FreeRTOS之事件组(五)"/></a><div class="content"><a class="title" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8B%E4%BA%8B%E4%BB%B6%E7%BB%84(%E4%BA%94)/" title="基于ESP32S3的FreeRTOS之事件组(五)">基于ESP32S3的FreeRTOS之事件组(五)</a><time datetime="2022-12-16T03:39:00.000Z" title="发表于 2022-12-16 11:39:00">2022-12-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8B%E5%AE%9A%E6%97%B6%E5%99%A8(%E5%9B%9B)/" title="基于ESP32S3的FreeRTOS之定时器(四)"><img src="https://files.shanqianche.cn/202212/20221216215620.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于ESP32S3的FreeRTOS之定时器(四)"/></a><div class="content"><a class="title" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8B%E5%AE%9A%E6%97%B6%E5%99%A8(%E5%9B%9B)/" title="基于ESP32S3的FreeRTOS之定时器(四)">基于ESP32S3的FreeRTOS之定时器(四)</a><time datetime="2022-12-16T03:37:00.000Z" title="发表于 2022-12-16 11:37:00">2022-12-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8B%E4%BF%A1%E5%8F%B7%E9%87%8F(%E5%85%AD)/" title="基于ESP32S3的FreeRTOS之信号量(六)"><img src="https://files.shanqianche.cn/202212/20221216215620.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于ESP32S3的FreeRTOS之信号量(六)"/></a><div class="content"><a class="title" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8B%E4%BF%A1%E5%8F%B7%E9%87%8F(%E5%85%AD)/" title="基于ESP32S3的FreeRTOS之信号量(六)">基于ESP32S3的FreeRTOS之信号量(六)</a><time datetime="2022-12-16T03:35:00.000Z" title="发表于 2022-12-16 11:35:00">2022-12-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8B%E9%98%9F%E5%88%97(%E4%B8%89)/" title="基于ESP32S3的FreeRTOS之队列(三)"><img src="https://files.shanqianche.cn/202212/20221216215620.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于ESP32S3的FreeRTOS之队列(三)"/></a><div class="content"><a class="title" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8B%E9%98%9F%E5%88%97(%E4%B8%89)/" title="基于ESP32S3的FreeRTOS之队列(三)">基于ESP32S3的FreeRTOS之队列(三)</a><time datetime="2022-12-16T03:09:00.000Z" title="发表于 2022-12-16 11:09:00">2022-12-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8BTask(%E4%BA%8C)/" title="基于ESP32S3的FreeRTOS之Task(二)"><img src="https://files.shanqianche.cn/202212/20221216215620.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于ESP32S3的FreeRTOS之Task(二)"/></a><div class="content"><a class="title" href="/2022/12/16/%E5%9F%BA%E4%BA%8EESP32S3%E7%9A%84FreeRTOS%E4%B9%8BTask(%E4%BA%8C)/" title="基于ESP32S3的FreeRTOS之Task(二)">基于ESP32S3的FreeRTOS之Task(二)</a><time datetime="2022-12-16T03:08:00.000Z" title="发表于 2022-12-16 11:08:00">2022-12-16</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://images.wallpaperscraft.com/image/single/silhouettes_mannequins_drops_214100_1920x1200.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Merlynr</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, 加油！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'oS5GRWrcL4mqhmTb76gIam4o-gzGzoHsz',
      appKey: 'O3n8aheKbJxQxt2T6eYVtHDT',
      avatar: 'monsterid',
      serverURLs: 'https://os5grwrc.lc-cn-n1-shared.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script>((window.gitter = {}).chat = {}).options = {
  disableDefaultChat: true,
};
document.addEventListener('gitter-sidecar-ready', (e) => {
  const GitterChat = e.detail.Chat
  let chat

  function initGitter () {
    chat = new GitterChat({
      room: 'Merlynr/blog_chat',
      activationElement: '#chat_btn'
    });
  }

  initGitter()

  if (false) {
    document.addEventListener('pjax:complete', () => {
      chat.destroy()
      initGitter()
    })
  }

})</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async="async" defer="defer"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>